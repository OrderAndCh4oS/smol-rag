{
    "excerpt_id_8e74fbca347d63700a75f9a44ad95dec": {
        "doc_id": "doc_68ee570c562a4cdfb5c37cf96be2898d",
        "doc_order_index": 0,
        "excerpt": "**Title: SmolRAG Similarity Search**\n\n---\n\n### **1. Introduction to Similarity Search**\n\nSimilarity search is a core capability of SmolRAG that enables the system to find relevant document excerpts based on semantic similarity to a query. Unlike traditional keyword search, which relies on exact word matches, similarity search uses vector embeddings to capture the meaning and context of both queries and documents, allowing for more natural and effective information retrieval.\n\nThis approach allows SmolRAG to understand the intent behind queries and find relevant information even when the exact terminology differs between the query and the documents. Similarity search forms the foundation of SmolRAG's vector search query type and contributes to other query types as well.\n\n---\n\n### **2. Vector Representation and Semantic Meaning**\n\nAt the heart of similarity search is the concept of vector representation:\n\n- **Semantic Vectors**: Both queries and document excerpts are represented as high-dimensional vectors (embeddings).\n- **Meaning Capture**: These vectors capture the semantic meaning of the text, not just the words used.\n- **Dimensional Space**: In the high-dimensional vector space, similar concepts are positioned closer together.\n- **Contextual Understanding**: The vectors incorporate contextual information, allowing for nuanced understanding.\n- **Language Model Foundation**: The embedding models are built on advanced language models that have been trained on vast amounts of text.\n\nThis vector-based approach allows SmolRAG to move beyond simple keyword matching to a deeper understanding of language and meaning.\n\n---\n\n### **3. Similarity Metrics and Calculations**\n\nSmolRAG uses mathematical measures to determine how similar two vectors are:",
        "summary": "The excerpt outlines the foundational concepts of similarity search in SmolRAG, emphasizing its reliance on vector embeddings for semantic understanding, which aligns with the broader context of the full document that elaborates on various aspects and applications of this advanced search capability.",
        "indexed_at": 1745030046.978838
    },
    "excerpt_id_f6b27b7a25013f2c5751328db6d6e0e3": {
        "doc_id": "doc_68ee570c562a4cdfb5c37cf96be2898d",
        "doc_order_index": 1,
        "excerpt": "e keyword matching to a deeper understanding of language and meaning.\n\n---\n\n### **3. Similarity Metrics and Calculations**\n\nSmolRAG uses mathematical measures to determine how similar two vectors are:- **Cosine Similarity**: The primary metric used is cosine similarity, which measures the cosine of the angle between two vectors.\n- **Score Range**: Similarity scores typically range from 0 to 1, with 1 indicating perfect similarity.\n- **Threshold Filtering**: A configurable threshold (default: 0.02) filters out results that are not sufficiently similar.\n- **Ranking**: Results are ranked by their similarity score, with the most similar excerpts appearing first.\n- **Normalization**: Vectors are normalized to ensure fair comparison regardless of their magnitude.\n\nThese mathematical foundations ensure that similarity search is both accurate and efficient, providing relevant results even for complex queries.\n\n---\n\n### **4. Query Processing for Similarity Search**\n\nWhen a user submits a query, SmolRAG processes it as follows:\n\n1. **Query Embedding**: The query text is embedded using the same model used for document excerpts.\n2. **Vector Comparison**: The query vector is compared to all excerpt vectors in the database.\n3. **Similarity Scoring**: Each comparison produces a similarity score.\n4. **Ranking and Filtering**: Results are ranked by similarity score and filtered based on the threshold.\n5. **Top-K Selection**: The top-k most similar excerpts (default: 5) are selected.\n\nThis process happens quickly, allowing for real-time query responses even with large document collections.\n\n---\n\n### **5. NanoVectorStore Implementation**\n\nSmolRAG uses a lightweight vector database called NanoVectorStore to manage embeddings and perform similarity search:",
        "summary": "The excerpt details the mathematical foundations and processes of similarity search in SmolRAG, illustrating how it enhances the system's ability to retrieve relevant information efficiently by leveraging vector representations and similarity metrics within the broader context of the document's emphasis on advanced semantic understanding and retrieval methodologies.",
        "indexed_at": 1745030046.978903
    },
    "excerpt_id_dcec4d38f0e3c0cff01b04e3b7bdf6ce": {
        "doc_id": "doc_68ee570c562a4cdfb5c37cf96be2898d",
        "doc_order_index": 2,
        "excerpt": " with large document collections.\n\n---\n\n### **5. NanoVectorStore Implementation**\n\nSmolRAG uses a lightweight vector database called NanoVectorStore to manage embeddings and perform similarity search:- **Efficient Storage**: Vectors are stored in a format optimized for fast retrieval.\n- **In-Memory Processing**: For speed, vectors are loaded into memory during search operations.\n- **Persistence**: The store serializes vectors to disk to persist between runs.\n- **Metadata Management**: Each vector is associated with metadata for easy retrieval and filtering.\n- **CRUD Operations**: The store supports creating, reading, updating, and deleting vectors.\n\nThe NanoVectorStore is designed to be simple yet effective, providing the necessary functionality without the complexity of larger vector database systems.\n\n---\n\n### **6. Optimizing Search Performance**\n\nSmolRAG implements several strategies to optimize similarity search performance:\n\n- **Efficient Vector Operations**: Using NumPy for fast vector calculations.\n- **Batch Processing**: Processing multiple vectors at once for efficiency.\n- **Caching**: Caching query embeddings to avoid redundant API calls.\n- **Incremental Updates**: Only updating the vector store when documents change.\n- **Dimensionality Management**: Balancing vector dimension with performance requirements.\n\nThese optimizations ensure that similarity search remains fast and efficient even as the document collection grows.\n\n---\n\n### **7. Context Retrieval and Preparation**\n\nAfter finding the most similar excerpts, SmolRAG prepares them for use by the language model:\n\n1. **Excerpt Retrieval**: The full text of each selected excerpt is retrieved from storage.\n2. **Summary Inclusion**: Each excerpt's summary is included to provide context.\n3. **Formatting**: Excerpts and summaries are formatted into a structured context.\n4. **Token Management**: The combined context is truncated if necessary to fit within token limits.\n5. **Prompt Construction**: The context is incorporated into a prompt for the language model.\n\nThis careful preparation ensures that the language model has the most relevant information available when generating a response.\n\n---",
        "summary": "The excerpt elaborates on the implementation of the NanoVectorStore and strategies for optimizing search performance in SmolRAG, underscoring how these technical features enhance the system's ability to efficiently manage embeddings and deliver rapid, relevant results in the broader context of similarity search.",
        "indexed_at": 1745030046.9789639
    },
    "excerpt_id_6c59f654d2d8c621cf5fea19de72d0fe": {
        "doc_id": "doc_68ee570c562a4cdfb5c37cf96be2898d",
        "doc_order_index": 3,
        "excerpt": "The context is incorporated into a prompt for the language model.\n\nThis careful preparation ensures that the language model has the most relevant information available when generating a response.\n\n---### **8. Handling Edge Cases and Limitations**\n\nSmolRAG addresses several challenges in similarity search:\n\n- **Query Ambiguity**: Using multiple query types to handle different kinds of ambiguity.\n- **Semantic Gaps**: Incorporating knowledge graph information to bridge semantic gaps.\n- **Out-of-Domain Queries**: Gracefully handling queries that don't match any documents.\n- **Long Documents**: Using chunking and summarization to handle long documents effectively.\n- **Rare Terms**: Balancing the importance of rare terms with overall semantic meaning.\n\nBy addressing these challenges, SmolRAG provides robust similarity search that works well across a wide range of use cases.\n\n---\n\n### **9. Combining with Other Search Methods**\n\nWhile powerful on its own, similarity search in SmolRAG is often combined with other search methods:\n\n- **Knowledge Graph Integration**: Combining vector search with graph-based retrieval in the mix query type.\n- **Entity-Based Search**: Using entity embeddings to find relevant entities in the knowledge graph.\n- **Relationship-Based Search**: Finding relationships between entities based on semantic similarity.\n- **Hybrid Approaches**: Blending different search strategies to leverage their complementary strengths.\n- **Weighted Combinations**: Adjusting the influence of different search methods based on query characteristics.\n\nThese combinations enhance the system's ability to find relevant information across different types of queries and document structures.\n\n---\n\n### **10. Evaluating Search Quality**\n\nSmolRAG includes mechanisms for evaluating and improving similarity search quality:",
        "summary": "The excerpt highlights the importance of carefully preparing context for the language model within SmolRAG's broader framework of similarity search, which effectively addresses challenges such as query ambiguity and integrates multiple search methods to enhance information retrieval accuracy.",
        "indexed_at": 1745030046.979025
    },
    "excerpt_id_9852e72fbe12ed839b385c87873fec09": {
        "doc_id": "doc_68ee570c562a4cdfb5c37cf96be2898d",
        "doc_order_index": 4,
        "excerpt": " information across different types of queries and document structures.\n\n---\n\n### **10. Evaluating Search Quality**\n\nSmolRAG includes mechanisms for evaluating and improving similarity search quality:- **Test Queries**: Using predefined test queries to evaluate retrieval performance.\n- **Precision and Recall**: Measuring both the accuracy and completeness of search results.\n- **Threshold Tuning**: Adjusting similarity thresholds to balance precision and recall.\n- **Model Selection**: Comparing different embedding models to find the best performance.\n- **User Feedback**: Incorporating user feedback to improve search quality over time.\n\nRegular evaluation helps ensure that similarity search continues to provide high-quality results as the system evolves.\n\n---\n\n### **11. Practical Applications and Examples**\n\nSimilarity search in SmolRAG enables a wide range of practical applications:\n\n- **Question Answering**: Finding relevant information to answer specific questions.\n- **Document Exploration**: Discovering related content across different documents.\n- **Concept Search**: Finding information about concepts even when terminology varies.\n- **Technical Support**: Locating relevant documentation for technical issues.\n- **Knowledge Discovery**: Uncovering connections between different pieces of information.\n\nThese applications demonstrate the versatility and power of similarity search in real-world scenarios.\n\n---\n\n### **12. Future Enhancements**\n\nSmolRAG's similarity search capabilities continue to evolve:\n\n- **Advanced Models**: Incorporating newer and more powerful embedding models.\n- **Approximate Search**: Implementing approximate nearest neighbor search for larger collections.\n- **Multi-Modal Search**: Extending similarity search to handle images and other non-text content.\n- **Personalization**: Adapting search results based on user preferences and history.\n- **Federated Search**: Searching across multiple vector stores or knowledge bases.\n\nThese future enhancements will further improve the accuracy, efficiency, and versatility of similarity search in SmolRAG.\n\n---\n\n### **13. Conclusion**",
        "summary": "The excerpt highlights the evaluation and enhancement mechanisms of SmolRAG's similarity search, underscoring its role in ensuring high-quality information retrieval across diverse queries and applications, which is essential for the system's overall effectiveness and adaptability.",
        "indexed_at": 1745030046.9790862
    },
    "excerpt_id_6feed1d0b430f2139ef9246b1e1758d3": {
        "doc_id": "doc_68ee570c562a4cdfb5c37cf96be2898d",
        "doc_order_index": 5,
        "excerpt": "cross multiple vector stores or knowledge bases.\n\nThese future enhancements will further improve the accuracy, efficiency, and versatility of similarity search in SmolRAG.\n\n---\n\n### **13. Conclusion**Similarity search is a powerful capability that enables SmolRAG to find relevant information based on semantic meaning rather than just keywords. By representing both queries and documents as vectors in a high-dimensional space, the system can identify conceptually similar content even when the exact terminology differs.\n\nThis approach, combined with SmolRAG's other retrieval mechanisms, provides a robust foundation for accurate and contextually relevant information retrieval. Whether used on its own in the vector search query type or combined with knowledge graph approaches in other query types, similarity search plays a crucial role in SmolRAG's ability to understand and respond to user queries.",
        "summary": "The excerpt highlights the pivotal role of similarity search in SmolRAG, emphasizing its ability to enhance information retrieval by focusing on semantic meaning, which ties together the document's overall theme of advanced search capabilities and future improvements.",
        "indexed_at": 1745030046.9791439
    },
    "excerpt_id_e9a4b3b83fa7390d9e03b26469553d2e": {
        "doc_id": "doc_b117633f7a8a496b4f07a2327947e4d4",
        "doc_order_index": 0,
        "excerpt": "**Title: SmolRAG API Documentation**\n\n---\n\n### **1. Introduction to the SmolRAG API**\n\nThe SmolRAG API provides a simple and powerful interface for interacting with SmolRAG through HTTP requests. This REST API allows you to query documents using various query types without having to directly integrate the SmolRAG Python library into your application.\n\nThe API is built using FastAPI, a modern, fast web framework for building APIs with Python. It provides automatic validation, serialization, and documentation, making it easy to use and integrate with other systems.\n\n---\n\n### **2. API Overview**\n\nThe SmolRAG API exposes a single endpoint for querying documents:\n\n| Endpoint | Method | Description |\n|----------|--------|-------------|\n| `/query` | POST | Process a query using SmolRAG |\n\nThis endpoint accepts a JSON payload containing the query text and optional query type, and returns a JSON response with the query result.\n\n---\n\n### **3. Request Format**\n\nRequests to the `/query` endpoint should use the following format:\n\n```json\n{\n  \"text\": \"Your query text here\",\n  \"query_type\": \"standard\"\n}\n```\n\n**Parameters**:\n\n- `text` (string, required): The query text to process.\n- `query_type` (string, optional, default: \"standard\"): The type of query to perform. Valid values are:\n  - `standard`: Uses vector search query\n  - `local_kg`: Uses local knowledge graph query\n  - `global_kg`: Uses global knowledge graph query\n  - `hybrid_kg`: Uses hybrid knowledge graph query\n  - `mix`: Uses mix query (combines vector search and knowledge graph)\n\nIf the `query_type` parameter is omitted, the API will use the default \"standard\" query type.\n\n---\n\n### **4. Response Format**\n\nResponses from the `/query` endpoint use the following format:\n\n```json\n{\n  \"result\": \"The response text from SmolRAG\"\n}\n```\n\n**Fields**:\n\n- `result` (string): The response text generated by SmolRAG based on the query.\n\n---\n\n### **5. Error Handling**",
        "summary": "The excerpt provides a detailed overview of the initial sections of the SmolRAG API documentation, highlighting its purpose, endpoint structure, request and response formats, and error handling, which collectively emphasize the API's functionality within the broader context of enabling efficient document querying through a user-friendly interface.",
        "indexed_at": 1745030046.98109
    },
    "excerpt_id_57aae66702d1057a0462d26360d3ccef": {
        "doc_id": "doc_b117633f7a8a496b4f07a2327947e4d4",
        "doc_order_index": 1,
        "excerpt": "wing format:\n\n```json\n{\n  \"result\": \"The response text from SmolRAG\"\n}\n```\n\n**Fields**:\n\n- `result` (string): The response text generated by SmolRAG based on the query.\n\n---\n\n### **5. Error Handling**The API includes robust error handling to provide clear feedback when issues occur:\n\n**Client Errors (4xx)**:\n\n- **400 Bad Request**: Returned when the request is invalid, such as when the query text is empty or the query type is invalid.\n\n```json\n  {\n    \"detail\": \"Query text cannot be empty\"\n  }\n  ```\n\nor\n\n```json\n  {\n    \"detail\": \"Invalid query_type: unknown. Valid types are: standard, local_kg, global_kg, hybrid_kg, mix\"\n  }\n  ```\n\n**Server Errors (5xx)**:\n\n- **500 Internal Server Error**: Returned when an unexpected error occurs during query processing.\n\n```json\n  {\n    \"detail\": \"Error message describing the issue\"\n  }\n  ```\n\nThese error responses help diagnose and resolve issues when integrating with the API.\n\n---\n\n### **6. Authentication**\n\nThe SmolRAG API does not include built-in authentication by default. If you need to secure the API, you should implement authentication using FastAPI's security features or deploy the API behind an API gateway that provides authentication.\n\nFor production deployments, consider implementing one of the following authentication methods:\n\n- **API Key**: Require an API key in the request headers.\n- **OAuth 2.0**: Use OAuth 2.0 for more sophisticated authentication and authorization.\n- **JWT**: Use JSON Web Tokens for stateless authentication.\n\nExample implementation of API key authentication:",
        "summary": "The excerpt details the error handling and authentication mechanisms of the SmolRAG API, emphasizing the importance of clear feedback for common issues and the necessity for securing the API through various authentication methods, which are integral to ensuring reliable and secure interactions within the broader context of API usage and integration described in the full documentation.",
        "indexed_at": 1745030046.981153
    },
    "excerpt_id_de1f8b8f458f74d9b97d639f4ede4c9c": {
        "doc_id": "doc_b117633f7a8a496b4f07a2327947e4d4",
        "doc_order_index": 2,
        "excerpt": "\n- **OAuth 2.0**: Use OAuth 2.0 for more sophisticated authentication and authorization.\n- **JWT**: Use JSON Web Tokens for stateless authentication.\n\nExample implementation of API key authentication:```python\nfrom fastapi import FastAPI, Depends, HTTPException, Security\nfrom fastapi.security.api_key import APIKeyHeader\nfrom starlette.status import HTTP_403_FORBIDDEN\n\nAPI_KEY = \"your-secret-api-key\"\nAPI_KEY_NAME = \"X-API-Key\"\n\napi_key_header = APIKeyHeader(name=API_KEY_NAME, auto_error=False)\n\nasync def get_api_key(api_key: str = Security(api_key_header)):\n    if api_key == API_KEY:\n        return api_key\n    raise HTTPException(\n        status_code=HTTP_403_FORBIDDEN, detail=\"Invalid API Key\"\n    )\n\napp = FastAPI(title=\"SmolRag API\")\n\n@app.post(\"/query\", dependencies=[Depends(get_api_key)])\nasync def query_endpoint(request: QueryRequest):\n    # Process query as normal\n    pass\n```",
        "summary": "The excerpt details the authentication methods recommended for the SmolRAG API, highlighting the integration of API keys, OAuth 2.0, and JWT, which aligns with the broader context of ensuring secure and flexible access control in the API documentation.",
        "indexed_at": 1745030046.981212
    },
    "excerpt_id_df5dd931f692d6413ff6151ca37e0c76": {
        "doc_id": "doc_b117633f7a8a496b4f07a2327947e4d4",
        "doc_order_index": 3,
        "excerpt": "API Key\"\n    )\n\napp = FastAPI(title=\"SmolRag API\")\n\n@app.post(\"/query\", dependencies=[Depends(get_api_key)])\nasync def query_endpoint(request: QueryRequest):\n    # Process query as normal\n    pass\n```---\n\n### **7. Rate Limiting**\n\nThe SmolRAG API does not include built-in rate limiting by default. For production deployments, consider implementing rate limiting to prevent abuse and ensure fair usage of resources.\n\nYou can implement rate limiting using FastAPI middleware or deploy the API behind an API gateway that provides rate limiting capabilities.\n\nExample implementation using the `slowapi` package:\n\n```python\nfrom fastapi import FastAPI\nfrom slowapi import Limiter, _rate_limit_exceeded_handler\nfrom slowapi.util import get_remote_address\nfrom slowapi.errors import RateLimitExceeded\n\nlimiter = Limiter(key_func=get_remote_address)\napp = FastAPI(title=\"SmolRag API\")\napp.state.limiter = limiter\napp.add_exception_handler(RateLimitExceeded, _rate_limit_exceeded_handler)\n\n@app.post(\"/query\")\n@limiter.limit(\"10/minute\")\nasync def query_endpoint(request: QueryRequest):\n    # Process query as normal\n    pass\n```\n\n---\n\n### **8. CORS Configuration**\n\nCross-Origin Resource Sharing (CORS) allows web applications running on one domain to make requests to the API running on another domain. The SmolRAG API does not include CORS configuration by default.\n\nFor web applications that need to access the API from a browser, you should configure CORS using FastAPI's middleware:\n\n```python\nfrom fastapi import FastAPI\nfrom fastapi.middleware.cors import CORSMiddleware\n\napp = FastAPI(title=\"SmolRag API\")\n\n# Configure CORS\napp.add_middleware(\n    CORSMiddleware,\n    allow_origins=[\"https://your-frontend-domain.com\"],\n    allow_credentials=True,\n    allow_methods=[\"*\"],\n    allow_headers=[\"*\"],\n)\n\n# API endpoints\n```\n\nAdjust the `allow_origins` list to include the domains of your frontend applications.\n\n---\n\n### **9. API Versioning**\n\nAs your API evolves, you may need to make breaking changes while still supporting existing clients. API versioning allows you to do this by providing different versions of the API simultaneously.\n\nYou can implement versioning in FastAPI using path prefixes:",
        "summary": "The excerpt discusses essential aspects of API key authentication and rate limiting within the SmolRAG API, highlighting its security measures and performance optimization strategies to ensure reliable and controlled access, which aligns with the broader context of deploying and maintaining a robust API system outlined in the full document.",
        "indexed_at": 1745030046.981272
    },
    "excerpt_id_b9097e11b1551a13941242fc121df006": {
        "doc_id": "doc_b117633f7a8a496b4f07a2327947e4d4",
        "doc_order_index": 4,
        "excerpt": "s while still supporting existing clients. API versioning allows you to do this by providing different versions of the API simultaneously.\n\nYou can implement versioning in FastAPI using path prefixes:```python\nfrom fastapi import FastAPI, APIRouter\n\napp = FastAPI(title=\"SmolRag API\")\n\n# Version 1 router\nv1_router = APIRouter(prefix=\"/v1\")\n\n@v1_router.post(\"/query\")\nasync def query_endpoint_v1(request: QueryRequest):\n    # Process query using v1 logic\n    pass\n\n# Version 2 router\nv2_router = APIRouter(prefix=\"/v2\")\n\n@v2_router.post(\"/query\")\nasync def query_endpoint_v2(request: QueryRequestV2):\n    # Process query using v2 logic\n    pass\n\n# Include routers\napp.include_router(v1_router)\napp.include_router(v2_router)\n```",
        "summary": "The excerpt discusses the implementation of API versioning in the SmolRAG API, highlighting how it allows for simultaneous support of different versions to maintain backward compatibility, which is a crucial aspect of the API's evolution and usability in varied client applications.",
        "indexed_at": 1745030046.98133
    },
    "excerpt_id_453681d430472ffcca54f90331e78fee": {
        "doc_id": "doc_b117633f7a8a496b4f07a2327947e4d4",
        "doc_order_index": 5,
        "excerpt": "uter.post(\"/query\")\nasync def query_endpoint_v2(request: QueryRequestV2):\n    # Process query using v2 logic\n    pass\n\n# Include routers\napp.include_router(v1_router)\napp.include_router(v2_router)\n```This approach allows you to maintain backward compatibility while adding new features.\n\n---\n\n### **10. API Documentation with Swagger UI**\n\nFastAPI automatically generates interactive API documentation using Swagger UI. When you run the SmolRAG API, you can access the documentation at:\n\n- Swagger UI: `http://localhost:8000/docs`\n- ReDoc: `http://localhost:8000/redoc`\n\nThese interactive documentation pages allow you to:\n\n1. Explore the available endpoints\n2. View request and response schemas\n3. Test the API directly from the browser\n4. Understand the validation rules and error responses\n\nThe documentation is automatically generated from the API code, ensuring it stays up-to-date with the implementation.\n\n---\n\n### **11. Example API Requests**\n\nHere are examples of how to interact with the SmolRAG API using different tools:\n\n**Using curl**:\n\n```bash\n# Standard query\ncurl -X POST http://localhost:8000/query \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\"text\": \"What is SmolRAG?\", \"query_type\": \"standard\"}'\n\n# Knowledge graph query\ncurl -X POST http://localhost:8000/query \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\"text\": \"What entities are related to document chunking?\", \"query_type\": \"local_kg\"}'\n\n# Mix query\ncurl -X POST http://localhost:8000/query \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\"text\": \"How does SmolRAG process and retrieve information?\", \"query_type\": \"mix\"}'\n```\n\n**Using Python requests**:",
        "summary": "The excerpt details the implementation of versioning in the SmolRAG API, specifically how different query endpoint versions can coexist to maintain backward compatibility while introducing new features, reinforcing the documentation's overall theme of enabling seamless integration and evolution of the API.",
        "indexed_at": 1745030046.981388
    },
    "excerpt_id_06064de98cbba1d78e30fa4dc9a3ba41": {
        "doc_id": "doc_b117633f7a8a496b4f07a2327947e4d4",
        "doc_order_index": 6,
        "excerpt": "-X POST http://localhost:8000/query \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\"text\": \"How does SmolRAG process and retrieve information?\", \"query_type\": \"mix\"}'\n```\n\n**Using Python requests**:```python\nimport requests\nimport json\n\nurl = \"http://localhost:8000/query\"\nheaders = {\"Content-Type\": \"application/json\"}\n\n# Standard query\npayload = {\n    \"text\": \"What is SmolRAG?\",\n    \"query_type\": \"standard\"\n}\nresponse = requests.post(url, data=json.dumps(payload), headers=headers)\nprint(response.json())\n\n# Knowledge graph query\npayload = {\n    \"text\": \"What entities are related to document chunking?\",\n    \"query_type\": \"local_kg\"\n}\nresponse = requests.post(url, data=json.dumps(payload), headers=headers)\nprint(response.json())\n\n# Mix query\npayload = {\n    \"text\": \"How does SmolRAG process and retrieve information?\",\n    \"query_type\": \"mix\"\n}\nresponse = requests.post(url, data=json.dumps(payload), headers=headers)\nprint(response.json())\n```",
        "summary": "The excerpt illustrates practical examples of how to interact with the SmolRAG API's `/query` endpoint, thereby demonstrating its functionality within the broader context of the API documentation which outlines usage, formats, and response handling for querying documents.",
        "indexed_at": 1745030046.981449
    },
    "excerpt_id_63cd91bc48a4a86dbc4244526ba83736": {
        "doc_id": "doc_b117633f7a8a496b4f07a2327947e4d4",
        "doc_order_index": 7,
        "excerpt": "load = {\n    \"text\": \"How does SmolRAG process and retrieve information?\",\n    \"query_type\": \"mix\"\n}\nresponse = requests.post(url, data=json.dumps(payload), headers=headers)\nprint(response.json())\n```**Using JavaScript fetch**:\n\n```javascript\n// Standard query\nfetch('http://localhost:8000/query', {\n  method: 'POST',\n  headers: {\n    'Content-Type': 'application/json',\n  },\n  body: JSON.stringify({\n    text: 'What is SmolRAG?',\n    query_type: 'standard'\n  }),\n})\n.then(response => response.json())\n.then(data => console.log(data));\n\n// Knowledge graph query\nfetch('http://localhost:8000/query', {\n  method: 'POST',\n  headers: {\n    'Content-Type': 'application/json',\n  },\n  body: JSON.stringify({\n    text: 'What entities are related to document chunking?',\n    query_type: 'local_kg'\n  }),\n})\n.then(response => response.json())\n.then(data => console.log(data));\n\n// Mix query\nfetch('http://localhost:8000/query', {\n  method: 'POST',\n  headers: {\n    'Content-Type': 'application/json',\n  },\n  body: JSON.stringify({\n    text: 'How does SmolRAG process and retrieve information?',\n    query_type: 'mix'\n  }),\n})\n.then(response => response.json())\n.then(data => console.log(data));\n```\n\n---\n\n### **12. Deployment Considerations**\n\nWhen deploying the SmolRAG API to production, consider the following:\n\n**Server Options**:\n- **Uvicorn**: A lightweight ASGI server suitable for development and small deployments.\n\n```bash\n  uvicorn api.main:app --host 0.0.0.0 --port 8000\n  ```\n\n- **Gunicorn with Uvicorn Workers**: For production deployments with multiple workers.\n\n```bash\n  gunicorn api.main:app -w 4 -k uvicorn.workers.UvicornWorker --bind 0.0.0.0:8000\n  ```\n\n- **Docker**: Containerize the API for consistent deployment across environments.\n\n```bash\n  docker build -t smol-rag .\n  docker run -p 8000:8000 --env-file .env smol-rag\n  ```\n\n**Performance Optimization**:\n- Use a production-grade ASGI server like Uvicorn with Gunicorn\n- Implement caching for frequent queries\n- Consider horizontal scaling for high-traffic deployments\n- Monitor memory usage, as the vector store and knowledge graph can consume significant memory",
        "summary": "The excerpt illustrates practical examples of using the SmolRAG API for querying information, emphasizing its request format, response handling, and deployment considerations, all of which align with the broader context of providing a comprehensive and user-friendly API documentation for SmolRAG.",
        "indexed_at": 1745030046.9815092
    },
    "excerpt_id_1e99d3a705e109f5103d3d1958b6a8db": {
        "doc_id": "doc_b117633f7a8a496b4f07a2327947e4d4",
        "doc_order_index": 8,
        "excerpt": "icorn\n- Implement caching for frequent queries\n- Consider horizontal scaling for high-traffic deployments\n- Monitor memory usage, as the vector store and knowledge graph can consume significant memory**Security**:\n- Implement authentication and authorization\n- Use HTTPS in production\n- Regularly update dependencies\n- Implement proper input validation and sanitization\n\n**Monitoring**:\n- Set up logging to track API usage and errors\n- Implement health check endpoints\n- Use monitoring tools to track performance and availability\n\n---\n\n### **13. Extending the API**\n\nThe SmolRAG API can be extended to provide additional functionality:\n\n**Additional Endpoints**:\n- **Document Management**: Add endpoints for adding, updating, and removing documents.\n\n```python\n  @app.post(\"/documents\")\n  async def add_document(document: DocumentRequest):\n      # Add document logic\n      pass\n  \n  @app.delete(\"/documents/{document_id}\")\n  async def remove_document(document_id: str):\n      # Remove document logic\n      pass\n  ```\n\n- **System Information**: Add endpoints for retrieving information about the system.\n\n```python\n  @app.get(\"/info\")\n  async def get_info():\n      # Return system information\n      pass\n  ```\n\n**Asynchronous Processing**:\n- For long-running queries, implement asynchronous processing with background tasks.\n\n```python\n  from fastapi import BackgroundTasks\n  \n  @app.post(\"/query/async\")\n  async def async_query(request: QueryRequest, background_tasks: BackgroundTasks):\n      # Start query in background\n      background_tasks.add_task(process_query, request)\n      return {\"status\": \"processing\", \"query_id\": query_id}\n  \n  @app.get(\"/query/result/{query_id}\")\n  async def get_query_result(query_id: str):\n      # Return result if available\n      pass\n  ```\n\n**Webhooks**:\n- Implement webhooks for notifying external systems when queries are completed.\n\n```python\n  @app.post(\"/query/webhook\")\n  async def webhook_query(request: WebhookQueryRequest):\n      # Process query and send result to webhook URL\n      pass\n  ```\n\n---\n\n### **14. Conclusion**",
        "summary": "The excerpt discusses security, monitoring, and potential extensions of the SmolRAG API, emphasizing the importance of robust deployment practices and additional functionality to enhance user experience, which aligns with the document's broader goal of providing a comprehensive and flexible API for document querying.",
        "indexed_at": 1745030046.981568
    },
    "excerpt_id_e65b14cb533eda0a73c1a54d86336320": {
        "doc_id": "doc_b117633f7a8a496b4f07a2327947e4d4",
        "doc_order_index": 9,
        "excerpt": "ed.\n\n```python\n  @app.post(\"/query/webhook\")\n  async def webhook_query(request: WebhookQueryRequest):\n      # Process query and send result to webhook URL\n      pass\n  ```\n\n---\n\n### **14. Conclusion**The SmolRAG API provides a simple yet powerful interface for querying documents using various retrieval methods. By following RESTful principles and leveraging FastAPI's capabilities, the API offers a clean, well-documented, and easy-to-use interface for integrating SmolRAG into your applications.\n\nWhether you're building a web application, mobile app, or integrating with other systems, the SmolRAG API provides the flexibility and functionality you need to leverage the power of retrieval-augmented generation.",
        "summary": "The excerpt emphasizes the SmolRAG API's extensibility through features like webhooks, reinforcing its overall purpose of providing a flexible interface for document querying while enabling integration with various applications and systems.",
        "indexed_at": 1745030046.981625
    },
    "excerpt_id_ccf53d07456b549a9c9785f0bc9519b8": {
        "doc_id": "doc_527d38dfafb42e0277ca302149af6bdb",
        "doc_order_index": 0,
        "excerpt": "**Title: SmolRAG Troubleshooting Guide**\n\n---\n\n### **1. Introduction to Troubleshooting SmolRAG**\n\nEven with careful implementation and configuration, you may encounter issues when working with SmolRAG. This troubleshooting guide aims to help you identify and resolve common problems that can occur during document ingestion, querying, and general system operation.\n\nThe guide is organized by problem category, with each section describing common symptoms, potential causes, and recommended solutions. By following this guide, you should be able to diagnose and fix most issues you encounter with SmolRAG, ensuring smooth operation of your retrieval-augmented generation system.\n\n---\n\n### **2. Installation and Setup Issues**\n\n**Symptom: Import errors when trying to use SmolRAG**\n\n*Potential Causes:*\n- Missing dependencies\n- Incorrect Python version\n- Incorrect installation path\n\n*Solutions:*\n1. Ensure you're using Python 3.10 or higher:\n\n```bash\n   python --version\n   ```\n\n2. Reinstall dependencies with:\n\n```bash\n   pip install -r requirements.txt\n   ```\n\n3. Check your Python path:\n\n```python\n   import sys\n   print(sys.path)\n   ```\n\n**Symptom: Directory structure errors**\n\n*Potential Causes:*\n- Missing required directories\n- Incorrect permissions\n\n*Solutions:*\n1. Create the required directories:\n\n```bash\n   mkdir -p app/data app/cache app/logs app/input_docs\n   ```\n\n2. Check directory permissions:\n\n```bash\n   ls -la app/\n   ```\n\n3. Ensure the directories are writable by the current user:\n\n```bash\n   chmod -R u+w app/data app/cache app/logs app/input_docs\n   ```\n\n**Symptom: Environment variable errors**\n\n*Potential Causes:*\n- Missing or incorrect OpenAI API key\n- Environment variables not loaded\n\n*Solutions:*\n1. Check if your `.env` file exists and contains the required variables:\n\n```bash\n   cat .env\n   ```\n\n2. Ensure the API key is correctly formatted and valid:\n\n```\n   OPENAI_API_KEY=sk-your-api-key\n   ```\n\n3. Try setting the environment variable directly:",
        "summary": "The excerpt introduces the troubleshooting guide for SmolRAG, outlining its purpose to assist users in resolving common issues related to system implementation, highlighting specific problems, potential causes, and solutions, thereby making it a crucial component of the broader document focused on optimizing the user experience and functionality of the SmolRAG system.",
        "indexed_at": 1745030046.983724
    },
    "excerpt_id_3d02a7878513f8025940bb3e93ae517f": {
        "doc_id": "doc_527d38dfafb42e0277ca302149af6bdb",
        "doc_order_index": 1,
        "excerpt": "equired variables:\n\n```bash\n   cat .env\n   ```\n\n2. Ensure the API key is correctly formatted and valid:\n\n```\n   OPENAI_API_KEY=sk-your-api-key\n   ```\n\n3. Try setting the environment variable directly:```bash\n   export OPENAI_API_KEY=sk-your-api-key\n   ```",
        "summary": "The excerpt highlights the importance of correctly configuring environment variables, particularly the OpenAI API key, as a critical step in addressing installation and setup issues outlined in the broader context of the SmolRAG Troubleshooting Guide.",
        "indexed_at": 1745030046.9837902
    },
    "excerpt_id_81631ae5feaa160d24c7aa3331760a64": {
        "doc_id": "doc_527d38dfafb42e0277ca302149af6bdb",
        "doc_order_index": 2,
        "excerpt": "```bash\n   export OPENAI_API_KEY=sk-your-api-key\n   ```4. Verify the environment variable is loaded:\n\n```python\n   import os\n   print(os.environ.get(\"OPENAI_API_KEY\"))\n   ```\n\n---\n\n### **3. Document Ingestion Issues**\n\n**Symptom: Documents not being ingested**\n\n*Potential Causes:*\n- Documents not in the correct directory\n- Unsupported file formats\n- Permission issues\n\n*Solutions:*\n1. Verify documents are in the correct directory:\n\n```bash\n   ls -la app/input_docs/\n   ```\n\n2. Ensure documents are in supported formats (e.g., .txt, .md)\n\n3. Check file permissions:\n\n```bash\n   chmod -R u+r app/input_docs/\n   ```\n\n**Symptom: Slow document ingestion**\n\n*Potential Causes:*\n- Large documents\n- Many documents being processed at once\n- API rate limits\n- Insufficient resources\n\n*Solutions:*\n1. Process documents in smaller batches:\n\n```python\n   # Process documents in batches\n   import os\n   from app.definitions import INPUT_DOCS_DIR\n\n   files = [f for f in os.listdir(INPUT_DOCS_DIR) if os.path.isfile(os.path.join(INPUT_DOCS_DIR, f))]\n   batch_size = 5\n\n   for i in range(0, len(files), batch_size):\n       batch = files[i:i+batch_size]\n       # Process batch\n       print(f\"Processing batch {i//batch_size + 1}/{(len(files) + batch_size - 1)//batch_size}\")\n   ```\n\n2. Implement rate limiting for API calls:\n\n```python\n   import time\n\n   def rate_limited_api_call(func, *args, **kwargs):\n       result = func(*args, **kwargs)\n       time.sleep(0.1)  # Sleep to avoid hitting rate limits\n       return result\n   ```\n\n3. Monitor resource usage and adjust accordingly:\n\n```python\n   import psutil\n\n   def check_resources():\n       cpu_percent = psutil.cpu_percent()\n       memory_percent = psutil.virtual_memory().percent\n       print(f\"CPU: {cpu_percent}%, Memory: {memory_percent}%\")\n\n       if memory_percent > 90:\n           print(\"Warning: High memory usage\")\n   ```\n\n**Symptom: Errors during entity extraction**\n\n*Potential Causes:*\n- LLM API errors\n- Malformed content\n- Timeout issues\n\n*Solutions:*\n1. Implement robust error handling:",
        "summary": "The excerpt provides specific troubleshooting steps for resolving document ingestion issues in SmolRAG, aligning with the broader context of the full document by detailing common problems and solutions that help maintain the effective operation of the retrieval-augmented generation system.",
        "indexed_at": 1745030046.983855
    },
    "excerpt_id_98e0d419e4d21933f163a50d476d4728": {
        "doc_id": "doc_527d38dfafb42e0277ca302149af6bdb",
        "doc_order_index": 3,
        "excerpt": "g: High memory usage\")\n   ```\n\n**Symptom: Errors during entity extraction**\n\n*Potential Causes:*\n- LLM API errors\n- Malformed content\n- Timeout issues\n\n*Solutions:*\n1. Implement robust error handling:```python\n   try:\n       result = llm.get_completion(prompt)\n   except Exception as e:\n       logger.error(f\"Error during entity extraction: {e}\")\n       result = \"\"  # Provide a default or retry\n   ```",
        "summary": "The excerpt highlights specific errors related to entity extraction within SmolRAG, emphasizing the importance of implementing robust error handling as a part of the broader troubleshooting strategies detailed throughout the document to ensure effective resolution of common issues in the system's operation.",
        "indexed_at": 1745030046.983917
    },
    "excerpt_id_65383440b6cc941c8450b659b284a24d": {
        "doc_id": "doc_527d38dfafb42e0277ca302149af6bdb",
        "doc_order_index": 4,
        "excerpt": "`python\n   try:\n       result = llm.get_completion(prompt)\n   except Exception as e:\n       logger.error(f\"Error during entity extraction: {e}\")\n       result = \"\"  # Provide a default or retry\n   ```2. Check for and handle malformed content:\n\n```python\n   def sanitize_content(content):\n       # Remove problematic characters or patterns\n       return content\n   ```\n\n3. Implement retries with exponential backoff:\n\n```python\n   import time\n\n   def retry_with_backoff(func, max_retries=3):\n       retries = 0\n       while retries < max_retries:\n           try:\n               return func()\n           except Exception as e:\n               wait_time = 2 ** retries\n               print(f\"Error: {e}. Retrying in {wait_time} seconds...\")\n               time.sleep(wait_time)\n               retries += 1\n\n       # If we get here, all retries failed\n       raise Exception(\"Max retries exceeded\")\n   ```\n\n---\n\n### **4. Vector Store Issues**\n\n**Symptom: Vector store errors or corruption**\n\n*Potential Causes:*\n- Disk space issues\n- File permission problems\n- Concurrent access issues\n- Power loss during write operations\n\n*Solutions:*\n1. Check disk space:\n\n```bash\n   df -h\n   ```\n\n2. Verify file permissions:\n\n```bash\n   ls -la app/data/\n   ```\n\n3. Implement file locking for concurrent access:\n\n```python\n   import fcntl\n\n   def with_file_lock(file_path, callback):\n       with open(file_path, 'r+') as f:\n           try:\n               fcntl.flock(f, fcntl.LOCK_EX)\n               return callback(f)\n           finally:\n               fcntl.flock(f, fcntl.LOCK_UN)\n   ```\n\n4. Implement backup and recovery:\n\n```python\n   import shutil\n   import os\n\n   def backup_vector_store(vector_store_path, backup_dir):\n       os.makedirs(backup_dir, exist_ok=True)\n       backup_path = os.path.join(backup_dir, os.path.basename(vector_store_path) + '.bak')\n       shutil.copy2(vector_store_path, backup_path)\n       return backup_path\n   ```\n\n**Symptom: Missing or incorrect embeddings**\n\n*Potential Causes:*\n- Embedding generation failures\n- Embedding model issues\n- Caching problems\n\n*Solutions:*\n1. Verify embeddings exist:",
        "summary": "The excerpt highlights specific troubleshooting techniques for handling entity extraction and vector store issues within the SmolRAG system, illustrating the broader context of the document that provides comprehensive support for diagnosing and resolving various operational challenges in retrieval-augmented generation systems.",
        "indexed_at": 1745030046.98398
    },
    "excerpt_id_025af8cc196b4a0f0777ff0f427b6dff": {
        "doc_id": "doc_527d38dfafb42e0277ca302149af6bdb",
        "doc_order_index": 5,
        "excerpt": "kup_path\n   ```\n\n**Symptom: Missing or incorrect embeddings**\n\n*Potential Causes:*\n- Embedding generation failures\n- Embedding model issues\n- Caching problems\n\n*Solutions:*\n1. Verify embeddings exist:```python\n   def check_embeddings(rag, doc_id):\n       excerpt_ids = rag.doc_to_excerpt_kv.get_by_key(doc_id)\n       if not excerpt_ids:\n           print(f\"No excerpts found for document {doc_id}\")\n           return False\n\n       for excerpt_id in excerpt_ids:\n           results = rag.embeddings_db.query(query=None, filter_func=lambda x: x[\"__id__\"] == excerpt_id)\n           if not results:\n               print(f\"No embedding found for excerpt {excerpt_id}\")\n               return False\n\n       return True\n   ```",
        "summary": "The excerpt addresses the potential causes and solutions for missing or incorrect embeddings in SmolRAG, highlighting a critical troubleshooting aspect relevant to the broader context of the document which provides comprehensive guidance on diagnosing and resolving various operational issues within the retrieval-augmented generation system.",
        "indexed_at": 1745030046.984042
    },
    "excerpt_id_8125dcd822731acc0c981b8a1307c4d3": {
        "doc_id": "doc_527d38dfafb42e0277ca302149af6bdb",
        "doc_order_index": 6,
        "excerpt": " filter_func=lambda x: x[\"__id__\"] == excerpt_id)\n           if not results:\n               print(f\"No embedding found for excerpt {excerpt_id}\")\n               return False\n\n       return True\n   ```2. Clear embedding cache and regenerate:\n\n```python\n   import os\n   from app.definitions import CACHE_DIR\n\n   def clear_embedding_cache():\n       cache_path = os.path.join(CACHE_DIR, \"embedding_cache.json\")\n       if os.path.exists(cache_path):\n           os.remove(cache_path)\n           print(f\"Removed embedding cache at {cache_path}\")\n   ```\n\n3. Check embedding dimensions:\n\n```python\n   def verify_embedding_dimensions(rag, expected_dim=1536):\n       # Get a sample embedding\n       results = rag.embeddings_db.query(query=None, top_k=1)\n       if not results:\n           print(\"No embeddings found\")\n           return False\n\n       sample_id = results[0][\"__id__\"]\n       sample_vector = results[0][\"__vector__\"]\n\n       actual_dim = len(sample_vector)\n       if actual_dim != expected_dim:\n           print(f\"Dimension mismatch: expected {expected_dim}, got {actual_dim}\")\n           return False\n\n       return True\n   ```\n\n---\n\n### **5. Knowledge Graph Issues**\n\n**Symptom: Missing or incorrect entities and relationships**\n\n*Potential Causes:*\n- Entity extraction failures\n- Graph storage issues\n- Prompt engineering problems\n\n*Solutions:*\n1. Check entity extraction prompt:\n\n```python\n   from app.prompts import get_extract_entities_prompt\n\n   # Print the prompt for a sample excerpt\n   sample_excerpt = \"Your sample text here\"\n   print(get_extract_entities_prompt(sample_excerpt))\n   ```\n\n2. Manually test entity extraction:\n\n```python\n   from app.openai_llm import OpenAiLlm\n   from app.prompts import get_extract_entities_prompt\n\n   llm = OpenAiLlm()\n   sample_excerpt = \"Your sample text here\"\n   prompt = get_extract_entities_prompt(sample_excerpt)\n   result = llm.get_completion(prompt)\n   print(result)\n   ```\n\n3. Verify graph structure:",
        "summary": "The excerpt addresses specific troubleshooting steps related to embedding verification and knowledge graph entity extraction, contributing to the broader context of the SmolRAG troubleshooting guide by offering targeted solutions for common issues users may face in the retrieval-augmented generation system.",
        "indexed_at": 1745030046.984113
    },
    "excerpt_id_cb0e5d0ad627c9ecd6e0fb7b4ac2bb43": {
        "doc_id": "doc_527d38dfafb42e0277ca302149af6bdb",
        "doc_order_index": 7,
        "excerpt": "enAiLlm()\n   sample_excerpt = \"Your sample text here\"\n   prompt = get_extract_entities_prompt(sample_excerpt)\n   result = llm.get_completion(prompt)\n   print(result)\n   ```\n\n3. Verify graph structure:```python\n   def inspect_graph(rag):\n       print(f\"Graph has {rag.graph.graph.number_of_nodes()} nodes and {rag.graph.graph.number_of_edges()} edges\")\n\n       # Print some sample nodes\n       for i, node in enumerate(list(rag.graph.graph.nodes())[:5]):\n           print(f\"Node {i}: {node}\")\n           print(f\"  Attributes: {rag.graph.graph.nodes[node]}\")\n\n       # Print some sample edges\n       for i, edge in enumerate(list(rag.graph.graph.edges())[:5]):\n           print(f\"Edge {i}: {edge}\")\n           print(f\"  Attributes: {rag.graph.graph.edges[edge]}\")\n   ```",
        "summary": "The excerpt illustrates specific methods for inspecting and validating the knowledge graph within the broader SmolRAG troubleshooting guide, emphasizing the importance of entity extraction and graph structure verification in resolving system issues.",
        "indexed_at": 1745030046.9841769
    },
    "excerpt_id_fcc70198270a02757f7c7194e7f32c25": {
        "doc_id": "doc_527d38dfafb42e0277ca302149af6bdb",
        "doc_order_index": 8,
        "excerpt": "rint some sample edges\n       for i, edge in enumerate(list(rag.graph.graph.edges())[:5]):\n           print(f\"Edge {i}: {edge}\")\n           print(f\"  Attributes: {rag.graph.graph.edges[edge]}\")\n   ```**Symptom: Knowledge graph query returns unexpected results**\n\n*Potential Causes:*\n- Keyword extraction issues\n- Graph traversal problems\n- Ranking issues\n\n*Solutions:*\n1. Debug keyword extraction:\n\n```python\n   from app.prompts import get_high_low_level_keywords_prompt\n   from app.openai_llm import OpenAiLlm\n   from app.utilities import extract_json_from_text\n\n   llm = OpenAiLlm()\n   query = \"Your query here\"\n   prompt = get_high_low_level_keywords_prompt(query)\n   result = llm.get_completion(prompt)\n   keyword_data = extract_json_from_text(result)\n   print(keyword_data)\n   ```\n\n2. Trace graph traversal:\n\n```python\n   def trace_kg_query(rag, query):\n       # Get keywords\n       prompt = rag.prompts.get_high_low_level_keywords_prompt(query)\n       result = rag.llm.get_completion(prompt)\n       keyword_data = rag.utilities.extract_json_from_text(result)\n\n       print(f\"Low-level keywords: {keyword_data.get('low_level_keywords', [])}\")\n       print(f\"High-level keywords: {keyword_data.get('high_level_keywords', [])}\")\n\n       # Trace entity search\n       ll_keywords = keyword_data.get(\"low_level_keywords\", [])\n       if ll_keywords:\n           ll_embedding = rag.llm.get_embedding(ll_keywords)\n           ll_results = rag.entities_db.query(query=ll_embedding, top_k=5)\n           print(\"Top entity matches:\")\n           for r in ll_results:\n               print(f\"  {r['__entity_name__']} (score: {r['__score__']:.4f})\")\n\n       # Trace relationship search\n       hl_keywords = keyword_data.get(\"high_level_keywords\", [])\n       if hl_keywords:\n           hl_embedding = rag.llm.get_embedding(hl_keywords)\n           hl_results = rag.relationships_db.query(query=hl_embedding, top_k=5)\n           print(\"Top relationship matches:\")\n           for r in hl_results:\n               print(f\"  {r['__source__']} -> {r['__target__']} (score: {r['__score__']:.4f})\")\n   ```\n\n3. Adjust ranking parameters:",
        "summary": "The excerpt addresses troubleshooting methods for unexpected results from knowledge graph queries in SmolRAG, which is part of a broader troubleshooting guide aimed at helping users resolve various system issues related to document ingestion, querying, and overall operation.",
        "indexed_at": 1745030046.984241
    },
    "excerpt_id_58afd38ac61f13786dbc05d2f0c7bf8f": {
        "doc_id": "doc_527d38dfafb42e0277ca302149af6bdb",
        "doc_order_index": 9,
        "excerpt": "print(\"Top relationship matches:\")\n           for r in hl_results:\n               print(f\"  {r['__source__']} -> {r['__target__']} (score: {r['__score__']:.4f})\")\n   ```\n\n3. Adjust ranking parameters:```python\n   # Modify the ranking logic in your custom SmolRag subclass\n   class CustomSmolRag(SmolRag):\n       def _get_entities_from_relationships(self, kg_dataset):\n           # ... existing code ...\n\n           # Adjust ranking to prioritize degree more than before\n           data = sorted(data, key=lambda x: (x[\"rank\"] * 2, x[\"weight\"]), reverse=True)\n\n           # ... rest of the method ...\n   ```",
        "summary": "The excerpt demonstrates the implementation of a ranking adjustment within the SmolRAG system's knowledge graph to improve the prioritization of entities based on their relationships, which relates to the broader context of the troubleshooting guide by highlighting specific strategies for enhancing query results and system performance.",
        "indexed_at": 1745030046.9843042
    },
    "excerpt_id_cbb4e8dad766e2f663005e81522d4b82": {
        "doc_id": "doc_527d38dfafb42e0277ca302149af6bdb",
        "doc_order_index": 10,
        "excerpt": "         # Adjust ranking to prioritize degree more than before\n           data = sorted(data, key=lambda x: (x[\"rank\"] * 2, x[\"weight\"]), reverse=True)\n\n           # ... rest of the method ...\n   ```---\n\n### **6. Query Issues**\n\n**Symptom: Queries return irrelevant or incorrect information**\n\n*Potential Causes:*\n- Poor document quality\n- Inappropriate query type\n- Embedding quality issues\n- Prompt engineering problems\n\n*Solutions:*\n1. Try different query types:\n\n```python\n   query = \"Your query here\"\n\n   # Try all query types\n   standard_result = rag.query(query)\n   local_kg_result = rag.local_kg_query(query)\n   global_kg_result = rag.global_kg_query(query)\n   hybrid_kg_result = rag.hybrid_kg_query(query)\n   mix_result = rag.mix_query(query)\n\n   # Compare results\n   print(\"Standard Query Result:\", standard_result)\n   print(\"Local KG Query Result:\", local_kg_result)\n   print(\"Global KG Query Result:\", global_kg_result)\n   print(\"Hybrid KG Query Result:\", hybrid_kg_result)\n   print(\"Mix Query Result:\", mix_result)\n   ```\n\n2. Inspect retrieved excerpts:\n\n```python\n   def inspect_query_excerpts(rag, query):\n       embedding = rag.llm.get_embedding(query)\n       embedding_array = np.array(embedding)\n       results = rag.embeddings_db.query(query=embedding_array, top_k=5)\n\n       print(f\"Top {len(results)} excerpts for query: '{query}'\")\n       for i, result in enumerate(results):\n           excerpt_id = result[\"__id__\"]\n           score = result[\"__score__\"]\n           excerpt_data = rag.excerpt_kv.get_by_key(excerpt_id)\n\n           print(f\"\\nExcerpt {i+1} (ID: {excerpt_id}, Score: {score:.4f}):\")\n           print(f\"Summary: {excerpt_data['summary']}\")\n           print(f\"Excerpt: {excerpt_data['excerpt'][:200]}...\")\n   ```\n\n3. Adjust similarity threshold:",
        "summary": "The excerpt discusses how to improve query results in SmolRAG by adjusting ranking mechanisms and experimenting with different query types, which is vital for effectively resolving broader issues related to irrelevant or incorrect information returned by the system, as outlined in the troubleshooting guide.",
        "indexed_at": 1745030046.9843671
    },
    "excerpt_id_38c732d43cab759a55244eaa09fa38a6": {
        "doc_id": "doc_527d38dfafb42e0277ca302149af6bdb",
        "doc_order_index": 11,
        "excerpt": "D: {excerpt_id}, Score: {score:.4f}):\")\n           print(f\"Summary: {excerpt_data['summary']}\")\n           print(f\"Excerpt: {excerpt_data['excerpt'][:200]}...\")\n   ```\n\n3. Adjust similarity threshold:```python\n   # Modify the threshold in your custom SmolRag subclass\n   class CustomSmolRag(SmolRag):\n       def _get_query_excerpts(self, text):\n           embedding = self.llm.get_embedding(text)\n           embedding_array = np.array(embedding)\n           # Increase threshold for higher precision\n           results = self.embeddings_db.query(query=embedding_array, top_k=5, better_than_threshold=0.05)\n           excerpts = [self.excerpt_kv.get_by_key(result[\"__id__\"]) for result in results]\n           excerpts = truncate_list_by_token_size(excerpts, get_text_for_row=lambda x: x[\"excerpt\"], max_token_size=4000)\n           return excerpts\n   ```",
        "summary": "The excerpt discusses a method for adjusting the similarity threshold in the SmolRAG system's query process, specifically aimed at enhancing precision by filtering results based on a defined threshold, thereby contributing to the broader troubleshooting framework outlined in the guide for optimizing query performance and addressing potential inaccuracies.",
        "indexed_at": 1745030046.98443
    },
    "excerpt_id_2cca7c90cc52ed8a7fc9fa49eb39d02c": {
        "doc_id": "doc_527d38dfafb42e0277ca302149af6bdb",
        "doc_order_index": 12,
        "excerpt": "key(result[\"__id__\"]) for result in results]\n           excerpts = truncate_list_by_token_size(excerpts, get_text_for_row=lambda x: x[\"excerpt\"], max_token_size=4000)\n           return excerpts\n   ```**Symptom: Queries are slow**\n\n*Potential Causes:*\n- Large vector database\n- Complex knowledge graph\n- API latency\n- Resource constraints\n\n*Solutions:*\n1. Implement query caching:\n\n```python\n   import hashlib\n   import json\n   import os\n\n   class QueryCache:\n       def __init__(self, cache_dir):\n           self.cache_dir = cache_dir\n           os.makedirs(cache_dir, exist_ok=True)\n\n       def get_cache_key(self, query_text, query_type):\n           key = f\"{query_text}_{query_type}\"\n           return hashlib.md5(key.encode()).hexdigest()\n\n       def get_from_cache(self, query_text, query_type):\n           key = self.get_cache_key(query_text, query_type)\n           cache_file = os.path.join(self.cache_dir, f\"{key}.json\")\n\n           if os.path.exists(cache_file):\n               with open(cache_file, 'r') as f:\n                   return json.load(f)\n           return None\n\n       def save_to_cache(self, query_text, query_type, result):\n           key = self.get_cache_key(query_text, query_type)\n           cache_file = os.path.join(self.cache_dir, f\"{key}.json\")\n\n           with open(cache_file, 'w') as f:\n               json.dump(result, f)\n   ```\n\n2. Optimize vector search:",
        "summary": "The excerpt discusses solutions for addressing slow query performance in the SmolRAG system, specifically focusing on implementing query caching and optimizing vector search, which ties into the broader context of the troubleshooting guide by providing targeted strategies to enhance system efficiency amid various potential causes for performance issues.",
        "indexed_at": 1745030046.9844952
    },
    "excerpt_id_450b2f19c98596bfc6089aeec9514ca4": {
        "doc_id": "doc_527d38dfafb42e0277ca302149af6bdb",
        "doc_order_index": 13,
        "excerpt": "ext, query_type)\n           cache_file = os.path.join(self.cache_dir, f\"{key}.json\")\n\n           with open(cache_file, 'w') as f:\n               json.dump(result, f)\n   ```\n\n2. Optimize vector search:```python\n   # Use approximate nearest neighbor search for larger datasets\n   # This is a simplified example - in practice, you would use a library like FAISS\n   def approximate_vector_search(vectors, query_vector, top_k=5):\n       # Randomly sample a subset of vectors for initial filtering\n       sample_size = min(1000, len(vectors))\n       sample_indices = random.sample(range(len(vectors)), sample_size)\n       sample_vectors = [vectors[i] for i in sample_indices]\n\n       # Compute similarities for the sample\n       similarities = [np.dot(v, query_vector) / (np.linalg.norm(v) * np.linalg.norm(query_vector)) for v in sample_vectors]\n\n       # Get top candidates from the sample\n       top_sample_indices = np.argsort(similarities)[-top_k*2:]\n       top_candidates = [sample_indices[i] for i in top_sample_indices]\n\n       # Compute exact similarities for the top candidates\n       candidate_vectors = [vectors[i] for i in top_candidates]\n       candidate_similarities = [np.dot(v, query_vector) / (np.linalg.norm(v) * np.linalg.norm(query_vector)) for v in candidate_vectors]\n\n       # Get final top-k\n       top_k_indices = np.argsort(candidate_similarities)[-top_k:]\n       return [top_candidates[i] for i in top_k_indices]\n   ```",
        "summary": "The excerpt illustrates a specific solution for optimizing vector search by employing approximate nearest neighbor techniques, which contributes to the broader troubleshooting context of the SmolRAG guide by addressing performance issues related to slow query responses in larger datasets.",
        "indexed_at": 1745030046.98456
    },
    "excerpt_id_fe5d529dab986843e6821f4c56079a32": {
        "doc_id": "doc_527d38dfafb42e0277ca302149af6bdb",
        "doc_order_index": 14,
        "excerpt": "(query_vector)) for v in candidate_vectors]\n\n       # Get final top-k\n       top_k_indices = np.argsort(candidate_similarities)[-top_k:]\n       return [top_candidates[i] for i in top_k_indices]\n   ```3. Use a simpler query type for time-sensitive applications:\n\n```python\n   def fast_query(rag, query_text):\n       # Use the standard vector search query which is typically faster\n       return rag.query(query_text)\n   ```\n\n**Symptom: Out of memory errors during queries**\n\n*Potential Causes:*\n- Large context size\n- Memory leaks\n- Insufficient system resources\n\n*Solutions:*\n1. Limit context size:\n\n```python\n   # Modify the context truncation in your custom SmolRag subclass\n   class CustomSmolRag(SmolRag):\n       def _get_excerpt_context(self, excerpts):\n           # Limit to fewer excerpts\n           excerpts = excerpts[:3]\n\n           context = \"\"\n           for excerpt in excerpts:\n               context += inspect.cleandoc(f\"\"\"\n                   ## Excerpt\n\n                   {excerpt[\"excerpt\"]}\n\n                   ## Summary\n\n                   {excerpt[\"summary\"]} \n               \"\"\")\n               context += \"\\n\\n\"\n\n           return context\n   ```\n\n2. Implement garbage collection:\n\n```python\n   import gc\n\n   def memory_efficient_query(rag, query_text):\n       # Force garbage collection before query\n       gc.collect()\n\n       result = rag.query(query_text)\n\n       # Force garbage collection after query\n       gc.collect()\n\n       return result\n   ```\n\n3. Monitor memory usage:\n\n```python\n   import psutil\n\n   def memory_safe_query(rag, query_text, max_memory_percent=90):\n       # Check memory before query\n       memory_percent = psutil.virtual_memory().percent\n       if memory_percent > max_memory_percent:\n           return \"System is low on memory. Please try again later.\"\n\n       # Proceed with query\n       return rag.query(query_text)\n   ```\n\n---\n\n### **7. API Issues**\n\n**Symptom: OpenAI API errors**\n\n*Potential Causes:*\n- Invalid API key\n- Rate limiting\n- Quota exceeded\n- API service disruption\n\n*Solutions:*\n1. Verify API key:",
        "summary": "The excerpt discusses solutions to memory management and API error issues in the SmolRAG system, which aligns with the broader context of the troubleshooting guide by providing specific strategies to mitigate common sources of operational challenges faced by users.",
        "indexed_at": 1745030046.984628
    },
    "excerpt_id_30d921e9ed8b86da0f8b9366dfbaa2a7": {
        "doc_id": "doc_527d38dfafb42e0277ca302149af6bdb",
        "doc_order_index": 15,
        "excerpt": "xt)\n   ```\n\n---\n\n### **7. API Issues**\n\n**Symptom: OpenAI API errors**\n\n*Potential Causes:*\n- Invalid API key\n- Rate limiting\n- Quota exceeded\n- API service disruption\n\n*Solutions:*\n1. Verify API key:```python\n   import os\n   from openai import OpenAI\n\n   def verify_openai_api_key():\n       api_key = os.environ.get(\"OPENAI_API_KEY\")\n       if not api_key:\n           print(\"API key not found in environment variables\")\n           return False\n\n       client = OpenAI(api_key=api_key)\n       try:\n           # Make a simple API call to verify the key\n           response = client.embeddings.create(\n               model=\"text-embedding-3-small\",\n               input=\"test\"\n           )\n           print(\"API key is valid\")\n           return True\n       except Exception as e:\n           print(f\"API key verification failed: {e}\")\n           return False\n   ```",
        "summary": "The excerpt discusses potential API issues related to the OpenAI integration within SmolRAG, specifically focusing on common errors like invalid API keys and rate limiting, which are essential for troubleshooting and maintaining the system's functionality as outlined in the broader troubleshooting guide.",
        "indexed_at": 1745030046.9846961
    },
    "excerpt_id_fa24916a2f72f3ae233e5d1977ee1ae2": {
        "doc_id": "doc_527d38dfafb42e0277ca302149af6bdb",
        "doc_order_index": 16,
        "excerpt": "input=\"test\"\n           )\n           print(\"API key is valid\")\n           return True\n       except Exception as e:\n           print(f\"API key verification failed: {e}\")\n           return False\n   ```2. Implement rate limiting:\n\n```python\n   import time\n\n   class RateLimitedOpenAiLlm:\n       def __init__(self, base_llm, requests_per_minute=60):\n           self.base_llm = base_llm\n           self.min_seconds_per_request = 60 / requests_per_minute\n           self.last_request_time = 0\n\n       def get_embedding(self, text):\n           self._wait_for_rate_limit()\n           return self.base_llm.get_embedding(text)\n\n       def get_completion(self, prompt, context=None, use_cache=True):\n           self._wait_for_rate_limit()\n           return self.base_llm.get_completion(prompt, context, use_cache)\n\n       def _wait_for_rate_limit(self):\n           current_time = time.time()\n           time_since_last_request = current_time - self.last_request_time\n\n           if time_since_last_request < self.min_seconds_per_request:\n               sleep_time = self.min_seconds_per_request - time_since_last_request\n               time.sleep(sleep_time)\n\n           self.last_request_time = time.time()\n   ```\n\n3. Implement exponential backoff for retries:",
        "summary": "The excerpt details specific implementation strategies for verifying the OpenAI API key and managing request rates, which aligns with the broader troubleshooting context by providing actionable solutions to API-related issues discussed in the guide.",
        "indexed_at": 1745030046.984767
    },
    "excerpt_id_6eb845511a3798c85225934f19cae61f": {
        "doc_id": "doc_527d38dfafb42e0277ca302149af6bdb",
        "doc_order_index": 17,
        "excerpt": "me = self.min_seconds_per_request - time_since_last_request\n               time.sleep(sleep_time)\n\n           self.last_request_time = time.time()\n   ```\n\n3. Implement exponential backoff for retries:```python\n   import time\n   import random\n\n   def retry_with_exponential_backoff(\n       func,\n       initial_delay=1,\n       exponential_base=2,\n       jitter=True,\n       max_retries=10,\n       errors=(Exception,),\n   ):\n       \"\"\"Retry a function with exponential backoff.\"\"\"\n\n       def wrapper(*args, **kwargs):\n           # Initialize variables\n           num_retries = 0\n           delay = initial_delay\n\n           # Loop until a successful response or max_retries is hit\n           while True:\n               try:\n                   return func(*args, **kwargs)\n\n               # Retry on specified errors\n               except errors as e:\n                   num_retries += 1\n\n                   # Check if max retries has been reached\n                   if num_retries > max_retries:\n                       raise Exception(f\"Maximum number of retries ({max_retries}) exceeded.\")\n\n                   # Increment the delay\n                   delay *= exponential_base * (1 + jitter * random.random())\n\n                   # Sleep for the delay\n                   time.sleep(delay)\n\n                   # Log the retry\n                   print(f\"Retry {num_retries}/{max_retries} after {delay:.2f} seconds delay\")\n\n       return wrapper\n   ```",
        "summary": "The excerpt illustrates an implementation detail within the broader context of the SmolRAG troubleshooting guide, specifically addressing how to handle OpenAI API rate limits and errors through exponential backoff retries, thereby enhancing the reliability and efficiency of API interactions in the system.",
        "indexed_at": 1745030046.984837
    },
    "excerpt_id_3720213ae71a08acca1f7e46b7864f3e": {
        "doc_id": "doc_527d38dfafb42e0277ca302149af6bdb",
        "doc_order_index": 18,
        "excerpt": "ay\n                   time.sleep(delay)\n\n                   # Log the retry\n                   print(f\"Retry {num_retries}/{max_retries} after {delay:.2f} seconds delay\")\n\n       return wrapper\n   ```**Symptom: FastAPI errors**\n\n*Potential Causes:*\n- Incorrect request format\n- Server configuration issues\n- Resource constraints\n\n*Solutions:*\n1. Validate request format:\n\n```python\n   from fastapi import FastAPI, HTTPException\n   from pydantic import BaseModel, validator\n\n   class QueryRequest(BaseModel):\n       text: str\n       query_type: str = \"standard\"\n\n       @validator(\"text\")\n       def text_must_not_be_empty(cls, v):\n           if not v.strip():\n               raise ValueError(\"Query text cannot be empty\")\n           return v\n\n       @validator(\"query_type\")\n       def query_type_must_be_valid(cls, v):\n           valid_types = [\"standard\", \"local_kg\", \"global_kg\", \"hybrid_kg\", \"mix\"]\n           if v not in valid_types:\n               raise ValueError(f\"Invalid query_type: {v}. Valid types are: {', '.join(valid_types)}\")\n           return v\n   ```\n\n2. Implement proper error handling:\n\n```python\n   @app.post(\"/query\")\n   async def query_endpoint(request: QueryRequest):\n       try:\n           # Process query\n           query_func = query_map.get(request.query_type.lower())\n           result = query_func(request.text)\n           return {\"result\": result}\n       except Exception as e:\n           # Log the error\n           logger.error(f\"Error processing query: {e}\")\n           # Return a user-friendly error message\n           raise HTTPException(status_code=500, detail=f\"An error occurred while processing your query: {str(e)}\")\n   ```\n\n3. Implement request timeouts:",
        "summary": "The excerpt provides specific troubleshooting strategies for addressing FastAPI errors within the broader context of the SmolRAG Troubleshooting Guide, highlighting the importance of validating request formats, implementing error handling, and managing request timeouts to ensure the system operates smoothly.",
        "indexed_at": 1745030046.984909
    },
    "excerpt_id_1123c47dc960c83e906ef0521acbf692": {
        "doc_id": "doc_527d38dfafb42e0277ca302149af6bdb",
        "doc_order_index": 19,
        "excerpt": "        # Return a user-friendly error message\n           raise HTTPException(status_code=500, detail=f\"An error occurred while processing your query: {str(e)}\")\n   ```\n\n3. Implement request timeouts:```python\n   from fastapi import FastAPI, HTTPException, BackgroundTasks\n   import asyncio\n\n   app = FastAPI()\n\n   async def process_query_with_timeout(query_text, query_type, timeout=30):\n       try:\n           # Run the query with a timeout\n           result = await asyncio.wait_for(\n               asyncio.to_thread(query_map[query_type], query_text),\n               timeout=timeout\n           )\n           return result\n       except asyncio.TimeoutError:\n           raise HTTPException(status_code=504, detail=\"Query processing timed out\")\n\n   @app.post(\"/query\")\n   async def query_endpoint(request: QueryRequest):\n       result = await process_query_with_timeout(request.text, request.query_type)\n       return {\"result\": result}\n   ```",
        "summary": "The excerpt highlights the implementation of error handling and request timeouts in the FastAPI query endpoint, reinforcing the broader context of ensuring robust and user-friendly interactions within the SmolRAG troubleshooting framework.",
        "indexed_at": 1745030046.984979
    },
    "excerpt_id_f460391fbb913e0e360f66999d788989": {
        "doc_id": "doc_527d38dfafb42e0277ca302149af6bdb",
        "doc_order_index": 20,
        "excerpt": ")\n\n   @app.post(\"/query\")\n   async def query_endpoint(request: QueryRequest):\n       result = await process_query_with_timeout(request.text, request.query_type)\n       return {\"result\": result}\n   ```---\n\n### **8. Performance Issues**\n\n**Symptom: System becomes slower over time**\n\n*Potential Causes:*\n- Growing vector database\n- Expanding knowledge graph\n- Cache bloat\n- Memory leaks\n\n*Solutions:*\n1. Implement database pruning:\n\n```python\n   def prune_old_documents(rag, days_threshold=90):\n       \"\"\"Remove documents older than the threshold.\"\"\"\n       import time\n\n       current_time = time.time()\n       threshold_time = current_time - (days_threshold * 24 * 60 * 60)\n\n       # Get all documents\n       all_doc_ids = list(rag.doc_to_source_kv.data.keys())\n\n       for doc_id in all_doc_ids:\n           # Check if we have timestamp information\n           excerpt_ids = rag.doc_to_excerpt_kv.get_by_key(doc_id)\n           if not excerpt_ids:\n               continue\n\n           # Get the first excerpt to check its timestamp\n           excerpt_data = rag.excerpt_kv.get_by_key(excerpt_ids[0])\n           if not excerpt_data or \"indexed_at\" not in excerpt_data:\n               continue\n\n           # Check if the document is older than the threshold\n           if excerpt_data[\"indexed_at\"] < threshold_time:\n               print(f\"Removing old document: {doc_id}\")\n               rag.remove_document_by_id(doc_id)\n   ```\n\n2. Implement cache cleanup:\n\n```python\n   import os\n   import time\n\n   def clean_old_cache_files(cache_dir, days_threshold=30):\n       \"\"\"Remove cache files older than the threshold.\"\"\"\n       current_time = time.time()\n       threshold_time = current_time - (days_threshold * 24 * 60 * 60)\n\n       for filename in os.listdir(cache_dir):\n           file_path = os.path.join(cache_dir, filename)\n           if os.path.isfile(file_path):\n               file_mtime = os.path.getmtime(file_path)\n               if file_mtime < threshold_time:\n                   os.remove(file_path)\n                   print(f\"Removed old cache file: {file_path}\")\n   ```\n\n3. Monitor and optimize memory usage:",
        "summary": "The excerpt provides specific code examples for handling performance issues in the SmolRAG system, specifically addressing strategies like pruning old documents, cleaning up cache files, and optimizing memory usage, which align with the broader context of troubleshooting various operational challenges within the entire SmolRAG Troubleshooting Guide.",
        "indexed_at": 1745030046.9850502
    },
    "excerpt_id_3e82863c53e1d9f1a2c455e3b10d5c48": {
        "doc_id": "doc_527d38dfafb42e0277ca302149af6bdb",
        "doc_order_index": 21,
        "excerpt": "h)\n               if file_mtime < threshold_time:\n                   os.remove(file_path)\n                   print(f\"Removed old cache file: {file_path}\")\n   ```\n\n3. Monitor and optimize memory usage:```python\n   import psutil\n   import gc\n\n   def optimize_memory():\n       \"\"\"Force garbage collection and report memory usage.\"\"\"\n       # Get initial memory usage\n       initial_memory = psutil.Process().memory_info().rss / (1024 * 1024)  # MB\n\n       # Force garbage collection\n       gc.collect()\n\n       # Get memory usage after garbage collection\n       final_memory = psutil.Process().memory_info().rss / (1024 * 1024)  # MB\n\n       print(f\"Memory before: {initial_memory:.2f} MB\")\n       print(f\"Memory after: {final_memory:.2f} MB\")\n       print(f\"Memory freed: {initial_memory - final_memory:.2f} MB\")\n   ```",
        "summary": "The excerpt discusses memory optimization techniques, which relate to the broader context of the troubleshooting guide by emphasizing the importance of managing system resources to enhance the performance and stability of the SmolRAG retrieval-augmented generation system.",
        "indexed_at": 1745030046.9851189
    },
    "excerpt_id_f14c1300eef7ee3f8f678d652b5e2c17": {
        "doc_id": "doc_527d38dfafb42e0277ca302149af6bdb",
        "doc_order_index": 22,
        "excerpt": "* 1024)  # MB\n\n       print(f\"Memory before: {initial_memory:.2f} MB\")\n       print(f\"Memory after: {final_memory:.2f} MB\")\n       print(f\"Memory freed: {initial_memory - final_memory:.2f} MB\")\n   ```**Symptom: High CPU usage**\n\n*Potential Causes:*\n- Inefficient vector operations\n- Large batch processing\n- Excessive parallel processing\n- Background tasks\n\n*Solutions:*\n1. Profile CPU usage:\n\n```python\n   import cProfile\n   import pstats\n\n   def profile_function(func, *args, **kwargs):\n       profiler = cProfile.Profile()\n       profiler.enable()\n\n       result = func(*args, **kwargs)\n\n       profiler.disable()\n       stats = pstats.Stats(profiler).sort_stats('cumtime')\n       stats.print_stats(20)  # Print top 20 functions by cumulative time\n\n       return result\n\n   # Usage\n   profile_function(rag.query, \"What is SmolRAG?\")\n   ```\n\n2. Optimize vector operations:\n\n```python\n   import numpy as np\n\n   # Use vectorized operations instead of loops\n   def optimized_similarity(vectors, query_vector):\n       # Compute dot products in a single operation\n       dot_products = np.dot(vectors, query_vector)\n\n       # Compute norms in a single operation\n       vector_norms = np.linalg.norm(vectors, axis=1)\n       query_norm = np.linalg.norm(query_vector)\n\n       # Compute similarities\n       similarities = dot_products / (vector_norms * query_norm)\n\n       return similarities\n   ```\n\n3. Implement batch size control:\n\n```python\n   def process_with_controlled_batches(items, process_func, batch_size=100):\n       \"\"\"Process items in controlled batch sizes to manage CPU usage.\"\"\"\n       results = []\n\n       for i in range(0, len(items), batch_size):\n           batch = items[i:i+batch_size]\n           batch_results = process_func(batch)\n           results.extend(batch_results)\n\n           # Optional: Add a small delay between batches\n           time.sleep(0.1)\n\n       return results\n   ```\n\n**Symptom: Disk I/O bottlenecks**\n\n*Potential Causes:*\n- Frequent vector store saves\n- Large log files\n- Inefficient file operations\n- Slow storage media\n\n*Solutions:*\n1. Reduce save frequency:",
        "summary": "The excerpt details troubleshooting strategies for high CPU usage and disk I/O bottlenecks in the SmolRAG system, illustrating specific causes and solutions, which reflects the broader context of the guide's aim to help users efficiently diagnose and resolve operational issues within the retrieval-augmented generation framework.",
        "indexed_at": 1745030046.985225
    },
    "excerpt_id_01ca0248de3b39f386fb010c1c75727a": {
        "doc_id": "doc_527d38dfafb42e0277ca302149af6bdb",
        "doc_order_index": 23,
        "excerpt": "  ```\n\n**Symptom: Disk I/O bottlenecks**\n\n*Potential Causes:*\n- Frequent vector store saves\n- Large log files\n- Inefficient file operations\n- Slow storage media\n\n*Solutions:*\n1. Reduce save frequency:```python\n   class BufferedVectorStore:\n       def __init__(self, base_store, buffer_size=100):\n           self.base_store = base_store\n           self.buffer_size = buffer_size\n           self.buffer = []\n\n       def upsert(self, items):\n           self.buffer.extend(items)\n\n           if len(self.buffer) >= self.buffer_size:\n               self.base_store.upsert(self.buffer)\n               self.buffer = []\n               self.base_store.save()\n\n       def save(self):\n           if self.buffer:\n               self.base_store.upsert(self.buffer)\n               self.buffer = []\n           self.base_store.save()\n   ```",
        "summary": "The excerpt addresses strategies for reducing disk I/O bottlenecks in the SmolRAG system, specifically by suggesting a buffered approach to vector store saves, which is part of the broader troubleshooting guide aimed at enhancing the system's performance and reliability.",
        "indexed_at": 1745030046.985292
    },
    "excerpt_id_b6a3bf9520f31279c695c790576b2216": {
        "doc_id": "doc_527d38dfafb42e0277ca302149af6bdb",
        "doc_order_index": 24,
        "excerpt": "   self.base_store.save()\n\n       def save(self):\n           if self.buffer:\n               self.base_store.upsert(self.buffer)\n               self.buffer = []\n           self.base_store.save()\n   ```2. Implement log rotation:\n\n```python\n   import logging\n   from logging.handlers import RotatingFileHandler\n\n   def setup_rotating_logger(log_path, max_bytes=10485760, backup_count=5):\n       \"\"\"Set up a rotating logger to prevent large log files.\"\"\"\n       logger = logging.getLogger(\"smolrag\")\n       handler = RotatingFileHandler(\n           log_path,\n           maxBytes=max_bytes,\n           backupCount=backup_count\n       )\n       formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n       handler.setFormatter(formatter)\n       logger.addHandler(handler)\n       return logger\n   ```\n\n3. Use memory-mapped files for large datasets:",
        "summary": "The excerpt discusses techniques for managing data storage and logging in SmolRAG, specifically through buffer management and log rotation, which are vital for maintaining system performance and preventing issues related to data handling and resource consumption in the broader context of troubleshooting the system.",
        "indexed_at": 1745030046.9853592
    },
    "excerpt_id_03db7bd394b5c8f0cca7825a7bc0976e": {
        "doc_id": "doc_527d38dfafb42e0277ca302149af6bdb",
        "doc_order_index": 25,
        "excerpt": "sctime)s - %(name)s - %(levelname)s - %(message)s')\n       handler.setFormatter(formatter)\n       logger.addHandler(handler)\n       return logger\n   ```\n\n3. Use memory-mapped files for large datasets:```python\n   import numpy as np\n   import os\n\n   class MemmapVectorStore:\n       def __init__(self, file_path, dimensions, max_vectors=10000):\n           self.file_path = file_path\n           self.dimensions = dimensions\n           self.max_vectors = max_vectors\n           self.metadata_file = file_path + \".meta\"\n           self.initialize()\n\n       def initialize(self):\n           if not os.path.exists(self.file_path):\n               # Create an empty memory-mapped array\n               self.vectors = np.memmap(\n                   self.file_path,\n                   dtype=np.float32,\n                   mode='w+',\n                   shape=(self.max_vectors, self.dimensions)\n               )\n               self.count = 0\n               self.save_metadata()\n           else:\n               # Load metadata\n               self.load_metadata()\n               # Load existing memory-mapped array\n               self.vectors = np.memmap(\n                   self.file_path,\n                   dtype=np.float32,\n                   mode='r+',\n                   shape=(self.max_vectors, self.dimensions)\n               )\n\n       def save_metadata(self):\n           with open(self.metadata_file, 'w') as f:\n               f.write(str(self.count))\n\n       def load_metadata(self):\n           with open(self.metadata_file, 'r') as f:\n               self.count = int(f.read().strip())\n   ```",
        "summary": "The excerpt discusses the implementation of memory-mapped files for efficient storage and management of large datasets within the SmolRAG system, highlighting a performance optimization strategy that aligns with the document's broader focus on troubleshooting and enhancing system efficiency.",
        "indexed_at": 1745030046.9854238
    },
    "excerpt_id_d14d4b5fb9d1135b6a915fef1087d3b4": {
        "doc_id": "doc_527d38dfafb42e0277ca302149af6bdb",
        "doc_order_index": 26,
        "excerpt": "a_file, 'w') as f:\n               f.write(str(self.count))\n\n       def load_metadata(self):\n           with open(self.metadata_file, 'r') as f:\n               self.count = int(f.read().strip())\n   ```---\n\n### **9. General Troubleshooting Strategies**\n\nWhen you encounter issues that aren't covered by the specific scenarios above, these general troubleshooting strategies can help:\n\n**1. Check the Logs**\n\nSmolRAG logs important information to the `app/logs/` directory. Examining these logs can provide valuable insights into what's happening:\n\n```bash\n# View the main log file\ncat app/logs/main.log\n\n# Search for errors\ngrep \"ERROR\" app/logs/main.log\n\n# Follow the log in real-time\ntail -f app/logs/main.log\n```\n\n**2. Enable Debug Logging**\n\nFor more detailed information, you can enable debug logging:\n\n```python\n# In app/logger.py\ndef set_logger(log_file_name):\n    # ...\n    logger.setLevel(logging.DEBUG)  # Change from INFO to DEBUG\n    # ...\n```\n\n**3. Inspect Data Files**\n\nExamining the data files can help identify issues:\n\n```bash\n# List data files\nls -la app/data/\n\n# Check file sizes\ndu -h app/data/\n\n# Check if vector store files exist\nls -la app/data/embeddings.db\n```\n\n**4. Test Components in Isolation**\n\nWhen troubleshooting complex issues, it can be helpful to test components in isolation:\n\n```python\n# Test document loading\nfrom app.utilities import read_file\ncontent = read_file(\"app/input_docs/sample.md\")\nprint(f\"Loaded document with {len(content)} characters\")\n\n# Test chunking\nfrom app.chunking import preserve_markdown_code_excerpts\nchunks = preserve_markdown_code_excerpts(content, 2000, 200)\nprint(f\"Created {len(chunks)} chunks\")\n\n# Test embedding generation\nfrom app.openai_llm import OpenAiLlm\nllm = OpenAiLlm()\nembedding = llm.get_embedding(\"Test text\")\nprint(f\"Generated embedding with {len(embedding)} dimensions\")\n```\n\n**5. Create a Minimal Reproduction**\n\nCreating a minimal reproduction of the issue can help isolate the problem:",
        "summary": "The excerpt provides practical strategies for troubleshooting issues in SmolRAG, aligning with the broader context of the troubleshooting guide by offering systematic methods for diagnosing and resolving common problems encountered during system operation.",
        "indexed_at": 1745030046.985492
    },
    "excerpt_id_75e438adb9ff4c01e847c8be11bcc6e4": {
        "doc_id": "doc_527d38dfafb42e0277ca302149af6bdb",
        "doc_order_index": 27,
        "excerpt": "edding(\"Test text\")\nprint(f\"Generated embedding with {len(embedding)} dimensions\")\n```\n\n**5. Create a Minimal Reproduction**\n\nCreating a minimal reproduction of the issue can help isolate the problem:```python\n# Minimal SmolRAG setup\nfrom app.smol_rag import SmolRag\nimport os\nfrom app.definitions import DATA_DIR, CACHE_DIR, LOG_DIR\n\n# Clean start\nfor dir_path in [DATA_DIR, CACHE_DIR, LOG_DIR]:\n    os.makedirs(dir_path, exist_ok=True)\n    for file in os.listdir(dir_path):\n        file_path = os.path.join(dir_path, file)\n        if os.path.isfile(file_path):\n            os.remove(file_path)\n\n# Initialize with minimal configuration\nrag = SmolRag(excerpt_size=1000, overlap=100)\n\n# Test basic functionality\nrag.import_documents()\nresult = rag.query(\"Test query\")\nprint(result)\n```",
        "summary": "The excerpt illustrates a troubleshooting strategy involving the creation of a minimal reproduction setup for diagnosing issues with SmolRAG, highlighting the importance of isolating problems in the broader context of the troubleshooting guide's systematic approach to resolving various system-related challenges.",
        "indexed_at": 1745030046.985556
    },
    "excerpt_id_7026c9111f1e878a76710759253c04ae": {
        "doc_id": "doc_527d38dfafb42e0277ca302149af6bdb",
        "doc_order_index": 28,
        "excerpt": "(file_path)\n\n# Initialize with minimal configuration\nrag = SmolRag(excerpt_size=1000, overlap=100)\n\n# Test basic functionality\nrag.import_documents()\nresult = rag.query(\"Test query\")\nprint(result)\n```**6. Check System Resources**\n\nSystem resource constraints can cause various issues:\n\n```python\nimport psutil\n\ndef check_system_resources():\n    # CPU usage\n    cpu_percent = psutil.cpu_percent(interval=1)\n    print(f\"CPU Usage: {cpu_percent}%\")\n\n    # Memory usage\n    memory = psutil.virtual_memory()\n    print(f\"Memory Usage: {memory.percent}%\")\n    print(f\"Available Memory: {memory.available / (1024 * 1024):.2f} MB\")\n\n    # Disk usage\n    disk = psutil.disk_usage('/')\n    print(f\"Disk Usage: {disk.percent}%\")\n    print(f\"Free Disk Space: {disk.free / (1024 * 1024 * 1024):.2f} GB\")\n\n# Check resources\ncheck_system_resources()\n```\n\n---\n\n### **10. Conclusion**\n\nThis troubleshooting guide covers common issues you might encounter when working with SmolRAG. By following the diagnostic steps and implementing the suggested solutions, you should be able to resolve most problems and ensure smooth operation of your retrieval-augmented generation system.\n\nRemember that troubleshooting is often an iterative process. Start with the simplest possible explanation and solution, and gradually work your way toward more complex possibilities. Keep detailed notes about what you've tried and the results, as this can help identify patterns and root causes.\n\nIf you encounter issues not covered in this guide, consider:\n\n1. Checking the project's issue tracker for similar problems and solutions\n2. Consulting the community forums or discussion groups\n3. Reviewing the source code to understand the underlying behavior\n4. Reaching out to the project maintainers with a detailed description of the issue and steps to reproduce it\n\nWith persistence and systematic troubleshooting, most issues can be resolved, allowing you to take full advantage of SmolRAG's capabilities for retrieval-augmented generation.",
        "summary": "The excerpt provides an example of initializing the SmolRAG system and testing its functionality, which aligns with the troubleshooting guide's broader context of diagnosing and resolving issues encountered during its operation.",
        "indexed_at": 1745030046.9856231
    },
    "excerpt_id_dc80c8904c8ce4e245e92a5bec8771ed": {
        "doc_id": "doc_45a79dc2abea34f697412f4eb7307752",
        "doc_order_index": 0,
        "excerpt": "**Title: SmolRAG Excerpt Embeddings**\n\n---\n\n### **1. Introduction to Excerpt Embeddings**\n\nExcerpt embeddings are a fundamental component of SmolRAG's retrieval capabilities. These embeddings transform text chunks into high-dimensional vector representations that capture semantic meaning, enabling the system to find relevant content based on conceptual similarity rather than just keyword matching.\n\nIn SmolRAG, each document excerpt is embedded along with its summary to create a rich representation that captures both the specific content and its broader context. These embeddings power the semantic search functionality, allowing users to find information even when their queries don't exactly match the wording in the documents.\n\n---\n\n### **2. Embedding Generation Process**\n\nThe embedding generation process in SmolRAG follows these steps:\n\n1. **Excerpt Preparation**: After a document is chunked, each excerpt is paired with its summary.\n2. **Combined Content**: The excerpt and its summary are concatenated to form the content to be embedded.\n3. **API Call**: The combined content is sent to OpenAI's embedding API.\n4. **Vector Creation**: The API returns a high-dimensional vector (default: 1536 dimensions).\n5. **Storage**: The vector is stored in the NanoVectorStore along with metadata.\n\nThis process is performed for each excerpt during document ingestion, creating a comprehensive vector database that represents the semantic content of all documents.\n\n---\n\n### **3. Embedding Models and Dimensions**\n\nSmolRAG uses OpenAI's embedding models to generate vector representations:",
        "summary": "The excerpt outlines the foundational role of excerpt embeddings in SmolRAG's retrieval system, emphasizing how they enable semantic search by transforming text into high-dimensional vector representations that encapsulate both specific content and broader context, thereby enhancing the effectiveness of information retrieval within the document.",
        "indexed_at": 1745030046.9939892
    },
    "excerpt_id_c86849cd9a6f6eb952b7842d703f3170": {
        "doc_id": "doc_45a79dc2abea34f697412f4eb7307752",
        "doc_order_index": 1,
        "excerpt": "sive vector database that represents the semantic content of all documents.\n\n---\n\n### **3. Embedding Models and Dimensions**\n\nSmolRAG uses OpenAI's embedding models to generate vector representations:- **Default Model**: text-embedding-3-small is the default embedding model.\n- **Alternative Models**: The system can be configured to use other OpenAI embedding models.\n- **Dimensionality**: The default embedding dimension is 1536, which provides a good balance between expressiveness and efficiency.\n- **Configurable Dimensions**: The dimension can be adjusted based on specific needs and the embedding model used.\n\nThe choice of embedding model affects both the quality of retrieval and the computational resources required. The default model provides excellent performance for most use cases, but users can experiment with different models to optimize for their specific requirements.\n\n---\n\n### **4. Contextual Enhancement with Summaries**\n\nA key innovation in SmolRAG is the inclusion of excerpt summaries in the embedding process:\n\n- **Summary Integration**: Each excerpt's summary is included in the content to be embedded.\n- **Contextual Awareness**: This approach helps the embedding capture not just the excerpt's content but also its significance within the document.\n- **Improved Retrieval**: The enhanced embeddings lead to more contextually relevant search results.\n- **Coherence Preservation**: Summaries help maintain the narrative flow and logical connections between excerpts.\n\nBy embedding both the excerpt and its summary, SmolRAG creates vectors that represent a richer understanding of the content, leading to more accurate and contextually appropriate retrieval.\n\n---\n\n### **5. Vector Storage and Indexing**\n\nSmolRAG uses a lightweight vector database called NanoVectorStore to manage embeddings:",
        "summary": "The excerpt elaborates on the embedding generation process and contextual enhancements in SmolRAG, highlighting how the integration of summaries and the use of various embedding models contribute to improved semantic retrieval capabilities within the broader framework of the document's discussion on efficient information management and search optimization.",
        "indexed_at": 1745030046.9941819
    },
    "excerpt_id_9c6c3d629e2b94029b3f534beffe4780": {
        "doc_id": "doc_45a79dc2abea34f697412f4eb7307752",
        "doc_order_index": 2,
        "excerpt": ", leading to more accurate and contextually appropriate retrieval.\n\n---\n\n### **5. Vector Storage and Indexing**\n\nSmolRAG uses a lightweight vector database called NanoVectorStore to manage embeddings:- **Efficient Storage**: Embeddings are stored in a format optimized for fast retrieval.\n- **Metadata Association**: Each embedding is associated with metadata including document ID, excerpt ID, and timestamp.\n- **Indexing**: The store supports efficient similarity search through appropriate indexing.\n- **Persistence**: Embeddings are serialized to disk to persist between runs.\n- **CRUD Operations**: The store supports creating, reading, updating, and deleting embeddings.\n\nThe NanoVectorStore is designed to be simple yet effective, providing the necessary functionality without the complexity of larger vector database systems.\n\n---\n\n### **6. Similarity Search Mechanisms**\n\nSmolRAG's embedding-based similarity search works as follows:\n\n- **Query Embedding**: When a user submits a query, it is embedded using the same model as the excerpts.\n- **Similarity Computation**: The query embedding is compared to all excerpt embeddings using cosine similarity.\n- **Ranking**: Excerpts are ranked based on their similarity to the query.\n- **Threshold Filtering**: Results below a certain similarity threshold can be filtered out.\n- **Top-K Selection**: The top-k most similar excerpts are selected for further processing.\n\nThis similarity search mechanism is the foundation of SmolRAG's ability to find relevant information based on semantic meaning rather than exact keyword matches.\n\n---\n\n### **7. Entity and Relationship Embeddings**\n\nIn addition to excerpt embeddings, SmolRAG also generates embeddings for entities and relationships:\n\n- **Entity Embeddings**: Each entity extracted from the documents is embedded based on its name and description.\n- **Relationship Embeddings**: Relationships between entities are embedded based on their description and keywords.\n- **Separate Storage**: Entity and relationship embeddings are stored separately from excerpt embeddings.\n- **Cross-Referencing**: The system maintains connections between entities, relationships, and the excerpts they come from.",
        "summary": "The excerpt highlights the crucial role of the NanoVectorStore in managing embeddings efficiently, which is essential for SmolRAG's capability to perform semantic search and retrieve contextually relevant information from large document collections, ensuring the system's overall effectiveness and performance.",
        "indexed_at": 1745030046.994254
    },
    "excerpt_id_46387a7852ed874c1b3ab073c392b95b": {
        "doc_id": "doc_45a79dc2abea34f697412f4eb7307752",
        "doc_order_index": 3,
        "excerpt": "y and relationship embeddings are stored separately from excerpt embeddings.\n- **Cross-Referencing**: The system maintains connections between entities, relationships, and the excerpts they come from.These additional embeddings enable more sophisticated query types that leverage the knowledge graph structure while still benefiting from semantic similarity.\n\n---\n\n### **8. Embedding Caching and Optimization**\n\nTo improve performance and reduce API costs, SmolRAG implements several optimization strategies:\n\n- **Embedding Cache**: Previously computed embeddings are cached to avoid redundant API calls.\n- **Batch Processing**: Where possible, multiple items are embedded in a single API call.\n- **Incremental Updates**: When documents change, only the affected excerpts are re-embedded.\n- **Dimensionality Management**: The system balances embedding dimension with performance requirements.\n- **Error Handling**: Robust error handling ensures the system can continue even if embedding generation fails for some items.\n\nThese optimizations make SmolRAG efficient and cost-effective, especially when working with large document collections or frequent updates.\n\n---\n\n### **9. Embedding Quality and Evaluation**\n\nThe quality of embeddings directly affects retrieval performance. SmolRAG addresses this through:\n\n- **High-Quality Models**: Using state-of-the-art embedding models from OpenAI.\n- **Contextual Enhancement**: Including summaries to improve embedding quality.\n- **Threshold Tuning**: Adjustable similarity thresholds to control precision vs. recall.\n- **Evaluation Framework**: Tools for evaluating retrieval performance on test queries.\n- **Continuous Improvement**: The system is designed to easily incorporate new embedding models as they become available.\n\nRegular evaluation of embedding quality helps ensure that SmolRAG continues to provide accurate and relevant results as document collections grow and change.\n\n---\n\n### **10. Limitations and Considerations**\n\nWhile embeddings are powerful, they have some limitations to be aware of:",
        "summary": "The excerpt highlights the implementation of entity and relationship embeddings in SmolRAG, emphasizing their role in enhancing semantic search capabilities and illustrating the system's commitment to optimizing performance and retrieval accuracy within the broader context of the document's focus on embedding technology and retrieval mechanisms.",
        "indexed_at": 1745030046.994324
    },
    "excerpt_id_13f0a88ca4ce9d7111d35d577b03200f": {
        "doc_id": "doc_45a79dc2abea34f697412f4eb7307752",
        "doc_order_index": 4,
        "excerpt": "ovide accurate and relevant results as document collections grow and change.\n\n---\n\n### **10. Limitations and Considerations**\n\nWhile embeddings are powerful, they have some limitations to be aware of:- **Semantic Drift**: Very long or complex documents may not be perfectly represented by fixed-length vectors.\n- **Domain Specificity**: General-purpose embedding models may not capture domain-specific nuances.\n- **Language Limitations**: Performance may vary across different languages and technical domains.\n- **Computational Cost**: Generating and storing embeddings for large document collections requires significant resources.\n- **API Dependency**: Reliance on external embedding APIs introduces potential points of failure.\n\nUnderstanding these limitations helps users set appropriate expectations and implement mitigations where necessary.\n\n---\n\n### **11. Future Directions**\n\nThe field of text embeddings is rapidly evolving, and SmolRAG is designed to evolve with it:\n\n- **Model Upgrades**: Support for newer and more powerful embedding models as they become available.\n- **Local Embeddings**: Potential integration with local embedding models to reduce API dependency.\n- **Multi-Modal Support**: Possible extension to handle embeddings for images and other non-text content.\n- **Hierarchical Embeddings**: Exploration of hierarchical embedding approaches for better handling of long documents.\n- **Fine-Tuning**: Potential support for fine-tuned embedding models for specific domains.\n\nThese future directions will continue to enhance SmolRAG's ability to understand and retrieve information from diverse document collections.\n\n---\n\n### **12. Conclusion**\n\nExcerpt embeddings are a core component of SmolRAG's retrieval capabilities, transforming text into vector representations that capture semantic meaning. By embedding both excerpts and their summaries, SmolRAG creates rich representations that enable accurate and contextually relevant retrieval.",
        "summary": "The excerpt addresses the limitations and future directions of embedding technology in SmolRAG, highlighting the challenges faced and potential advancements that could enhance the system's retrieval capabilities within the broader context of the document's focus on semantic understanding and efficient information retrieval.",
        "indexed_at": 1745030046.994414
    },
    "excerpt_id_3e377a1f38aab6a7301bb88392d388d4": {
        "doc_id": "doc_45a79dc2abea34f697412f4eb7307752",
        "doc_order_index": 5,
        "excerpt": "nto vector representations that capture semantic meaning. By embedding both excerpts and their summaries, SmolRAG creates rich representations that enable accurate and contextually relevant retrieval.The combination of high-quality embeddings, efficient storage, and sophisticated similarity search mechanisms allows SmolRAG to find relevant information even when queries don't exactly match the wording in the documents. This semantic understanding is a key advantage of the RAG approach, enabling more natural and effective information retrieval.",
        "summary": "The excerpt highlights SmolRAG's effectiveness in retrieving information through semantic understanding by embedding excerpts and their summaries, which enhances retrieval accuracy and supports natural query processing within the broader framework of its embedding capabilities and similarity search mechanisms.",
        "indexed_at": 1745030046.994503
    },
    "excerpt_id_9b3e7699a2ad7cd3ed369e4a0e702290": {
        "doc_id": "doc_2c751da5b112adc2cd611bbd9bb377fa",
        "doc_order_index": 0,
        "excerpt": "**Title: SmolRAG Performance Considerations**\n\n---\n\n### **1. Introduction to Performance in SmolRAG**\n\nPerformance is a critical aspect of any RAG system, affecting response times, resource usage, and overall user experience. SmolRAG is designed to be lightweight and efficient, but like any system that processes and analyzes text data, it can face performance challenges as the volume of documents and queries increases.\n\nThis document explores the key performance considerations when using SmolRAG, including potential bottlenecks, optimization strategies, resource requirements, and scaling approaches. Understanding these considerations will help you optimize SmolRAG for your specific use case and ensure it performs well even as your document collection grows.\n\n---\n\n### **2. Key Performance Metrics**\n\nWhen evaluating and optimizing SmolRAG's performance, several key metrics should be considered:\n\n**Response Time Metrics**:\n- **Document Ingestion Time**: How long it takes to process and index new documents.\n- **Query Response Time**: How long it takes to process a query and return a response.\n- **Embedding Generation Time**: How long it takes to generate embeddings for documents and queries.\n\n**Resource Usage Metrics**:\n- **Memory Usage**: How much RAM is consumed by the system, particularly by the vector store and knowledge graph.\n- **Disk Usage**: How much storage space is required for the vector database, knowledge graph, and other data.\n- **CPU Usage**: How much processing power is required, especially during document ingestion and complex queries.\n- **API Calls**: How many calls are made to external APIs (e.g., OpenAI), affecting both cost and performance.\n\n**Quality Metrics**:\n- **Retrieval Precision**: How relevant the retrieved excerpts are to the query.\n- **Retrieval Recall**: How many of the relevant excerpts are actually retrieved.\n- **Response Quality**: How accurate and helpful the final responses are.",
        "summary": "The excerpt introduces the performance considerations essential for the SmolRAG system, emphasizing the importance of response times, resource usage, and key metrics to optimize its efficiency and user experience within the broader context of ensuring the system remains effective as document and query volumes increase.",
        "indexed_at": 1745030047.0087948
    },
    "excerpt_id_eb65f41dba3401c3f9ecff6a2b835fca": {
        "doc_id": "doc_2c751da5b112adc2cd611bbd9bb377fa",
        "doc_order_index": 1,
        "excerpt": "ant the retrieved excerpts are to the query.\n- **Retrieval Recall**: How many of the relevant excerpts are actually retrieved.\n- **Response Quality**: How accurate and helpful the final responses are.Monitoring these metrics will help you identify performance bottlenecks and evaluate the effectiveness of optimization strategies.\n\n---\n\n### **3. Document Ingestion Performance**\n\nDocument ingestion is often the most resource-intensive operation in SmolRAG, especially for large document collections:\n\n**Potential Bottlenecks**:\n- **Chunking**: Processing large documents into chunks can be CPU-intensive.\n- **Summarization**: Generating summaries for each chunk requires LLM API calls, which can be slow and costly.\n- **Embedding Generation**: Creating embeddings for each chunk requires API calls and can be time-consuming.\n- **Entity Extraction**: Extracting entities and relationships requires LLM API calls and can be slow.\n\n**Optimization Strategies**:\n- **Batch Processing**: Process documents in batches rather than all at once to manage memory usage.\n- **Incremental Updates**: Only process new or changed documents rather than reprocessing everything.\n- **Parallel Processing**: Use parallel processing for independent operations like embedding generation.\n- **Chunking Strategy**: Choose an appropriate chunking strategy based on your document types.\n- **Caching**: Implement caching for embeddings and LLM calls to avoid redundant processing.\n\n**Example: Batch Processing Implementation**:\n\n```python\nfrom app.smol_rag import SmolRag\nimport os\nfrom app.definitions import INPUT_DOCS_DIR\n\nrag = SmolRag()\n\n# Process documents in batches\nbatch_size = 5\nall_files = [os.path.join(INPUT_DOCS_DIR, f) for f in os.listdir(INPUT_DOCS_DIR) if os.path.isfile(os.path.join(INPUT_DOCS_DIR, f))]\n\nfor i in range(0, len(all_files), batch_size):\n    batch = all_files[i:i+batch_size]\n    for file in batch:\n        # Process each file in the batch\n        # (In a real implementation, you would need to modify SmolRAG to support processing individual files)\n    print(f\"Processed batch {i//batch_size + 1}/{(len(all_files) + batch_size - 1)//batch_size}\")\n```\n\n---\n\n### **4. Query Performance**",
        "summary": "The excerpt highlights the critical performance metrics and challenges related to document ingestion and query processing in SmolRAG, emphasizing the importance of monitoring these factors to identify bottlenecks and implement optimization strategies, which directly relates to the broader context of ensuring the system's efficiency and user experience as document collections grow.",
        "indexed_at": 1745030047.008872
    },
    "excerpt_id_e22b8da6dcf20fed5f472fe57b90902b": {
        "doc_id": "doc_2c751da5b112adc2cd611bbd9bb377fa",
        "doc_order_index": 2,
        "excerpt": " need to modify SmolRAG to support processing individual files)\n    print(f\"Processed batch {i//batch_size + 1}/{(len(all_files) + batch_size - 1)//batch_size}\")\n```\n\n---\n\n### **4. Query Performance**Query performance affects the user experience directly, as users expect quick responses to their questions:\n\n**Potential Bottlenecks**:\n- **Vector Search**: Searching through a large number of vectors can be slow.\n- **Knowledge Graph Queries**: Complex graph traversals can be computationally expensive.\n- **LLM Generation**: Generating the final response using the LLM can take time, especially with large contexts.\n- **Context Size**: Large contexts (many retrieved excerpts) can slow down LLM processing and increase costs.\n\n**Optimization Strategies**:\n- **Query Caching**: Cache query results to avoid reprocessing identical queries.\n- **Embedding Caching**: Cache query embeddings to avoid regenerating them.\n- **Query Type Selection**: Choose the appropriate query type based on the question and performance requirements.\n- **Context Limitation**: Limit the number of excerpts included in the context to reduce LLM processing time.\n- **Asynchronous Processing**: For non-interactive use cases, process queries asynchronously.\n\n**Example: Query Caching Implementation**:",
        "summary": "The excerpt highlights a specific implementation detail regarding batch processing in SmolRAG, emphasizing how efficient document handling can mitigate performance bottlenecks, which aligns with the broader context of optimizing overall system performance and user experience throughout the full document.",
        "indexed_at": 1745030047.008945
    },
    "excerpt_id_abcf57555611c91d669a12c878d8428b": {
        "doc_id": "doc_2c751da5b112adc2cd611bbd9bb377fa",
        "doc_order_index": 3,
        "excerpt": "xcerpts included in the context to reduce LLM processing time.\n- **Asynchronous Processing**: For non-interactive use cases, process queries asynchronously.\n\n**Example: Query Caching Implementation**:```python\nimport hashlib\nimport json\nimport os\n\nclass QueryCache:\n    def __init__(self, cache_dir):\n        self.cache_dir = cache_dir\n        os.makedirs(cache_dir, exist_ok=True)\n    \n    def get_cache_key(self, query_text, query_type):\n        # Create a unique key based on the query text and type\n        key = f\"{query_text}_{query_type}\"\n        return hashlib.md5(key.encode()).hexdigest()\n    \n    def get_from_cache(self, query_text, query_type):\n        key = self.get_cache_key(query_text, query_type)\n        cache_file = os.path.join(self.cache_dir, f\"{key}.json\")\n        \n        if os.path.exists(cache_file):\n            with open(cache_file, 'r') as f:\n                return json.load(f)\n        return None\n    \n    def save_to_cache(self, query_text, query_type, result):\n        key = self.get_cache_key(query_text, query_type)\n        cache_file = os.path.join(self.cache_dir, f\"{key}.json\")\n        \n        with open(cache_file, 'w') as f:\n            json.dump(result, f)\n\n# Usage\ncache = QueryCache(\"app/cache/query_cache\")\nquery_text = \"What is SmolRAG?\"\nquery_type = \"standard\"\n\n# Check cache first\ncached_result = cache.get_from_cache(query_text, query_type)\nif cached_result:\n    print(\"Using cached result\")\n    result = cached_result\nelse:\n    # Process query and cache result\n    result = rag.query(query_text)\n    cache.save_to_cache(query_text, query_type, result)\n```",
        "summary": "The excerpt details the implementation of a query caching mechanism in SmolRAG, highlighting its importance for optimizing query performance by reducing LLM processing time, which aligns with the broader context of the full document focused on various performance considerations and optimization strategies for the SmolRAG system.",
        "indexed_at": 1745030047.0090182
    },
    "excerpt_id_0da14f0f2868bc4e6d5add7c81a2957c": {
        "doc_id": "doc_2c751da5b112adc2cd611bbd9bb377fa",
        "doc_order_index": 4,
        "excerpt": "t:\n    print(\"Using cached result\")\n    result = cached_result\nelse:\n    # Process query and cache result\n    result = rag.query(query_text)\n    cache.save_to_cache(query_text, query_type, result)\n```---\n\n### **5. Memory Usage Optimization**\n\nMemory usage can be a significant constraint, especially for large document collections:\n\n**Memory-Intensive Components**:\n- **Vector Store**: Storing embeddings for all document chunks can consume significant memory.\n- **Knowledge Graph**: A large graph with many entities and relationships can be memory-intensive.\n- **Caches**: Caching embeddings and query results increases memory usage.\n\n**Optimization Strategies**:\n- **Lazy Loading**: Load vectors and graph components only when needed.\n- **Memory-Mapped Files**: Use memory-mapped files for vector storage to reduce RAM usage.\n- **Pruning**: Remove less important entities and relationships from the knowledge graph.\n- **Garbage Collection**: Explicitly trigger garbage collection after processing large batches.\n- **Resource Monitoring**: Implement monitoring to track memory usage and identify leaks.\n\n**Example: Memory-Efficient Vector Store**:",
        "summary": "The excerpt discusses memory usage optimization strategies for SmolRAG, highlighting important components and techniques to mitigate resource constraints, which are essential for ensuring the system's performance as detailed in the broader context of the document.",
        "indexed_at": 1745030047.009088
    },
    "excerpt_id_bb6ad6a345cbdf6df0cbdc4225260a25": {
        "doc_id": "doc_2c751da5b112adc2cd611bbd9bb377fa",
        "doc_order_index": 5,
        "excerpt": "icitly trigger garbage collection after processing large batches.\n- **Resource Monitoring**: Implement monitoring to track memory usage and identify leaks.\n\n**Example: Memory-Efficient Vector Store**:```python\nimport numpy as np\nimport os\n\nclass MemoryEfficientVectorStore:\n    def __init__(self, file_path, dimensions):\n        self.file_path = file_path\n        self.dimensions = dimensions\n        self.metadata = {}\n        self.initialize()\n    \n    def initialize(self):\n        if not os.path.exists(self.file_path):\n            # Create an empty memory-mapped array\n            self.vectors = np.memmap(self.file_path, dtype=np.float32, mode='w+', shape=(0, self.dimensions))\n        else:\n            # Load existing memory-mapped array\n            # We would need to store metadata separately to know the shape\n            # This is a simplified example\n            self.vectors = np.memmap(self.file_path, dtype=np.float32, mode='r+')\n    \n    def add_vector(self, id, vector):\n        # In a real implementation, we would resize the memmap and add the vector\n        # This is a simplified example\n        pass\n    \n    def query(self, query_vector, top_k=5):\n        # Compute similarities in batches to reduce memory usage\n        batch_size = 1000\n        similarities = []\n        \n        for i in range(0, len(self.vectors), batch_size):\n            batch = self.vectors[i:i+batch_size]\n            # Compute cosine similarity\n            batch_similarities = np.dot(batch, query_vector) / (np.linalg.norm(batch, axis=1) * np.linalg.norm(query_vector))\n            similarities.extend(batch_similarities)\n        \n        # Get top-k indices\n        top_indices = np.argsort(similarities)[-top_k:]\n        \n        # Return results\n        return [{\"id\": self.metadata[i][\"id\"], \"score\": similarities[i]} for i in top_indices]\n```",
        "summary": "The excerpt illustrates a specific optimization technique for memory usage in SmolRAG, highlighting the implementation of a memory-efficient vector store, which supports the broader context of the document by providing a practical solution to mitigate resource constraints during document processing and querying as system demands increase.",
        "indexed_at": 1745030047.009162
    },
    "excerpt_id_e329d73f72654b591f8c6832617f0209": {
        "doc_id": "doc_2c751da5b112adc2cd611bbd9bb377fa",
        "doc_order_index": 6,
        "excerpt": "p-k indices\n        top_indices = np.argsort(similarities)[-top_k:]\n        \n        # Return results\n        return [{\"id\": self.metadata[i][\"id\"], \"score\": similarities[i]} for i in top_indices]\n```---\n\n### **6. Disk Usage Optimization**\n\nDisk usage can become significant as your document collection grows:\n\n**Disk-Intensive Components**:\n- **Vector Database Files**: Storing embeddings for all document chunks.\n- **Knowledge Graph Files**: Storing the graph structure and properties.\n- **Key-Value Stores**: Storing metadata, mappings, and caches.\n- **Log Files**: Storing detailed logs, especially at DEBUG level.\n\n**Optimization Strategies**:\n- **Compression**: Use compression for stored data where appropriate.\n- **Selective Storage**: Only store essential information and derive other data as needed.\n- **Regular Cleanup**: Implement policies for cleaning up old or unused data.\n- **Efficient Serialization**: Use efficient serialization formats for stored data.\n- **Log Rotation**: Implement log rotation to prevent log files from growing too large.\n\n**Example: Log Rotation Configuration**:\n\n```python\nimport logging\nfrom logging.handlers import RotatingFileHandler\nimport os\n\ndef setup_logger(log_dir, log_file, max_size_mb=10, backup_count=5):\n    os.makedirs(log_dir, exist_ok=True)\n    log_path = os.path.join(log_dir, log_file)\n    \n    logger = logging.getLogger(\"smolrag\")\n    logger.setLevel(logging.INFO)\n    \n    # Create rotating file handler\n    handler = RotatingFileHandler(\n        log_path,\n        maxBytes=max_size_mb * 1024 * 1024,  # Convert MB to bytes\n        backupCount=backup_count\n    )\n    \n    formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n    handler.setFormatter(formatter)\n    \n    logger.addHandler(handler)\n    return logger\n\n# Usage\nlogger = setup_logger(\"app/logs\", \"smolrag.log\")\n```\n\n---\n\n### **7. API Usage Optimization**\n\nSmolRAG relies on OpenAI's API for embeddings and completions, which can be a significant cost and performance factor:",
        "summary": "The excerpt on disk usage optimization and API usage refinement highlights critical strategies for improving the performance of SmolRAG by efficiently managing data storage and minimizing external API dependencies, aligning with the broader context of performance considerations discussed in the full document.",
        "indexed_at": 1745030047.0092402
    },
    "excerpt_id_81db384c7c323402180915d5a9c65d67": {
        "doc_id": "doc_2c751da5b112adc2cd611bbd9bb377fa",
        "doc_order_index": 7,
        "excerpt": "up_logger(\"app/logs\", \"smolrag.log\")\n```\n\n---\n\n### **7. API Usage Optimization**\n\nSmolRAG relies on OpenAI's API for embeddings and completions, which can be a significant cost and performance factor:**API-Intensive Operations**:\n- **Embedding Generation**: Creating embeddings for document chunks and queries.\n- **Excerpt Summarization**: Generating summaries for each document chunk.\n- **Entity Extraction**: Extracting entities and relationships from document chunks.\n- **Response Generation**: Generating the final response to a query.\n\n**Optimization Strategies**:\n- **Caching**: Cache API responses to avoid redundant calls.\n- **Batching**: Batch API requests where possible to reduce overhead.\n- **Model Selection**: Use smaller, faster models when appropriate.\n- **Rate Limiting**: Implement rate limiting to avoid API rate limit errors.\n- **Retry Logic**: Implement robust retry logic for API failures.\n\n**Example: API Batching for Embeddings**:",
        "summary": "The excerpt on API usage optimization highlights the critical dependence of SmolRAG on OpenAI's API for performance, emphasizing strategies such as caching and batching to mitigate costs and enhance efficiency, connecting directly to the broader context of optimizing system performance discussed throughout the document.",
        "indexed_at": 1745030047.009315
    },
    "excerpt_id_b35b21c7869785d9ef1329f450f10a5d": {
        "doc_id": "doc_2c751da5b112adc2cd611bbd9bb377fa",
        "doc_order_index": 8,
        "excerpt": "n appropriate.\n- **Rate Limiting**: Implement rate limiting to avoid API rate limit errors.\n- **Retry Logic**: Implement robust retry logic for API failures.\n\n**Example: API Batching for Embeddings**:```python\nfrom openai import OpenAI\nimport numpy as np\n\nclass BatchEmbedder:\n    def __init__(self, api_key, model=\"text-embedding-3-small\", batch_size=100):\n        self.client = OpenAI(api_key=api_key)\n        self.model = model\n        self.batch_size = batch_size\n    \n    def embed_texts(self, texts):\n        \"\"\"Embed multiple texts in batches.\"\"\"\n        all_embeddings = []\n        \n        for i in range(0, len(texts), self.batch_size):\n            batch = texts[i:i+self.batch_size]\n            try:\n                response = self.client.embeddings.create(\n                    model=self.model,\n                    input=batch\n                )\n                batch_embeddings = [np.array(item.embedding) for item in response.data]\n                all_embeddings.extend(batch_embeddings)\n                print(f\"Embedded batch {i//self.batch_size + 1}/{(len(texts) + self.batch_size - 1)//self.batch_size}\")\n            except Exception as e:\n                print(f\"Error embedding batch: {e}\")\n                # In a real implementation, you would handle this error more gracefully\n                raise\n        \n        return all_embeddings\n\n# Usage\nembedder = BatchEmbedder(api_key=\"your-api-key\")\ntexts = [\"Text 1 to embed\", \"Text 2 to embed\", ..., \"Text N to embed\"]\nembeddings = embedder.embed_texts(texts)\n```",
        "summary": "The excerpt provides an example of API usage optimization in SmolRAG, specifically focusing on batch processing for embedding text, which is a critical component in the broader context of enhancing performance and efficiency in document ingestion and query response times as discussed throughout the full document.",
        "indexed_at": 1745030047.0093892
    },
    "excerpt_id_d819e633cca45f5553e358a312c96667": {
        "doc_id": "doc_2c751da5b112adc2cd611bbd9bb377fa",
        "doc_order_index": 9,
        "excerpt": "     return all_embeddings\n\n# Usage\nembedder = BatchEmbedder(api_key=\"your-api-key\")\ntexts = [\"Text 1 to embed\", \"Text 2 to embed\", ..., \"Text N to embed\"]\nembeddings = embedder.embed_texts(texts)\n```---\n\n### **8. Scaling Strategies**\n\nAs your document collection and query volume grow, you may need to scale SmolRAG:\n\n**Vertical Scaling**:\n- **Increase Memory**: Add more RAM to handle larger vector stores and knowledge graphs.\n- **Faster CPU**: Use a more powerful CPU to speed up processing.\n- **SSD Storage**: Use fast SSD storage for better I/O performance.\n\n**Horizontal Scaling**:\n- **Distributed Processing**: Split document ingestion across multiple machines.\n- **Sharded Vector Store**: Shard the vector store across multiple instances.\n- **Load Balancing**: Distribute queries across multiple API instances.\n- **Microservices Architecture**: Split functionality into separate services that can scale independently.\n\n**Cloud Deployment**:\n- **Containerization**: Use Docker to containerize SmolRAG for consistent deployment.\n- **Kubernetes**: Use Kubernetes for orchestration and scaling.\n- **Serverless**: For some components, consider serverless deployment for automatic scaling.\n\n**Example: Docker Compose for Scaling**:\n\n```yaml\nversion: '3'\n\nservices:\n  smolrag-api-1:\n    build: .\n    ports:\n      - \"8001:8000\"\n    volumes:\n      - ./app/data:/app/app/data\n      - ./app/input_docs:/app/app/input_docs\n    environment:\n      - OPENAI_API_KEY=${OPENAI_API_KEY}\n  \n  smolrag-api-2:\n    build: .\n    ports:\n      - \"8002:8000\"\n    volumes:\n      - ./app/data:/app/app/data\n      - ./app/input_docs:/app/app/input_docs\n    environment:\n      - OPENAI_API_KEY=${OPENAI_API_KEY}\n  \n  nginx:\n    image: nginx:latest\n    ports:\n      - \"8000:80\"\n    volumes:\n      - ./nginx.conf:/etc/nginx/conf.d/default.conf\n    depends_on:\n      - smolrag-api-1\n      - smolrag-api-2\n```\n\n---\n\n### **9. Monitoring and Profiling**\n\nTo optimize performance effectively, you need to monitor and profile SmolRAG:",
        "summary": "The excerpt discusses the implementation of a batch embedding process for text inputs in SmolRAG, connecting to the broader context of scaling strategies outlined in the document, which emphasizes the need for efficient data handling and performance optimization as document collections and query volumes increase.",
        "indexed_at": 1745030047.009464
    },
    "excerpt_id_a4f75c2d6d663c161d853c1243a60af5": {
        "doc_id": "doc_2c751da5b112adc2cd611bbd9bb377fa",
        "doc_order_index": 10,
        "excerpt": ".d/default.conf\n    depends_on:\n      - smolrag-api-1\n      - smolrag-api-2\n```\n\n---\n\n### **9. Monitoring and Profiling**\n\nTo optimize performance effectively, you need to monitor and profile SmolRAG:**Monitoring Metrics**:\n- **Response Times**: Track how long different operations take.\n- **Resource Usage**: Monitor CPU, memory, and disk usage.\n- **API Calls**: Track the number and cost of API calls.\n- **Error Rates**: Monitor errors and exceptions.\n\n**Profiling Tools**:\n- **Python Profilers**: Use cProfile or line_profiler to identify bottlenecks.\n- **Memory Profilers**: Use memory_profiler to track memory usage.\n- **Logging**: Implement detailed logging for performance-critical operations.\n- **Tracing**: Use OpenTelemetry or similar tools for distributed tracing.\n\n**Example: Simple Performance Monitoring**:",
        "summary": "The excerpt discusses the importance of monitoring and profiling in optimizing SmolRAG's performance, highlighting various metrics and tools that help identify bottlenecks and ensure efficient resource usage in the broader context of performance considerations detailed throughout the document.",
        "indexed_at": 1745030047.009535
    },
    "excerpt_id_a932de00c67d51e468546b00d37959d4": {
        "doc_id": "doc_2c751da5b112adc2cd611bbd9bb377fa",
        "doc_order_index": 11,
        "excerpt": ".\n- **Logging**: Implement detailed logging for performance-critical operations.\n- **Tracing**: Use OpenTelemetry or similar tools for distributed tracing.\n\n**Example: Simple Performance Monitoring**:```python\nimport time\nimport psutil\nimport logging\n\nclass PerformanceMonitor:\n    def __init__(self, logger=None):\n        self.logger = logger or logging.getLogger(\"performance\")\n        self.start_time = None\n        self.start_memory = None\n    \n    def start(self, operation_name):\n        self.operation_name = operation_name\n        self.start_time = time.time()\n        self.start_memory = psutil.Process().memory_info().rss / (1024 * 1024)  # MB\n        self.logger.info(f\"Starting {operation_name} - Memory: {self.start_memory:.2f} MB\")\n    \n    def end(self):\n        end_time = time.time()\n        end_memory = psutil.Process().memory_info().rss / (1024 * 1024)  # MB\n        duration = end_time - self.start_time\n        memory_change = end_memory - self.start_memory\n        \n        self.logger.info(\n            f\"Completed {self.operation_name} - \"\n            f\"Duration: {duration:.2f}s, \"\n            f\"Memory: {end_memory:.2f} MB, \"\n            f\"Memory Change: {memory_change:+.2f} MB\"\n        )\n        \n        return {\n            \"operation\": self.operation_name,\n            \"duration\": duration,\n            \"memory_start\": self.start_memory,\n            \"memory_end\": end_memory,\n            \"memory_change\": memory_change\n        }\n\n# Usage\nmonitor = PerformanceMonitor()\n\n# Monitor document ingestion\nmonitor.start(\"document_ingestion\")\nrag.import_documents()\ningestion_stats = monitor.end()\n\n# Monitor query\nmonitor.start(\"query_processing\")\nresult = rag.query(\"What is SmolRAG?\")\nquery_stats = monitor.end()\n```",
        "summary": "The excerpt highlights the importance of performance monitoring in SmolRAG, providing details on tracking resource usage during operations, which aligns with the broader context of the full document that outlines various performance considerations and optimization strategies for enhancing SmolRAG\u2019s efficiency.",
        "indexed_at": 1745030047.009611
    },
    "excerpt_id_4e649c101b76d51df1364c3c6cc472a9": {
        "doc_id": "doc_2c751da5b112adc2cd611bbd9bb377fa",
        "doc_order_index": 12,
        "excerpt": "t(\"document_ingestion\")\nrag.import_documents()\ningestion_stats = monitor.end()\n\n# Monitor query\nmonitor.start(\"query_processing\")\nresult = rag.query(\"What is SmolRAG?\")\nquery_stats = monitor.end()\n```---\n\n### **10. Query Optimization Techniques**\n\nDifferent query types have different performance characteristics, and optimizing them requires specific techniques:\n\n**Vector Search Query Optimization**:\n- **Indexing**: Use approximate nearest neighbor (ANN) indexing for faster searches.\n- **Dimensionality Reduction**: Consider reducing embedding dimensions for faster processing.\n- **Query Preprocessing**: Simplify and normalize queries before embedding.\n\n**Knowledge Graph Query Optimization**:\n- **Graph Indexing**: Index the graph for faster traversal.\n- **Query Planning**: Optimize the order of operations in graph queries.\n- **Caching**: Cache intermediate results for common query patterns.\n\n**Mix Query Optimization**:\n- **Parallel Processing**: Run vector search and knowledge graph queries in parallel.\n- **Adaptive Strategies**: Dynamically choose between query types based on the query characteristics.\n- **Result Merging**: Optimize how results from different query types are combined.\n\n**Example: Parallel Query Processing**:\n\n```python\nimport concurrent.futures\n\ndef parallel_query(rag, query_text):\n    \"\"\"Run vector search and knowledge graph queries in parallel.\"\"\"\n    with concurrent.futures.ThreadPoolExecutor(max_workers=2) as executor:\n        # Start both queries\n        vector_future = executor.submit(rag.query, query_text)\n        kg_future = executor.submit(rag.hybrid_kg_query, query_text)\n        \n        # Wait for both to complete\n        vector_result = vector_future.result()\n        kg_result = kg_future.result()\n        \n        # Combine results (in a real implementation, you would need a more sophisticated merging strategy)\n        combined_result = f\"Vector Search Result:\\n{vector_result}\\n\\nKnowledge Graph Result:\\n{kg_result}\"\n        return combined_result\n\n# Usage\nresult = parallel_query(rag, \"What is SmolRAG?\")\n```\n\n---\n\n### **11. Hardware Considerations**\n\nThe hardware you run SmolRAG on can significantly impact its performance:",
        "summary": "The excerpt discusses specific query optimization techniques and hardware considerations that are essential for enhancing the performance of the SmolRAG system, aligning with the broader context of performance evaluation and improvement strategies outlined throughout the document.",
        "indexed_at": 1745030047.0096881
    },
    "excerpt_id_6c06a295a7f56782823d65a71c55d286": {
        "doc_id": "doc_2c751da5b112adc2cd611bbd9bb377fa",
        "doc_order_index": 13,
        "excerpt": "eturn combined_result\n\n# Usage\nresult = parallel_query(rag, \"What is SmolRAG?\")\n```\n\n---\n\n### **11. Hardware Considerations**\n\nThe hardware you run SmolRAG on can significantly impact its performance:**CPU Considerations**:\n- **Core Count**: More cores help with parallel processing during document ingestion.\n- **Clock Speed**: Higher clock speeds improve single-threaded performance for operations like vector similarity calculations.\n- **Cache Size**: Larger CPU caches improve performance for memory-intensive operations.\n\n**Memory Considerations**:\n- **Capacity**: Sufficient RAM is crucial, especially for large document collections.\n- **Speed**: Faster RAM improves overall system performance.\n- **Configuration**: Proper memory configuration (e.g., swap settings) can prevent out-of-memory errors.\n\n**Storage Considerations**:\n- **Type**: SSDs provide much faster I/O than HDDs, improving performance for disk-bound operations.\n- **Capacity**: Sufficient storage space is needed for vector databases, knowledge graphs, and logs.\n- **I/O Performance**: High I/O throughput is important for operations that read from or write to disk frequently.\n\n**Network Considerations**:\n- **Bandwidth**: Sufficient bandwidth is needed for API calls and distributed deployments.\n- **Latency**: Low latency improves performance for operations that require API calls.\n- **Reliability**: A reliable network connection is crucial for systems that depend on external APIs.\n\n**Example: Hardware Recommendations**:\n- **Small Deployments** (< 1,000 documents):\n  - 4+ CPU cores\n  - 8+ GB RAM\n  - 50+ GB SSD storage\n- **Medium Deployments** (1,000 - 10,000 documents):\n  - 8+ CPU cores\n  - 16+ GB RAM\n  - 100+ GB SSD storage\n- **Large Deployments** (> 10,000 documents):\n  - 16+ CPU cores\n  - 32+ GB RAM\n  - 200+ GB SSD storage\n  - Consider distributed deployment\n\n---\n\n### **12. Performance Testing**\n\nSystematic performance testing helps identify bottlenecks and validate optimizations:",
        "summary": "The excerpt discusses the critical hardware and performance testing considerations for optimizing SmolRAG's efficiency, emphasizing the impact of CPU, memory, storage, and network resources on system performance within the broader context of ensuring effective and scalable document handling and query processing.",
        "indexed_at": 1745030047.009762
    },
    "excerpt_id_3db25e98f4a52a9f3effc27f3a26925e": {
        "doc_id": "doc_2c751da5b112adc2cd611bbd9bb377fa",
        "doc_order_index": 14,
        "excerpt": "\n  - 32+ GB RAM\n  - 200+ GB SSD storage\n  - Consider distributed deployment\n\n---\n\n### **12. Performance Testing**\n\nSystematic performance testing helps identify bottlenecks and validate optimizations:**Testing Approaches**:\n- **Benchmark Tests**: Measure performance metrics for standard operations.\n- **Load Tests**: Test performance under various load conditions.\n- **Stress Tests**: Test performance at or beyond expected capacity.\n- **Endurance Tests**: Test performance over extended periods.\n\n**Testing Metrics**:\n- **Throughput**: How many operations can be processed per unit of time.\n- **Latency**: How long each operation takes.\n- **Resource Usage**: How much CPU, memory, and disk are used.\n- **Error Rates**: How many operations fail under load.\n\n**Example: Simple Benchmark Script**:",
        "summary": "The excerpt emphasizes the importance of performance testing in optimizing SmolRAG's efficiency, particularly in relation to resource requirements, as detailed in the broader context of system specifications for handling larger document collections and varied operational loads.",
        "indexed_at": 1745030047.009835
    },
    "excerpt_id_8df198dc0e22767ee72f9d76b21e44aa": {
        "doc_id": "doc_2c751da5b112adc2cd611bbd9bb377fa",
        "doc_order_index": 15,
        "excerpt": "*Latency**: How long each operation takes.\n- **Resource Usage**: How much CPU, memory, and disk are used.\n- **Error Rates**: How many operations fail under load.\n\n**Example: Simple Benchmark Script**:```python\nimport time\nimport statistics\nimport random\nfrom app.smol_rag import SmolRag\n\ndef benchmark_queries(rag, queries, query_type=\"standard\", runs=3):\n    \"\"\"Benchmark query performance.\"\"\"\n    results = []\n    \n    for query in queries:\n        query_times = []\n        \n        for _ in range(runs):\n            start_time = time.time()\n            \n            if query_type == \"standard\":\n                rag.query(query)\n            elif query_type == \"local_kg\":\n                rag.local_kg_query(query)\n            elif query_type == \"global_kg\":\n                rag.global_kg_query(query)\n            elif query_type == \"hybrid_kg\":\n                rag.hybrid_kg_query(query)\n            elif query_type == \"mix\":\n                rag.mix_query(query)\n            \n            query_time = time.time() - start_time\n            query_times.append(query_time)\n        \n        avg_time = statistics.mean(query_times)\n        min_time = min(query_times)\n        max_time = max(query_times)\n        \n        results.append({\n            \"query\": query,\n            \"type\": query_type,\n            \"avg_time\": avg_time,\n            \"min_time\": min_time,\n            \"max_time\": max_time\n        })\n    \n    return results\n\n# Usage\nrag = SmolRag()\nrag.import_documents()\n\ntest_queries = [\n    \"What is SmolRAG?\",\n    \"How does document chunking work?\",\n    \"What are the benefits of knowledge graphs?\",\n    \"How do vector embeddings work?\",\n    \"What query types are supported?\"\n]\n\n# Benchmark different query types\nstandard_results = benchmark_queries(rag, test_queries, \"standard\")\nkg_results = benchmark_queries(rag, test_queries, \"hybrid_kg\")\nmix_results = benchmark_queries(rag, test_queries, \"mix\")\n\n# Print results\nfor result in standard_results:\n    print(f\"Query: {result['query']}\")\n    print(f\"Type: {result['type']}\")\n    print(f\"Avg Time: {result['avg_time']:.2f}s\")\n    print(f\"Min Time: {result['min_time']:.2f}s\")\n    print(f\"Max Time: {result['max_time']:.2f}s\")\n    print(\"-\"",
        "summary": "The excerpt provides specific examples of benchmarking query performance within the SmolRAG system by measuring metrics like latency, resource usage, and error rates, which ties into the broader context of optimizing performance and identifying bottlenecks discussed throughout the full document.",
        "indexed_at": 1745030047.009911
    },
    "excerpt_id_1f85cb53bc4e7de3a80fec7f9c6b4d2c": {
        "doc_id": "doc_2c751da5b112adc2cd611bbd9bb377fa",
        "doc_order_index": 16,
        "excerpt": "    print(f\"Type: {result['type']}\")\n    print(f\"Avg Time: {result['avg_time']:.2f}s\")\n    print(f\"Min Time: {result['min_time']:.2f}s\")\n    print(f\"Max Time: {result['max_time']:.2f}s\")\n    print(\"-\" * 50)\n```",
        "summary": "The excerpt illustrates the performance benchmarking process for queries in SmolRAG, which is integral to the document's broader context focused on optimizing performance metrics and ensuring efficient system operation as document collections grow.",
        "indexed_at": 1745030047.009995
    },
    "excerpt_id_4b1d39bb3b412ccb5521449ed59095c6": {
        "doc_id": "doc_2c751da5b112adc2cd611bbd9bb377fa",
        "doc_order_index": 17,
        "excerpt": " * 50)\n```---\n\n### **13. Cloud Deployment Performance**\n\nWhen deploying SmolRAG in the cloud, specific performance considerations apply:\n\n**Cloud Provider Selection**:\n- **Compute Options**: Different providers offer various VM types optimized for different workloads.\n- **Managed Services**: Consider using managed services for databases, caching, etc.\n- **Pricing Model**: Understand the cost implications of different resource allocations.\n\n**Containerization**:\n- **Resource Limits**: Set appropriate CPU and memory limits for containers.\n- **Volume Mounting**: Use efficient volume mounting for persistent data.\n- **Image Optimization**: Optimize Docker images for size and startup time.\n\n**Serverless Considerations**:\n- **Cold Starts**: Be aware of cold start latency for serverless functions.\n- **Memory Allocation**: Allocate sufficient memory for serverless functions.\n- **Execution Limits**: Understand execution time limits for long-running operations.\n\n**Example: Kubernetes Resource Configuration**:\n\n```yaml\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: smolrag-api\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: smolrag-api\n  template:\n    metadata:\n      labels:\n        app: smolrag-api\n    spec:\n      containers:\n      - name: smolrag-api\n        image: smolrag:latest\n        resources:\n          requests:\n            memory: \"1Gi\"\n            cpu: \"500m\"\n          limits:\n            memory: \"2Gi\"\n            cpu: \"1000m\"\n        volumeMounts:\n        - name: data-volume\n          mountPath: /app/app/data\n        - name: docs-volume\n          mountPath: /app/app/input_docs\n        env:\n        - name: OPENAI_API_KEY\n          valueFrom:\n            secretKeyRef:\n              name: openai-credentials\n              key: api-key\n      volumes:\n      - name: data-volume\n        persistentVolumeClaim:\n          claimName: smolrag-data-pvc\n      - name: docs-volume\n        persistentVolumeClaim:\n          claimName: smolrag-docs-pvc\n```\n\n---",
        "summary": "The excerpt discusses cloud deployment performance considerations for SmolRAG, focusing on aspects such as cloud provider selection, containerization, serverless function management, and resource configuration, which are essential for optimizing the system's operation in a scalable and cost-effective manner as highlighted throughout the broader document.",
        "indexed_at": 1745030047.010071
    },
    "excerpt_id_ab0c2359f35ddf542e46336b81a7e409": {
        "doc_id": "doc_2c751da5b112adc2cd611bbd9bb377fa",
        "doc_order_index": 18,
        "excerpt": ":\n      - name: data-volume\n        persistentVolumeClaim:\n          claimName: smolrag-data-pvc\n      - name: docs-volume\n        persistentVolumeClaim:\n          claimName: smolrag-docs-pvc\n```\n\n---### **14. Conclusion**\n\nOptimizing SmolRAG's performance requires a holistic approach that considers document ingestion, query processing, resource usage, and scaling strategies. By understanding the potential bottlenecks and implementing appropriate optimization techniques, you can ensure that SmolRAG performs well even as your document collection and query volume grow.\n\nKey takeaways for performance optimization:\n\n1. **Monitor and Profile**: Understand where time and resources are being spent.\n2. **Optimize Document Ingestion**: Use batch processing, incremental updates, and efficient chunking.\n3. **Optimize Query Processing**: Implement caching, choose appropriate query types, and limit context size.\n4. **Manage Resources**: Monitor and optimize memory, disk, and API usage.\n5. **Scale Appropriately**: Choose the right scaling strategy based on your needs and constraints.\n6. **Test Systematically**: Use benchmarks and load tests to validate optimizations.\n\nBy following these principles and implementing the techniques described in this document, you can ensure that SmolRAG provides fast, efficient, and reliable performance for your specific use case.",
        "summary": "The excerpt on persistent volume claims for data and documents illustrates the practical application of scaling strategies discussed in the broader context of optimizing SmolRAG's performance, ensuring robust storage solutions are in place as document collections grow.",
        "indexed_at": 1745030047.010145
    },
    "excerpt_id_9e82c97bd0829ec40084f1a45d364353": {
        "doc_id": "doc_dd41b1cad448630c72186b53ef909f09",
        "doc_order_index": 0,
        "excerpt": "**Title: SmolRAG Knowledge Graphs**\n\n---\n\n### **1. Introduction to Knowledge Graphs in SmolRAG**\n\nKnowledge graphs are a powerful component of SmolRAG that complement vector embeddings by providing structured representations of entities and relationships extracted from documents. While vector embeddings capture semantic meaning, knowledge graphs capture explicit connections between concepts, enabling more sophisticated reasoning and query capabilities.\n\nIn SmolRAG, the knowledge graph serves as a structured repository of information that can be queried directly or used to enhance vector-based retrieval. This dual approach allows the system to leverage both the flexibility of semantic search and the precision of structured knowledge representation.\n\n---\n\n### **2. Knowledge Graph Structure and Components**\n\nThe SmolRAG knowledge graph consists of several key components:\n\n- **Entities**: Distinct concepts, terms, or objects extracted from documents.\n- **Entity Properties**: Each entity has properties including:\n  - Name: The unique identifier for the entity\n  - Category: The type or class of the entity\n  - Description: A textual description of the entity\n  - Excerpt ID: Reference to the document excerpt where the entity was found\n- **Relationships**: Connections between entities, with properties including:\n  - Source and Target: The entities connected by the relationship\n  - Description: A textual description of the relationship\n  - Keywords: Terms that characterize the relationship\n  - Weight: A numerical value indicating the strength or importance of the relationship\n  - Excerpt ID: Reference to the document excerpt where the relationship was found\n\nThis structure allows SmolRAG to represent complex knowledge in a way that can be efficiently queried and traversed.\n\n---\n\n### **3. Knowledge Graph Construction**\n\nSmolRAG builds its knowledge graph during the document ingestion process:",
        "summary": "The excerpt introduces the concept of knowledge graphs in SmolRAG, highlighting their role in providing structured representations of entities and relationships that enhance both semantic search and precise query capabilities, reflecting the broader context of how SmolRAG integrates these graphs with vector embeddings for more sophisticated knowledge retrieval and reasoning.",
        "indexed_at": 1745030047.0166001
    },
    "excerpt_id_2f91a07d0891228b7332afeffe8b7a42": {
        "doc_id": "doc_dd41b1cad448630c72186b53ef909f09",
        "doc_order_index": 1,
        "excerpt": "esent complex knowledge in a way that can be efficiently queried and traversed.\n\n---\n\n### **3. Knowledge Graph Construction**\n\nSmolRAG builds its knowledge graph during the document ingestion process:1. **Entity Extraction**: For each document excerpt, the system uses LLM-based analysis to identify key entities.\n2. **Relationship Extraction**: The system identifies relationships between entities within the same excerpt.\n3. **Property Assignment**: Properties are assigned to both entities and relationships.\n4. **Deduplication and Merging**: If an entity already exists, its properties are merged with the new information.\n5. **Graph Storage**: The resulting entities and relationships are stored in the NetworkXGraphStore.\n\nThis process transforms unstructured text into a structured knowledge representation that captures the key concepts and connections in the documents.\n\n---\n\n### **4. NetworkX Implementation**\n\nSmolRAG uses NetworkX, a Python library for graph analysis, as the foundation for its knowledge graph:\n\n- **Graph Structure**: A NetworkX graph stores nodes (entities) and edges (relationships).\n- **Property Storage**: Node and edge attributes store the properties of entities and relationships.\n- **Serialization**: The graph is serialized to disk for persistence between runs.\n- **Graph Operations**: NetworkX provides efficient algorithms for graph traversal and analysis.\n- **Extensibility**: The implementation can be extended with additional graph algorithms as needed.\n\nThis lightweight yet powerful implementation provides the necessary functionality without the complexity of larger graph database systems.\n\n---\n\n### **5. Entity and Relationship Embeddings**\n\nIn addition to the structured graph representation, SmolRAG also creates vector embeddings for entities and relationships:",
        "summary": "The excerpt details the construction and the implementation of the SmolRAG knowledge graph, illustrating how it efficiently transforms unstructured text into a structured format, which is central to enhancing the system's information retrieval and reasoning capabilities.",
        "indexed_at": 1745030047.016684
    },
    "excerpt_id_7c686d971d2fea42e5ba02fc141455aa": {
        "doc_id": "doc_dd41b1cad448630c72186b53ef909f09",
        "doc_order_index": 2,
        "excerpt": " graph database systems.\n\n---\n\n### **5. Entity and Relationship Embeddings**\n\nIn addition to the structured graph representation, SmolRAG also creates vector embeddings for entities and relationships:- **Entity Embeddings**: Each entity is embedded based on its name and description.\n- **Relationship Embeddings**: Each relationship is embedded based on its keywords, source, target, and description.\n- **Separate Storage**: These embeddings are stored in dedicated vector stores.\n- **Semantic Search**: The embeddings enable semantic search for entities and relationships.\n- **Cross-Referencing**: The system maintains connections between the graph structure and the embeddings.\n\nThis dual representation\u2014structured graph and vector embeddings\u2014allows SmolRAG to combine the strengths of both approaches in its query processing.\n\n---\n\n### **6. Knowledge Graph Queries**\n\nSmolRAG supports several types of knowledge graph queries:\n\n- **Local Knowledge Graph Query**: Focuses on low-level keywords to find relevant entities and their relationships.\n- **Global Knowledge Graph Query**: Focuses on high-level keywords to find relevant relationships and connected entities.\n- **Hybrid Knowledge Graph Query**: Combines both local and global approaches for comprehensive coverage.\n- **Mix Query**: Integrates knowledge graph results with vector search results.\n\nEach query type has different strengths and is suited to different types of questions, providing flexibility in how the knowledge graph is used.\n\n---\n\n### **7. Local Knowledge Graph Query Process**\n\nThe local knowledge graph query process focuses on entities:\n\n1. **Keyword Extraction**: The system extracts low-level keywords from the query.\n2. **Entity Search**: Keywords are embedded and used to find relevant entities.\n3. **Entity Ranking**: Entities are ranked based on graph degree (connectivity) and relevance.\n4. **Relationship Extraction**: Relationships connected to the top entities are retrieved.\n5. **Context Construction**: A structured context is created from the entities, relationships, and associated excerpts.\n\nThis approach is particularly effective for queries about specific entities and their immediate connections.\n\n---",
        "summary": "The excerpt highlights the integration of entity and relationship embeddings in SmolRAG, illustrating how this dual representation enhances the system's ability to process various knowledge graph queries, thereby reinforcing the overall efficiency and flexibility of the knowledge graph framework discussed in the broader document.",
        "indexed_at": 1745030047.016788
    },
    "excerpt_id_33641a6c02e3c56addefda7f4288b5b7": {
        "doc_id": "doc_dd41b1cad448630c72186b53ef909f09",
        "doc_order_index": 3,
        "excerpt": "uctured context is created from the entities, relationships, and associated excerpts.\n\nThis approach is particularly effective for queries about specific entities and their immediate connections.\n\n---### **8. Global Knowledge Graph Query Process**\n\nThe global knowledge graph query process focuses on relationships:\n\n1. **Keyword Extraction**: The system extracts high-level keywords from the query.\n2. **Relationship Search**: Keywords are embedded and used to find relevant relationships.\n3. **Relationship Ranking**: Relationships are ranked based on weight and connectivity.\n4. **Entity Extraction**: Entities connected by the top relationships are retrieved.\n5. **Context Construction**: A structured context is created from the relationships, entities, and associated excerpts.\n\nThis approach provides a broader view of how concepts are interconnected, making it suitable for more abstract or conceptual queries.\n\n---\n\n### **9. Hybrid Knowledge Graph Query Process**\n\nThe hybrid knowledge graph query combines local and global approaches:\n\n1. **Keyword Extraction**: The system extracts both low-level and high-level keywords.\n2. **Dual Search**: Both entity-focused and relationship-focused searches are performed.\n3. **Result Combination**: Results from both approaches are combined and ranked.\n4. **Context Construction**: A comprehensive context is created from all relevant entities, relationships, and excerpts.\n\nThis approach provides the most complete knowledge graph perspective, balancing specific entity information with broader conceptual connections.\n\n---\n\n### **10. Knowledge Graph and Vector Search Integration**\n\nThe mix query type integrates knowledge graph and vector search results:\n\n1. **Parallel Processing**: Both knowledge graph queries and vector searches are performed.\n2. **Result Combination**: Results from both approaches are combined into a unified context.\n3. **Context Structuring**: The combined context is structured to highlight both semantic similarities and explicit connections.\n4. **LLM Processing**: The structured context is provided to the LLM for response generation.",
        "summary": "The excerpt highlights the various query processes\u2014local, global, hybrid, and mix\u2014within the SmolRAG knowledge graph, illustrating how these approaches enable flexible and comprehensive information retrieval by balancing specific entity details with broader conceptual connections, thus emphasizing the dual utility of knowledge graphs and vector searches in enhancing query capabilities.",
        "indexed_at": 1745030047.016883
    },
    "excerpt_id_98340282e700c542414080ecac3ff4a6": {
        "doc_id": "doc_dd41b1cad448630c72186b53ef909f09",
        "doc_order_index": 4,
        "excerpt": "ng**: The combined context is structured to highlight both semantic similarities and explicit connections.\n4. **LLM Processing**: The structured context is provided to the LLM for response generation.This integration leverages the complementary strengths of both approaches, providing both semantic relevance and structured knowledge.\n\n---\n\n### **11. Knowledge Graph Maintenance and Updates**\n\nSmolRAG includes mechanisms for maintaining and updating the knowledge graph:\n\n- **Incremental Updates**: When documents change, affected entities and relationships are updated.\n- **Consistency Checks**: The system ensures that the graph remains consistent during updates.\n- **Orphan Handling**: Entities and relationships that no longer have associated excerpts are managed appropriately.\n- **Graph Pruning**: Optional pruning can be performed to remove less important entities and relationships.\n- **Performance Optimization**: The graph structure is optimized for efficient querying and traversal.\n\nThese maintenance mechanisms ensure that the knowledge graph remains accurate and up-to-date as documents change.\n\n---\n\n### **12. Strengths and Limitations of the Knowledge Graph Approach**\n\nThe knowledge graph approach in SmolRAG has several strengths and limitations:\n\n**Strengths**:\n- **Explicit Connections**: Captures explicit relationships between concepts.\n- **Structured Reasoning**: Enables structured reasoning about entities and their connections.\n- **Complementary to Vectors**: Provides information that may not be captured by vector embeddings.\n- **Multi-Hop Reasoning**: Supports reasoning across multiple connections.\n- **Explainability**: Graph structures are more interpretable than vector embeddings.\n\n**Limitations**:\n- **Extraction Quality**: Depends on the quality of entity and relationship extraction.\n- **Coverage**: May not capture all relevant information in the documents.\n- **Complexity**: Graph queries can be more complex than simple vector searches.\n- **Scaling**: Graph operations may become more resource-intensive as the graph grows.\n- **Domain Specificity**: Extraction quality may vary across different domains.",
        "summary": "The excerpt discusses the maintenance and limitations of knowledge graphs within SmolRAG, highlighting their role in ensuring up-to-date and accurate structured information, which is essential for the broader context of SmolRAG\u2019s dual approach to knowledge retrieval that combines structured reasoning with semantic search.",
        "indexed_at": 1745030047.01696
    },
    "excerpt_id_59fb313f068a75f4e40be3bf7b095013": {
        "doc_id": "doc_dd41b1cad448630c72186b53ef909f09",
        "doc_order_index": 5,
        "excerpt": "plex than simple vector searches.\n- **Scaling**: Graph operations may become more resource-intensive as the graph grows.\n- **Domain Specificity**: Extraction quality may vary across different domains.Understanding these strengths and limitations helps users choose the appropriate query type for their specific needs.\n\n---\n\n### **13. Future Directions for Knowledge Graphs in SmolRAG**\n\nThe knowledge graph capabilities in SmolRAG continue to evolve:\n\n- **Enhanced Extraction**: Improving entity and relationship extraction quality.\n- **Graph Algorithms**: Incorporating more sophisticated graph analysis algorithms.\n- **Temporal Aspects**: Adding support for temporal information in the knowledge graph.\n- **Multi-Document Reasoning**: Enhancing the ability to reason across multiple documents.\n- **User Feedback Integration**: Incorporating user feedback to improve the knowledge graph.\n\nThese future directions will further enhance SmolRAG's ability to represent and reason with structured knowledge.\n\n---\n\n### **14. Conclusion**\n\nKnowledge graphs are a powerful component of SmolRAG that complement vector embeddings by providing structured representations of entities and relationships. By combining the flexibility of semantic search with the precision of structured knowledge representation, SmolRAG can handle a wide range of query types and information needs.\n\nThe different knowledge graph query types\u2014local, global, hybrid, and mix\u2014provide users with flexible options for accessing information, from specific entity details to broad conceptual connections. This versatility, combined with the integration of vector search capabilities, makes SmolRAG a powerful tool for retrieving and reasoning with document-based knowledge.",
        "summary": "The excerpt highlights the strengths and limitations of the knowledge graph approach within SmolRAG, providing context for its ongoing development and future enhancements aimed at improving extraction quality, reasoning capabilities, and user feedback integration in the broader framework of document-based knowledge management.",
        "indexed_at": 1745030047.017035
    },
    "excerpt_id_f1ef3b38067579dab39116dbfeca6ddc": {
        "doc_id": "doc_79b1966b0925f4513282c449c4e7dc0a",
        "doc_order_index": 0,
        "excerpt": "**Title: SmolRAG Query Types: Strengths and Weaknesses**\n\n---\n\n### **1. Introduction to SmolRAG Query Types**\n\nSmolRAG offers multiple query types, each designed to leverage different aspects of the system's capabilities. These query types range from pure semantic search to sophisticated knowledge graph-based approaches, providing users with flexibility to address various information needs.\n\nUnderstanding the strengths and weaknesses of each query type is essential for getting the most out of SmolRAG. Different query types excel at different tasks, and choosing the right one can significantly improve the quality and relevance of the responses you receive.\n\n---\n\n### **2. Overview of Available Query Types**\n\nSmolRAG supports five main query types:\n\n1. **Vector Search Query** (`query`): Uses pure semantic similarity to find relevant excerpts.\n2. **Local Knowledge Graph Query** (`local_kg_query`): Focuses on low-level keywords to find relevant entities and their relationships.\n3. **Global Knowledge Graph Query** (`global_kg_query`): Focuses on high-level keywords to find relevant relationships and connected entities.\n4. **Hybrid Knowledge Graph Query** (`hybrid_kg_query`): Combines both local and global knowledge graph approaches.\n5. **Mix Query** (`mix_query`): Integrates both vector search and knowledge graph approaches.\n\nEach query type has a specific implementation in the SmolRAG class and can be accessed through both the Python API and the REST API.\n\n---\n\n### **3. Vector Search Query**\n\nThe vector search query (`query`) is the most straightforward query type in SmolRAG:\n\n**Implementation**:\n1. The query text is embedded using the same model as the document excerpts.\n2. The query embedding is compared to all excerpt embeddings using cosine similarity.\n3. The top-k most similar excerpts are selected.\n4. These excerpts and their summaries form the context for the LLM.",
        "summary": "The excerpt provides an overview of SmolRAG's multiple query types, highlighting their designed purposes and the importance of understanding their strengths and weaknesses, which is critical for optimizing the retrieval of information outlined in the broader document.",
        "indexed_at": 1745030047.030377
    },
    "excerpt_id_ad053b14f30e2ca2cbde4877068102ef": {
        "doc_id": "doc_79b1966b0925f4513282c449c4e7dc0a",
        "doc_order_index": 1,
        "excerpt": " The query embedding is compared to all excerpt embeddings using cosine similarity.\n3. The top-k most similar excerpts are selected.\n4. These excerpts and their summaries form the context for the LLM.**Strengths**:\n- **Speed**: Generally the fastest query type as it involves a single vector comparison operation.\n- **Simplicity**: Straightforward implementation with minimal processing steps.\n- **Direct Matching**: Excellent at finding excerpts that directly address the query topic.\n- **Contextual Understanding**: Captures semantic meaning beyond simple keyword matching.\n- **Broad Coverage**: Can find relevant information even when terminology differs.\n\n**Weaknesses**:\n- **Limited Context**: Only considers individual excerpts, not their connections to other information.\n- **No Structured Reasoning**: Lacks the ability to reason about relationships between concepts.\n- **Semantic Drift**: May retrieve excerpts that are semantically similar but not directly relevant.\n- **Missing Connections**: Cannot identify multi-hop connections that require traversing relationships.\n- **Ambiguity Handling**: May struggle with ambiguous queries that have multiple interpretations.\n\n**When to Use**:\n- For quick, straightforward questions that are likely answered directly in the documents.\n- When you need a fast response and don't require complex reasoning.\n- For questions about specific topics, concepts, or definitions.\n- When the query is well-formed and unambiguous.\n\n---\n\n### **4. Local Knowledge Graph Query**\n\nThe local knowledge graph query (`local_kg_query`) focuses on entities and their immediate relationships:\n\n**Implementation**:\n1. Low-level keywords are extracted from the query.\n2. These keywords are embedded and used to find relevant entities.\n3. Entities are ranked by graph degree (connectivity) and relevance.\n4. Relationships connected to the top entities are retrieved.\n5. A structured context is created from the entities, relationships, and associated excerpts.",
        "summary": "The excerpt details the mechanisms, strengths, and weaknesses of the vector search query type in SmolRAG, illustrating its functionality as the fastest and simplest method for retrieving relevant information, which contrasts with the local knowledge graph query's focus on entities and their relationships, underscoring the system's diverse querying capabilities to address varying information needs.",
        "indexed_at": 1745030047.0304809
    },
    "excerpt_id_9c79fe4d43437c480a6cef767c63d764": {
        "doc_id": "doc_79b1966b0925f4513282c449c4e7dc0a",
        "doc_order_index": 2,
        "excerpt": "y graph degree (connectivity) and relevance.\n4. Relationships connected to the top entities are retrieved.\n5. A structured context is created from the entities, relationships, and associated excerpts.**Strengths**:\n- **Entity Focus**: Excellent at finding information about specific entities.\n- **Relationship Awareness**: Identifies connections between entities.\n- **Fine-Grained Information**: Provides detailed information about specific concepts.\n- **Structured Context**: Presents information in a structured format that highlights relationships.\n- **Explicit Connections**: Captures explicit connections mentioned in the documents.\n\n**Weaknesses**:\n- **Limited Scope**: Focuses on specific entities rather than broader concepts.\n- **Extraction Dependence**: Quality depends on the entity extraction process.\n- **Missing Semantics**: May miss relevant information that isn't explicitly structured as entities and relationships.\n- **Narrow Context**: Primarily considers the immediate connections of entities.\n- **Keyword Sensitivity**: Performance depends on the quality of extracted keywords.\n\n**When to Use**:\n- For questions about specific entities and their properties.\n- When you need to understand the immediate connections of a concept.\n- For queries that involve specific technical terms or named entities.\n- When you want a structured representation of information.\n\n---\n\n### **5. Global Knowledge Graph Query**\n\nThe global knowledge graph query (`global_kg_query`) focuses on relationships and broader connections:\n\n**Implementation**:\n1. High-level keywords are extracted from the query.\n2. These keywords are embedded and used to find relevant relationships.\n3. Relationships are ranked by weight and connectivity.\n4. Entities connected by the top relationships are retrieved.\n5. A structured context is created from the relationships, entities, and associated excerpts.",
        "summary": "The excerpt discusses the strengths and weaknesses of the Local and Global Knowledge Graph Queries in SmolRAG, illustrating how these query types enable users to retrieve detailed information about specific entities and broader conceptual relationships, which is essential for effectively leveraging the system's capabilities for diverse information needs.",
        "indexed_at": 1745030047.0305622
    },
    "excerpt_id_2f5e12b98d229a1119f45f912ee45c12": {
        "doc_id": "doc_79b1966b0925f4513282c449c4e7dc0a",
        "doc_order_index": 3,
        "excerpt": "ships are ranked by weight and connectivity.\n4. Entities connected by the top relationships are retrieved.\n5. A structured context is created from the relationships, entities, and associated excerpts.**Strengths**:\n- **Conceptual Focus**: Excellent at finding information about broader concepts and themes.\n- **High-Level Connections**: Identifies connections between different areas of knowledge.\n- **Bird's-Eye View**: Provides a broader perspective on the topic.\n- **Thematic Understanding**: Captures thematic relationships across documents.\n- **Abstract Reasoning**: Better at handling abstract or conceptual queries.\n\n**Weaknesses**:\n- **Less Detail**: May not provide as much specific detail as other query types.\n- **Abstraction Challenges**: Can sometimes be too abstract for concrete questions.\n- **Relationship Dependence**: Quality depends on the relationship extraction process.\n- **Complexity**: More complex processing may lead to longer query times.\n- **Conceptual Drift**: May sometimes drift too far from the original query intent.\n\n**When to Use**:\n- For questions about broader concepts or themes.\n- When you need to understand how different areas of knowledge connect.\n- For abstract or conceptual queries.\n- When you want a high-level overview rather than specific details.\n\n---\n\n### **6. Hybrid Knowledge Graph Query**\n\nThe hybrid knowledge graph query (`hybrid_kg_query`) combines both local and global approaches:\n\n**Implementation**:\n1. Both low-level and high-level keywords are extracted from the query.\n2. Both entity-focused and relationship-focused searches are performed.\n3. Results from both approaches are combined and ranked.\n4. A comprehensive context is created from all relevant entities, relationships, and excerpts.\n\n**Strengths**:\n- **Comprehensive Coverage**: Combines the strengths of both local and global approaches.\n- **Balanced Perspective**: Provides both specific details and broader context.\n- **Flexible Handling**: Adapts to different types of queries.\n- **Rich Context**: Generates a rich context that includes both entities and relationships.\n- **Robust Performance**: Generally performs well across a wide range of query types.",
        "summary": "The excerpt illustrates the strengths and weaknesses of the Global Knowledge Graph Query type and the Hybrid Knowledge Graph Query in SmolRAG, highlighting their roles in providing comprehensive responses that balance specific detail and broader context within the broader framework of query type selection and optimization discussed in the full document.",
        "indexed_at": 1745030047.0306401
    },
    "excerpt_id_958fb948ab95cbababa3713159600cc7": {
        "doc_id": "doc_79b1966b0925f4513282c449c4e7dc0a",
        "doc_order_index": 4,
        "excerpt": "rent types of queries.\n- **Rich Context**: Generates a rich context that includes both entities and relationships.\n- **Robust Performance**: Generally performs well across a wide range of query types.**Weaknesses**:\n- **Complexity**: More complex processing may lead to longer query times.\n- **Information Overload**: May sometimes provide too much information.\n- **Resource Intensity**: Requires more computational resources than simpler query types.\n- **Balancing Challenge**: May not always optimally balance local and global information.\n- **Dependency Chain**: Depends on the quality of both entity and relationship extraction.\n\n**When to Use**:\n- For complex questions that involve both specific entities and broader concepts.\n- When you need a balanced perspective that includes both details and context.\n- For queries where you're not sure whether a local or global approach would be better.\n- When you want the most comprehensive knowledge graph-based response.\n\n---\n\n### **7. Mix Query**\n\nThe mix query (`mix_query`) integrates both vector search and knowledge graph approaches:\n\n**Implementation**:\n1. Both vector search and hybrid knowledge graph queries are performed.\n2. Results from both approaches are combined into a unified context.\n3. The context is structured to highlight both semantic similarities and explicit connections.\n4. This comprehensive context is provided to the LLM for response generation.\n\n**Strengths**:\n- **Maximum Coverage**: Combines the strengths of both vector search and knowledge graph approaches.\n- **Complementary Methods**: Vector search finds semantically similar content, while the knowledge graph provides structured connections.\n- **Robust Performance**: Generally performs well across the widest range of query types.\n- **Rich Context**: Provides the richest context for the LLM to generate responses.\n- **Fallback Mechanism**: If one approach fails to find relevant information, the other may succeed.",
        "summary": "The excerpt highlights the strengths and weaknesses of the hybrid knowledge graph query and mix query types in SmolRAG, illustrating how they provide comprehensive context and robust performance while also emphasizing their complexity and resource demands, which ties into the broader discussion of query type selection and optimal usage within the full document.",
        "indexed_at": 1745030047.03072
    },
    "excerpt_id_84dc24216724ab859775d987f5bb2e19": {
        "doc_id": "doc_79b1966b0925f4513282c449c4e7dc0a",
        "doc_order_index": 5,
        "excerpt": "of query types.\n- **Rich Context**: Provides the richest context for the LLM to generate responses.\n- **Fallback Mechanism**: If one approach fails to find relevant information, the other may succeed.**Weaknesses**:\n- **Resource Intensity**: The most computationally intensive query type.\n- **Complexity**: The most complex processing pipeline.\n- **Query Time**: Generally has the longest query time.\n- **Information Overload**: May sometimes provide too much information for the LLM to process effectively.\n- **Context Limit Challenges**: May more frequently encounter token limit constraints.\n\n**When to Use**:\n- For the most important or complex queries where you want the best possible response.\n- When you need both semantic relevance and structured knowledge.\n- For queries that might benefit from multiple perspectives.\n- When query time and computational resources are not major constraints.\n\n---\n\n### **8. Comparative Analysis of Query Types**\n\nTo help choose the right query type for your needs, here's a comparative analysis across several dimensions:\n\n| Query Type | Speed | Detail Level | Structured Reasoning | Semantic Understanding | Resource Usage | Best For |\n|------------|-------|-------------|---------------------|------------------------|---------------|----------|\n| Vector Search | Fastest | Medium | Low | High | Low | Direct questions, quick answers |\n| Local KG | Medium | High for entities | Medium | Low | Medium | Specific entity details |\n| Global KG | Medium | High for concepts | Medium | Low | Medium | Conceptual relationships |\n| Hybrid KG | Slow | High | High | Low | High | Balanced entity-concept questions |\n| Mix | Slowest | Highest | Highest | High | Highest | Complex, important questions |\n\nThis comparison can serve as a quick reference when deciding which query type to use for a particular question or use case.\n\n---\n\n### **9. Query Type Selection Strategies**\n\nChoosing the right query type can significantly impact the quality of responses. Here are some strategies for query type selection:",
        "summary": "The excerpt emphasizes the strengths and weaknesses of the Mix Query type within SmolRAG's broader framework of query types, showcasing its capacity for rich contextual understanding and comprehensive responses, while also highlighting the trade-offs in resource intensity and complexity associated with its use.",
        "indexed_at": 1745030047.030797
    },
    "excerpt_id_eefa49769efd623d4dac1e62ed2a7ced": {
        "doc_id": "doc_79b1966b0925f4513282c449c4e7dc0a",
        "doc_order_index": 6,
        "excerpt": "stion or use case.\n\n---\n\n### **9. Query Type Selection Strategies**\n\nChoosing the right query type can significantly impact the quality of responses. Here are some strategies for query type selection:- **Question Analysis**: Analyze the question to determine if it's about specific entities (local KG), broader concepts (global KG), or a mix of both.\n- **Iterative Refinement**: Start with a simpler query type and move to more complex ones if the initial response is insufficient.\n- **Domain-Specific Defaults**: For certain domains or document types, some query types may consistently perform better.\n- **Response Time Requirements**: Consider the trade-off between response quality and response time based on your use case.\n- **Computational Resource Constraints**: If resources are limited, prioritize more efficient query types.\n\nDeveloping a good strategy for query type selection can help optimize both response quality and system performance.\n\n---\n\n### **10. API Integration and Query Type Selection**\n\nWhen integrating SmolRAG into your application, you can provide query type selection capabilities:\n\n**Python API**:\n\n```python\nfrom app.smol_rag import SmolRag\n\nrag = SmolRag()\n\n# Vector search query\nresult = rag.query(\"What is SmolRAG?\")\n\n# Local knowledge graph query\nresult = rag.local_kg_query(\"What entities are related to document chunking?\")\n\n# Global knowledge graph query\nresult = rag.global_kg_query(\"How are different components connected?\")\n\n# Hybrid knowledge graph query\nresult = rag.hybrid_kg_query(\"What is the relationship between embeddings and queries?\")\n\n# Mix query\nresult = rag.mix_query(\"How does SmolRAG process and retrieve information?\")\n```\n\n**REST API**:\n\n```json\n{\n  \"text\": \"Your query text here\",\n  \"query_type\": \"standard\"  // Options: standard, local_kg, global_kg, hybrid_kg, mix\n}\n```\n\nProviding users with the ability to select query types can enhance the flexibility and effectiveness of your application.\n\n---\n\n### **11. Performance Considerations**\n\nDifferent query types have different performance characteristics:",
        "summary": "The excerpt on query type selection strategies emphasizes the importance of strategically choosing the appropriate query type in the broader context of SmolRAG's multiple query capabilities to optimize response quality and system performance.",
        "indexed_at": 1745030047.030901
    },
    "excerpt_id_d2ba6034366fcca143d67219ee341a22": {
        "doc_id": "doc_79b1966b0925f4513282c449c4e7dc0a",
        "doc_order_index": 7,
        "excerpt": "to select query types can enhance the flexibility and effectiveness of your application.\n\n---\n\n### **11. Performance Considerations**\n\nDifferent query types have different performance characteristics:- **Vector Search**: Generally the fastest, with performance primarily dependent on the size of the vector database.\n- **Knowledge Graph Queries**: Performance depends on the size and complexity of the knowledge graph.\n- **Mix Query**: The most resource-intensive, as it combines multiple query approaches.\n\nTo optimize performance:\n- Use simpler query types for less complex questions.\n- Implement caching for frequently asked questions.\n- Consider query type selection based on system load.\n- Monitor and tune similarity thresholds and other parameters.\n- Optimize the knowledge graph structure for frequently used query patterns.\n\nThese considerations can help balance response quality with system performance.\n\n---\n\n### **12. Future Query Type Developments**\n\nSmolRAG's query capabilities continue to evolve:\n\n- **Adaptive Query Selection**: Automatically selecting the optimal query type based on the question.\n- **Personalized Query Processing**: Adapting query processing based on user preferences and history.\n- **Multi-Stage Querying**: Implementing multi-stage query processes that refine results iteratively.\n- **Domain-Specific Optimizations**: Specialized query types for specific domains or document types.\n- **Interactive Querying**: Supporting interactive query refinement based on initial results.\n\nThese developments will further enhance SmolRAG's ability to provide accurate and relevant responses to a wide range of queries.\n\n---\n\n### **13. Conclusion**\n\nSmolRAG's multiple query types provide a flexible and powerful framework for retrieving and reasoning with document-based knowledge. Each query type has its own strengths and weaknesses, making them suitable for different types of questions and use cases.",
        "summary": "The excerpt discusses the performance characteristics of different query types in SmolRAG and future developments, highlighting the importance of query type selection for optimizing response quality and system efficiency within the broader context of leveraging SmolRAG's versatile querying capabilities.",
        "indexed_at": 1745030047.030986
    },
    "excerpt_id_e67e24565dae8dec6e972c21f5e33ed4": {
        "doc_id": "doc_79b1966b0925f4513282c449c4e7dc0a",
        "doc_order_index": 8,
        "excerpt": "owerful framework for retrieving and reasoning with document-based knowledge. Each query type has its own strengths and weaknesses, making them suitable for different types of questions and use cases.By understanding these different query types and when to use them, you can get the most out of SmolRAG and provide your users with the most accurate and relevant responses. Whether you need quick answers to straightforward questions or comprehensive responses to complex queries, SmolRAG's query types offer the flexibility to meet your needs.",
        "summary": "The excerpt emphasizes the importance of understanding SmolRAG's query types and their respective strengths and weaknesses to enhance the accuracy and relevance of responses in the broader context of effectively utilizing the system for diverse information needs.",
        "indexed_at": 1745030047.0310621
    },
    "excerpt_id_f8b124e0bd021d69415fab98214a7b6b": {
        "doc_id": "doc_d741bc43c52b5b5bb9c3f2a21dd5d086",
        "doc_order_index": 0,
        "excerpt": "**Title: SmolRAG Usage Examples**\n\n---\n\n### **1. Introduction to SmolRAG Usage**\n\nThis document provides practical examples of how to use SmolRAG in various scenarios. These examples demonstrate the flexibility and power of SmolRAG for different use cases, from simple document querying to more complex knowledge extraction and reasoning tasks.\n\nThe examples are designed to be easy to follow and adapt to your specific needs. Each example includes code snippets and explanations to help you understand how to implement similar functionality in your own applications.\n\n---\n\n### **2. Basic Setup and Initialization**\n\nBefore using SmolRAG, you need to set up your environment and initialize the system. Here's a basic example:\n\n```python\n# Import the SmolRag class\nfrom app.smol_rag import SmolRag\n\n# Initialize SmolRAG with default settings\nrag = SmolRag()\n\n# SmolRAG now uses preserve_markdown_code_excerpts as the default chunking strategy\n# This strategy keeps code blocks intact and splits text at sentence boundaries\nfrom app.chunking import preserve_markdown_code_excerpts, naive_overlap_excerpts\n\n# The default is already preserve_markdown_code_excerpts, but you can specify it explicitly:\nrag = SmolRag(excerpt_fn=preserve_markdown_code_excerpts)\n\n# Or use the simpler naive chunking if preferred:\n# rag = SmolRag(excerpt_fn=naive_overlap_excerpts)\n\n# If you want to customize dimensions or other parameters\nrag = SmolRag(\n    dimensions=1536,\n    excerpt_size=2000,\n    overlap=200\n)\n```\n\nThis basic setup creates a SmolRAG instance with either default or custom settings. The instance is now ready to import documents and process queries.\n\n---\n\n### **3. Document Ingestion Example**\n\nTo use SmolRAG, you first need to ingest documents. Here's how to do it:",
        "summary": "The excerpt introduces the SmolRAG usage examples, setting the stage for the broader context of the full document by outlining its purpose to demonstrate practical applications and configurations for utilizing SmolRAG effectively in various tasks, from basic setup to document ingestion.",
        "indexed_at": 1745048767.538389
    },
    "excerpt_id_98568b73e1554f3852d7cabeaa3a1878": {
        "doc_id": "doc_d741bc43c52b5b5bb9c3f2a21dd5d086",
        "doc_order_index": 1,
        "excerpt": "ustom settings. The instance is now ready to import documents and process queries.\n\n---\n\n### **3. Document Ingestion Example**\n\nTo use SmolRAG, you first need to ingest documents. Here's how to do it:```python\n# Import the SmolRag class\nfrom app.smol_rag import SmolRag\n\n# Initialize SmolRAG\nrag = SmolRag()\n\n# Import documents from the input_docs directory\nrag.import_documents()\n\n# You can also manually add documents to the input_docs directory before importing\nimport os\nimport shutil\nfrom app.definitions import INPUT_DOCS_DIR\n\n# Copy a document to the input_docs directory\nsource_file = \"path/to/your/document.md\"\ndestination = os.path.join(INPUT_DOCS_DIR, \"document.md\")\nshutil.copy(source_file, destination)\n\n# Then import documents\nrag.import_documents()\n```",
        "summary": "The excerpt illustrates the essential process of document ingestion in SmolRAG, which is a fundamental step enabling the system to utilize its querying capabilities, thereby reinforcing the broader context of practical usage examples provided throughout the document.",
        "indexed_at": 1745048767.538582
    },
    "excerpt_id_c7eb7e74a2b8451dbfbc03d8e9baccf9": {
        "doc_id": "doc_d741bc43c52b5b5bb9c3f2a21dd5d086",
        "doc_order_index": 2,
        "excerpt": "s directory\nsource_file = \"path/to/your/document.md\"\ndestination = os.path.join(INPUT_DOCS_DIR, \"document.md\")\nshutil.copy(source_file, destination)\n\n# Then import documents\nrag.import_documents()\n```This example shows how to import documents from the default input_docs directory. You can add documents to this directory manually or programmatically before importing.\n\n---\n\n### **4. Simple Query Example**\n\nOnce you have ingested documents, you can query them using the default vector search query:\n\n```python\n# Import the SmolRag class\nfrom app.smol_rag import SmolRag\n\n# Initialize SmolRAG\nrag = SmolRag()\n\n# Make sure documents are imported\nrag.import_documents()\n\n# Perform a simple query\nresult = rag.query(\"What is SmolRAG?\")\nprint(result)\n\n# Ask about specific features\nresult = rag.query(\"How does document chunking work in SmolRAG?\")\nprint(result)\n\n# Ask about use cases\nresult = rag.query(\"What are the main use cases for SmolRAG?\")\nprint(result)\n```\n\nThis example demonstrates how to perform simple queries using the default vector search method. This method is fast and works well for straightforward questions that are directly addressed in the documents.\n\n---\n\n### **5. Knowledge Graph Query Examples**\n\nSmolRAG offers several knowledge graph-based query methods for more complex questions:\n\n```python\n# Import the SmolRag class\nfrom app.smol_rag import SmolRag\n\n# Initialize SmolRAG\nrag = SmolRag()\n\n# Make sure documents are imported\nrag.import_documents()\n\n# Local knowledge graph query (entity-focused)\nresult = rag.local_kg_query(\"What entities are related to document chunking?\")\nprint(result)\n\n# Global knowledge graph query (relationship-focused)\nresult = rag.global_kg_query(\"How are different components of SmolRAG connected?\")\nprint(result)\n\n# Hybrid knowledge graph query (combines local and global)\nresult = rag.hybrid_kg_query(\"What is the relationship between embeddings and queries?\")\nprint(result)\n```\n\nThese examples show how to use different knowledge graph query methods for different types of questions. Each method has its strengths and is suited to different types of queries.\n\n---\n\n### **6. Mix Query Example**",
        "summary": "The excerpt illustrates practical examples of document ingestion and querying in SmolRAG, which supports the broader context of the document by demonstrating the system's capabilities in managing and retrieving information effectively.",
        "indexed_at": 1745048767.538733
    },
    "excerpt_id_44cefee3a8e8faba70704cd4a4d676ae": {
        "doc_id": "doc_d741bc43c52b5b5bb9c3f2a21dd5d086",
        "doc_order_index": 3,
        "excerpt": " show how to use different knowledge graph query methods for different types of questions. Each method has its strengths and is suited to different types of queries.\n\n---\n\n### **6. Mix Query Example**For the most comprehensive results, you can use the mix query method, which combines vector search and knowledge graph approaches:\n\n```python\n# Import the SmolRag class\nfrom app.smol_rag import SmolRag\n\n# Initialize SmolRAG\nrag = SmolRag()\n\n# Make sure documents are imported\nrag.import_documents()\n\n# Mix query (combines vector search and knowledge graph)\nresult = rag.mix_query(\"How does SmolRAG process and retrieve information?\")\nprint(result)\n\n# Complex question requiring both semantic search and structured knowledge\nresult = rag.mix_query(\"What are the advantages and limitations of different query types in SmolRAG?\")\nprint(result)\n```\n\nThe mix query method provides the most comprehensive results by combining the strengths of both vector search and knowledge graph approaches. It's particularly useful for complex questions that benefit from both semantic relevance and structured knowledge.\n\n---\n\n### **7. API Usage Example**\n\nIf you're using SmolRAG through its API, here's how to interact with it:\n\n```python\nimport requests\nimport json\n\n# Define the API endpoint\nurl = \"http://localhost:8000/query\"\n\n# Vector search query\npayload = {\n    \"text\": \"What is SmolRAG?\",\n    \"query_type\": \"standard\"\n}\nheaders = {\"Content-Type\": \"application/json\"}\nresponse = requests.post(url, data=json.dumps(payload), headers=headers)\nprint(response.json())\n\n# Knowledge graph query\npayload = {\n    \"text\": \"What entities are related to document chunking?\",\n    \"query_type\": \"local_kg\"\n}\nresponse = requests.post(url, data=json.dumps(payload), headers=headers)\nprint(response.json())\n\n# Mix query\npayload = {\n    \"text\": \"How does SmolRAG process and retrieve information?\",\n    \"query_type\": \"mix\"\n}\nresponse = requests.post(url, data=json.dumps(payload), headers=headers)\nprint(response.json())\n```\n\nThis example shows how to interact with SmolRAG through its REST API using the Python requests library. The API supports all the same query types as the Python interface.\n\n---",
        "summary": "The excerpt highlights the various knowledge graph query methods offered by SmolRAG, emphasizing their distinct strengths and suitability for different queries, while also illustrating the comprehensive capabilities of the mix query method that combines vector search with knowledge graphs, aligning with the broader context of providing practical usage examples throughout the document.",
        "indexed_at": 1745048767.5388212
    },
    "excerpt_id_3de9971b782eac586dc03f5864ad60f3": {
        "doc_id": "doc_d741bc43c52b5b5bb9c3f2a21dd5d086",
        "doc_order_index": 4,
        "excerpt": "nt(response.json())\n```\n\nThis example shows how to interact with SmolRAG through its REST API using the Python requests library. The API supports all the same query types as the Python interface.\n\n---### **8. Document Management Example**\n\nSmolRAG includes functionality for managing documents, including detecting changes and removing documents:\n\n```python\n# Import the SmolRag class\nfrom app.smol_rag import SmolRag\n\n# Initialize SmolRAG\nrag = SmolRag()\n\n# Import documents\nrag.import_documents()\n\n# If you update a document in the input_docs directory,\n# SmolRAG will automatically detect the change and update its internal representation\n# when you call import_documents() again\nrag.import_documents()\n\n# If you know the document ID, you can remove it directly\ndoc_id = \"doc_4c3f8100da0b90c1a44c94e6b4ffa041\"\nrag.remove_document_by_id(doc_id)\n\n# To get the document ID for a file path, you can use the source_to_doc_kv store\nfile_path = \"app/input_docs/document.md\"\nif rag.source_to_doc_kv.has(file_path):\n    doc_id = rag.source_to_doc_kv.get_by_key(file_path)\n    rag.remove_document_by_id(doc_id)\n```\n\nThis example demonstrates how to manage documents in SmolRAG, including handling updates and removing documents when needed.\n\n---\n\n### **9. Custom Chunking Strategy Example**\n\nIf the default chunking strategies don't meet your needs, you can implement a custom strategy:\n\n```python\n# Import the SmolRag class\nfrom app.smol_rag import SmolRag\n\n# Define a custom chunking function\ndef custom_chunking_strategy(text, excerpt_size, overlap):\n    # Your custom chunking logic here\n    # For example, a simple paragraph-based chunking:\n    paragraphs = text.split(\"\\n\\n\")\n    chunks = []\n    current_chunk = \"\"\n\n    for paragraph in paragraphs:\n        if len(current_chunk) + len(paragraph) <= excerpt_size:\n            current_chunk += paragraph + \"\\n\\n\"\n        else:\n            chunks.append(current_chunk)\n            current_chunk = paragraph + \"\\n\\n\"\n\n    if current_chunk:\n        chunks.append(current_chunk)\n\n    return chunks\n\n# Initialize SmolRAG with the custom chunking strategy\nrag = SmolRag(excerpt_fn=custom_chunking_strategy)\n\n# Import documents\nrag.import_documents()\n```",
        "summary": "The provided excerpt illustrates how to manage documents within SmolRAG, demonstrating the system's capabilities for updating and removing documents, which complements the broader context of the document by emphasizing SmolRAG's flexible functionality in document processing and management tasks.",
        "indexed_at": 1745048767.538919
    },
    "excerpt_id_adb7498f6f95f3de6fde939c658d11cf": {
        "doc_id": "doc_d741bc43c52b5b5bb9c3f2a21dd5d086",
        "doc_order_index": 5,
        "excerpt": "hunks.append(current_chunk)\n\n    return chunks\n\n# Initialize SmolRAG with the custom chunking strategy\nrag = SmolRag(excerpt_fn=custom_chunking_strategy)\n\n# Import documents\nrag.import_documents()\n```This example shows how to implement and use a custom chunking strategy. This can be useful if you have specific requirements for how documents should be divided into chunks.\n\n---\n\n### **10. Integration with Web Applications**\n\nHere's an example of integrating SmolRAG with a simple web application using Flask:\n\n```python\nfrom flask import Flask, request, jsonify\nfrom app.smol_rag import SmolRag\n\napp = Flask(__name__)\nrag = SmolRag()\n\n# Make sure documents are imported\nrag.import_documents()\n\n@app.route('/query', methods=['POST'])\ndef query():\n    data = request.json\n    query_text = data.get('text', '')\n    query_type = data.get('query_type', 'standard')\n\n    if not query_text:\n        return jsonify({'error': 'Query text is required'}), 400\n\n    try:\n        if query_type == 'standard':\n            result = rag.query(query_text)\n        elif query_type == 'local_kg':\n            result = rag.local_kg_query(query_text)\n        elif query_type == 'global_kg':\n            result = rag.global_kg_query(query_text)\n        elif query_type == 'hybrid_kg':\n            result = rag.hybrid_kg_query(query_text)\n        elif query_type == 'mix':\n            result = rag.mix_query(query_text)\n        else:\n            return jsonify({'error': f'Invalid query type: {query_type}'}), 400\n\n        return jsonify({'result': result})\n    except Exception as e:\n        return jsonify({'error': str(e)}), 500\n\nif __name__ == '__main__':\n    app.run(debug=True)\n```\n\nThis example demonstrates how to integrate SmolRAG with a Flask web application, providing a simple API for querying documents.\n\n---\n\n### **11. Batch Processing Example**\n\nIf you need to process multiple queries in batch, here's how to do it efficiently:",
        "summary": "The excerpt illustrates how to implement a custom chunking strategy in SmolRAG, showcasing its adaptability for specific document processing requirements within the broader context of the document's examples on using SmolRAG for diverse functionalities, including integration with web applications and batch processing.",
        "indexed_at": 1745048767.539005
    },
    "excerpt_id_97e526b02e37e6e2b2b176a8cb9cc039": {
        "doc_id": "doc_d741bc43c52b5b5bb9c3f2a21dd5d086",
        "doc_order_index": 6,
        "excerpt": "h a Flask web application, providing a simple API for querying documents.\n\n---\n\n### **11. Batch Processing Example**\n\nIf you need to process multiple queries in batch, here's how to do it efficiently:```python\n# Import the SmolRag class\nfrom app.smol_rag import SmolRag\n\n# Initialize SmolRAG\nrag = SmolRag()\n\n# Make sure documents are imported\nrag.import_documents()\n\n# Define a list of queries\nqueries = [\n    {\"text\": \"What is SmolRAG?\", \"type\": \"standard\"},\n    {\"text\": \"How does document chunking work?\", \"type\": \"local_kg\"},\n    {\"text\": \"What are the advantages of knowledge graphs?\", \"type\": \"global_kg\"},\n    {\"text\": \"How do vector embeddings and knowledge graphs work together?\", \"type\": \"mix\"}\n]\n\n# Process queries\nresults = []\nfor query in queries:\n    if query[\"type\"] == \"standard\":\n        result = rag.query(query[\"text\"])\n    elif query[\"type\"] == \"local_kg\":\n        result = rag.local_kg_query(query[\"text\"])\n    elif query[\"type\"] == \"global_kg\":\n        result = rag.global_kg_query(query[\"text\"])\n    elif query[\"type\"] == \"hybrid_kg\":\n        result = rag.hybrid_kg_query(query[\"text\"])\n    elif query[\"type\"] == \"mix\":\n        result = rag.mix_query(query[\"text\"])\n    else:\n        result = f\"Invalid query type: {query['type']}\"\n\n    results.append({\"query\": query[\"text\"], \"type\": query[\"type\"], \"result\": result})\n\n# Print results\nfor i, result in enumerate(results):\n    print(f\"Query {i+1}: {result['query']}\")\n    print(f\"Type: {result['type']}\")\n    print(f\"Result: {result['result']}\")\n    print(\"-\" * 50)\n```",
        "summary": "The excerpt illustrates a practical example of batch processing queries using SmolRAG, highlighting its capability to efficiently handle multiple query types, which aligns with the broader context of demonstrating the system's versatility and effectiveness in various querying scenarios throughout the document.",
        "indexed_at": 1745048767.539086
    },
    "excerpt_id_9bec674c65e1e71d106b31cafb5387bf": {
        "doc_id": "doc_d741bc43c52b5b5bb9c3f2a21dd5d086",
        "doc_order_index": 7,
        "excerpt": "\n# Print results\nfor i, result in enumerate(results):\n    print(f\"Query {i+1}: {result['query']}\")\n    print(f\"Type: {result['type']}\")\n    print(f\"Result: {result['result']}\")\n    print(\"-\" * 50)\n```This example shows how to process multiple queries in batch, which can be useful for testing or bulk processing.\n\n---\n\n### **12. Parallel Processing with Asyncio**\n\nSmolRAG now uses asyncio for parallel processing during document ingestion, which significantly improves performance:\n\n```python\nimport asyncio\nfrom app.smol_rag import SmolRag\n\n# Initialize SmolRAG\nrag = SmolRag()\n\n# The import_documents method uses asyncio internally\n# It processes multiple documents, embeddings, and entity extractions in parallel\nasync def import_docs():\n    await rag.import_documents()\n\n# Run the async function\nasyncio.run(import_docs())\n\n# Or in an existing async context:\n# await rag.import_documents()\n```\n\nThis example demonstrates how SmolRAG leverages asyncio for parallel processing. The system automatically:\n- Processes multiple documents simultaneously\n- Generates embeddings for multiple excerpts concurrently\n- Extracts entities and relationships from different excerpts in parallel\n\nThis parallel processing approach dramatically reduces ingestion time, especially for large document collections.\n\n---\n\n### **13. Advanced Configuration Example**\n\nFor advanced users, here's how to configure SmolRAG with custom components:",
        "summary": "The excerpt illustrates the practical application of batch processing and asynchronous capabilities in SmolRAG, emphasizing its efficiency in handling multiple queries and document ingestion as integral aspects of the broader context of enhancing performance across various use cases outlined in the full document.",
        "indexed_at": 1745048767.53918
    },
    "excerpt_id_2e0613b4c1b81b865a2002b59fe88b17": {
        "doc_id": "doc_d741bc43c52b5b5bb9c3f2a21dd5d086",
        "doc_order_index": 8,
        "excerpt": "tically reduces ingestion time, especially for large document collections.\n\n---\n\n### **13. Advanced Configuration Example**\n\nFor advanced users, here's how to configure SmolRAG with custom components:```python\n# Import necessary classes\nfrom app.smol_rag import SmolRag\nfrom app.openai_llm import OpenAiLlm\nfrom app.vector_store import NanoVectorStore\nfrom app.graph_store import NetworkXGraphStore\nfrom app.kv_store import JsonKvStore\nfrom app.chunking import preserve_markdown_code_excerpts\n\n# Custom paths\nembeddings_path = \"custom/path/to/embeddings.db\"\nentities_path = \"custom/path/to/entities.db\"\nrelationships_path = \"custom/path/to/relationships.db\"\nkg_path = \"custom/path/to/kg.db\"\nsource_to_doc_path = \"custom/path/to/source_to_doc.json\"\ndoc_to_source_path = \"custom/path/to/doc_to_source.json\"\ndoc_to_excerpt_path = \"custom/path/to/doc_to_excerpt.json\"\nexcerpt_path = \"custom/path/to/excerpt.json\"\nquery_cache_path = \"custom/path/to/query_cache.json\"\nembedding_cache_path = \"custom/path/to/embedding_cache.json\"\n\n# Custom dimensions\ndimensions = 1536\n\n# Initialize custom components\nllm = OpenAiLlm(\n    \"gpt-3.5-turbo\",\n    \"text-embedding-3-small\",\n    query_cache_kv=JsonKvStore(query_cache_path),\n    embedding_cache_kv=JsonKvStore(embedding_cache_path)\n)\n\nembeddings_db = NanoVectorStore(embeddings_path, dimensions)\nentities_db = NanoVectorStore(entities_path, dimensions)\nrelationships_db = NanoVectorStore(relationships_path, dimensions)\n\nsource_to_doc_kv = JsonKvStore(source_to_doc_path)\ndoc_to_source_kv = JsonKvStore(doc_to_source_path)\ndoc_to_excerpt_kv = JsonKvStore(doc_to_excerpt_path)\nexcerpt_kv = JsonKvStore(excerpt_path)\n\ngraph_db = NetworkXGraphStore(kg_path)\n\n# Initialize SmolRAG with custom components\nrag = SmolRag(\n    excerpt_fn=preserve_markdown_code_excerpts,\n    llm=llm,\n    embeddings_db=embeddings_db,\n    entities_db=entities_db,\n    relationships_db=relationships_db,\n    source_to_doc_kv=source_to_doc_kv,\n    doc_to_source_kv=doc_to_source_kv,\n    doc_to_excerpt_kv=doc_to_excerpt_kv,\n    excerpt_kv=excerpt_kv,\n    graph_db=graph_db,\n    dimensions=dimensions,\n    excerpt_size=2000,\n    overlap=200\n)\n\n# Import documents and use as normal\nrag.import_",
        "summary": "The excerpt outlines an advanced configuration example for SmolRAG, illustrating how users can customize its components and integration, which relates to the broader context of the document by demonstrating the system's flexibility and capability to accommodate various user needs in document processing and retrieval.",
        "indexed_at": 1745048767.539264
    },
    "excerpt_id_8efc423402a060df074b1830e38ed77b": {
        "doc_id": "doc_d741bc43c52b5b5bb9c3f2a21dd5d086",
        "doc_order_index": 9,
        "excerpt": "to_excerpt_kv=doc_to_excerpt_kv,\n    excerpt_kv=excerpt_kv,\n    graph_db=graph_db,\n    dimensions=dimensions,\n    excerpt_size=2000,\n    overlap=200\n)\n\n# Import documents and use as normal\nrag.import_documents()\nresult = rag.query(\"What is SmolRAG?\")\nprint(result)\n```",
        "summary": "The excerpt illustrates the customization and initialization of the SmolRAG system, which is a key aspect highlighted throughout the broader document as it emphasizes the framework's versatility in handling various document querying and knowledge extraction tasks.",
        "indexed_at": 1745048767.539347
    },
    "excerpt_id_31dbc989f689c5be27e9ae8b6d0588c4": {
        "doc_id": "doc_d741bc43c52b5b5bb9c3f2a21dd5d086",
        "doc_order_index": 10,
        "excerpt": "documents()\nresult = rag.query(\"What is SmolRAG?\")\nprint(result)\n```This advanced example demonstrates how to configure SmolRAG with custom components and paths, providing maximum flexibility for integration into existing systems.\n\n---\n\n### **14. Conclusion**\n\nThese examples demonstrate the versatility and power of SmolRAG for various use cases. Whether you need simple document querying, complex knowledge extraction, or integration with web applications, SmolRAG provides the tools you need.\n\nBy understanding these examples and adapting them to your specific needs, you can leverage the full potential of SmolRAG to build powerful document retrieval and question-answering systems.",
        "summary": "The excerpt highlights the flexibility and adaptability of SmolRAG, emphasizing its capabilities in document querying and knowledge extraction, which are central themes throughout the broader document's practical usage examples.",
        "indexed_at": 1745048767.539426
    },
    "excerpt_id_4df59d4084f8e159d0d92fc0fd19ada4": {
        "doc_id": "doc_c554f080ffc12bde105430067c572f1e",
        "doc_order_index": 0,
        "excerpt": "**Title: SmolRAG Configuration Options**\n\n---\n\n### **1. Introduction to SmolRAG Configuration**\n\nSmolRAG offers a variety of configuration options that allow you to customize its behavior to suit your specific needs. These options range from basic settings like model selection and directory paths to advanced customizations of the chunking, embedding, and query processes.\n\nThis document provides a comprehensive overview of the available configuration options, explaining what each option does, its default value, and how to set it. Understanding these options will help you optimize SmolRAG for your particular use case, whether you're prioritizing accuracy, speed, or resource efficiency.\n\n---\n\n### **2. Environment Variables**\n\nSmolRAG uses environment variables for core configuration settings. These can be set in your system environment or in a `.env` file in the project root directory.\n\n| Variable | Description | Required | Default |\n|----------|-------------|----------|---------|\n| `OPENAI_API_KEY` | Your OpenAI API key | Yes | None |\n| `COMPLETION_MODEL` | OpenAI model for completions | No | gpt-3.5-turbo |\n| `EMBEDDING_MODEL` | OpenAI model for embeddings | No | text-embedding-3-small |\n\n**Example `.env` file**:\n\n```\nOPENAI_API_KEY=sk-your-api-key\nCOMPLETION_MODEL=gpt-4\nEMBEDDING_MODEL=text-embedding-3-large\n```\n\nThese environment variables are loaded automatically when SmolRAG starts, and they take precedence over the default values defined in the code.\n\n---\n\n### **3. Directory Structure Configuration**\n\nSmolRAG uses a specific directory structure for storing documents, data, and logs. These paths are defined in `app/definitions.py` and can be customized if needed.",
        "summary": "The excerpt introduces the various configuration options available in SmolRAG, emphasizing their role in customizing the tool's behavior to optimize for specific needs, which is a foundational theme throughout the broader document that details implementation and customization practices.",
        "indexed_at": 1745048767.5465841
    },
    "excerpt_id_35ac427df33971aafd001dedc2094d13": {
        "doc_id": "doc_c554f080ffc12bde105430067c572f1e",
        "doc_order_index": 1,
        "excerpt": "Directory Structure Configuration**\n\nSmolRAG uses a specific directory structure for storing documents, data, and logs. These paths are defined in `app/definitions.py` and can be customized if needed.| Path Constant | Default Value | Description |\n|---------------|---------------|-------------|\n| `INPUT_DOCS_DIR` | `app/input_docs` | Directory where input documents are stored |\n| `DATA_DIR` | `app/data` | Directory for storing vector databases and other data |\n| `CACHE_DIR` | `app/cache` | Directory for storing caches |\n| `LOG_DIR` | `app/logs` | Directory for storing log files |\n\nIf you need to change these paths, you can modify the `definitions.py` file or override them when initializing SmolRAG by providing custom paths to the constructor.\n\n---\n\n### **4. SmolRag Initialization Parameters**\n\nThe `SmolRag` class constructor accepts several parameters that allow you to customize its behavior:\n\n```python\ndef __init__(\n    self,\n    excerpt_fn=None,\n    llm=None,\n    embeddings_db=None,\n    entities_db=None,\n    relationships_db=None,\n    source_to_doc_kv=None,\n    doc_to_source_kv=None,\n    doc_to_excerpt_kv=None,\n    excerpt_kv=None,\n    query_cache_kv=None,\n    embedding_cache_kv=None,\n    graph_db=None,\n    dimensions=None,\n    excerpt_size=2000,\n    overlap=200\n)\n```\n\n**Key Parameters**:\n\n- `excerpt_fn`: Function for chunking documents (default: `preserve_markdown_code_excerpts`)\n- `llm`: LLM interface instance (default: new `OpenAiLlm` instance)\n- `dimensions`: Embedding dimensions (default: 1536)\n- `excerpt_size`: Target size for document chunks in characters (default: 2000)\n- `overlap`: Overlap between chunks in characters (default: 200)\n\nThese parameters allow you to customize the core functionality of SmolRAG without modifying the source code.\n\n---\n\n### **5. Chunking Configuration**\n\nDocument chunking is a critical part of the RAG process, and SmolRAG provides several options for customizing it:\n\n**Built-in Chunking Functions**:",
        "summary": "The excerpt details the directory structure and initialization parameters of SmolRAG, illustrating how these configurations enable users to customize the system's behavior and optimize its functionality within the broader context of effectively managing and processing documents and data.",
        "indexed_at": 1745048767.5467148
    },
    "excerpt_id_ce594558fb5aeae85f51870c652a415b": {
        "doc_id": "doc_c554f080ffc12bde105430067c572f1e",
        "doc_order_index": 2,
        "excerpt": "ource code.\n\n---\n\n### **5. Chunking Configuration**\n\nDocument chunking is a critical part of the RAG process, and SmolRAG provides several options for customizing it:\n\n**Built-in Chunking Functions**:1. `naive_overlap_excerpts(text, excerpt_size, overlap)`: A simple chunking strategy that splits text at regular intervals with overlap.\n2. `preserve_markdown_code_excerpts(text, excerpt_size, overlap)`: An advanced strategy that respects Markdown structure and code blocks, which:\n   - Identifies and extracts fenced code blocks (\n\n``` ... ```\n\n) from the document\n   - Keeps entire code blocks intact, ensuring they remain functional and readable\n   - Merges code blocks with neighboring paragraphs when they fit within the chunk size limit\n   - Splits plain-text paragraphs at sentence boundaries when necessary\n   - Applies optional overlap between chunks to maintain context continuity\n\n**Chunking Parameters**:\n\n- `excerpt_size`: Target size for document chunks in characters (default: 2000)\n- `overlap`: Overlap between chunks in characters (default: 200)\n\n**Custom Chunking Function**:\n\nYou can implement your own chunking function and pass it to the `SmolRag` constructor:\n\n```python\ndef custom_chunking_strategy(text, excerpt_size, overlap):\n    # Your custom chunking logic here\n    # ...\n    return chunks\n\nrag = SmolRag(excerpt_fn=custom_chunking_strategy)\n```\n\nYour custom function should accept three parameters (`text`, `excerpt_size`, `overlap`) and return a list of text chunks.\n\n---\n\n### **6. LLM Configuration**\n\nSmolRAG uses OpenAI's API for language model capabilities. You can configure the models used and other LLM-related settings:\n\n**Model Selection**:\n\n- `COMPLETION_MODEL`: The model used for completions (default: gpt-3.5-turbo)\n- `EMBEDDING_MODEL`: The model used for embeddings (default: text-embedding-3-small)\n\n**Custom LLM Interface**:\n\nYou can create a custom `OpenAiLlm` instance with specific settings:",
        "summary": "The excerpt details the chunking configuration options of SmolRAG, emphasizing its importance for document processing and customization, which aligns with the broader context of the document that aims to provide comprehensive guidelines for optimizing the system's various configurations to enhance performance and meet specific user needs.",
        "indexed_at": 1745048767.546806
    },
    "excerpt_id_754be9b4e6d3cf65d9e60bea7edeb331": {
        "doc_id": "doc_c554f080ffc12bde105430067c572f1e",
        "doc_order_index": 3,
        "excerpt": "lt: gpt-3.5-turbo)\n- `EMBEDDING_MODEL`: The model used for embeddings (default: text-embedding-3-small)\n\n**Custom LLM Interface**:\n\nYou can create a custom `OpenAiLlm` instance with specific settings:```python\nfrom app.openai_llm import OpenAiLlm\nfrom app.kv_store import JsonKvStore\n\nllm = OpenAiLlm(\n    completion_model=\"gpt-4\",\n    embedding_model=\"text-embedding-3-large\",\n    query_cache_kv=JsonKvStore(\"custom/path/to/query_cache.json\"),\n    embedding_cache_kv=JsonKvStore(\"custom/path/to/embedding_cache.json\")\n)\n\nrag = SmolRag(llm=llm)\n```",
        "summary": "The excerpt illustrates the customization options available for the language model interface in SmolRAG, emphasizing the ability to select different models and configure caching, which aligns with the document's broader focus on optimizing the system's performance and flexibility through various configuration settings.",
        "indexed_at": 1745048767.5469
    },
    "excerpt_id_60a78091c7c8d6dae9b144963e93551a": {
        "doc_id": "doc_c554f080ffc12bde105430067c572f1e",
        "doc_order_index": 4,
        "excerpt": "del=\"text-embedding-3-large\",\n    query_cache_kv=JsonKvStore(\"custom/path/to/query_cache.json\"),\n    embedding_cache_kv=JsonKvStore(\"custom/path/to/embedding_cache.json\")\n)\n\nrag = SmolRag(llm=llm)\n```This allows you to customize the models used, caching behavior, and other LLM-related settings.\n\n---\n\n### **7. Vector Store Configuration**\n\nThe vector store is responsible for storing and retrieving embeddings. SmolRAG uses a lightweight implementation called `NanoVectorStore` that can be configured in several ways:\n\n**Basic Configuration**:\n\n- `dimensions`: The dimensionality of the embeddings (default: 1536)\n\n**Custom Vector Store**:\n\nYou can create a custom `NanoVectorStore` instance with specific settings:\n\n```python\nfrom app.vector_store import NanoVectorStore\n\nembeddings_db = NanoVectorStore(\"custom/path/to/embeddings.db\", dimensions=1536)\nentities_db = NanoVectorStore(\"custom/path/to/entities.db\", dimensions=1536)\nrelationships_db = NanoVectorStore(\"custom/path/to/relationships.db\", dimensions=1536)\n\nrag = SmolRag(\n    embeddings_db=embeddings_db,\n    entities_db=entities_db,\n    relationships_db=relationships_db\n)\n```\n\nThis allows you to customize the storage location and dimensionality of the vector stores.\n\n---\n\n### **8. Knowledge Graph Configuration**\n\nThe knowledge graph stores entities and relationships extracted from documents. SmolRAG uses a NetworkX-based implementation that can be configured:\n\n**Custom Graph Store**:\n\n```python\nfrom app.graph_store import NetworkXGraphStore\n\ngraph_db = NetworkXGraphStore(\"custom/path/to/kg.db\")\n\nrag = SmolRag(graph_db=graph_db)\n```\n\nThis allows you to customize the storage location of the knowledge graph.\n\n**Graph Extraction Parameters**:\n\nThe entity and relationship extraction process is guided by prompts defined in `prompts.py`. If you need to customize this process, you can modify these prompts or extend the `SmolRag` class to override the extraction methods.\n\n---\n\n### **9. Key-Value Store Configuration**\n\nSmolRAG uses several key-value stores for metadata, mappings, and caching. These can be customized:\n\n**Custom Key-Value Stores**:",
        "summary": "The excerpt highlights specific customization options for configuring the `SmolRAG` language model and its associated components, illustrating how users can optimize the system's performance and behavior within the broader context of the comprehensive configuration guidance provided in the full document.",
        "indexed_at": 1745048767.546981
    },
    "excerpt_id_51c03df854681a0be44a0cb38da8ceed": {
        "doc_id": "doc_c554f080ffc12bde105430067c572f1e",
        "doc_order_index": 5,
        "excerpt": "he extraction methods.\n\n---\n\n### **9. Key-Value Store Configuration**\n\nSmolRAG uses several key-value stores for metadata, mappings, and caching. These can be customized:\n\n**Custom Key-Value Stores**:```python\nfrom app.kv_store import JsonKvStore\n\nsource_to_doc_kv = JsonKvStore(\"custom/path/to/source_to_doc.json\")\ndoc_to_source_kv = JsonKvStore(\"custom/path/to/doc_to_source.json\")\ndoc_to_excerpt_kv = JsonKvStore(\"custom/path/to/doc_to_excerpt.json\")\nexcerpt_kv = JsonKvStore(\"custom/path/to/excerpt.json\")\n\nrag = SmolRag(\n    source_to_doc_kv=source_to_doc_kv,\n    doc_to_source_kv=doc_to_source_kv,\n    doc_to_excerpt_kv=doc_to_excerpt_kv,\n    excerpt_kv=excerpt_kv\n)\n```",
        "summary": "The excerpt on Key-Value Store Configuration illustrates how to customize data storage within SmolRAG, emphasizing its flexibility in managing metadata and caching, which aligns with the document's broader theme of optimizing and personalizing the software's functionality for various use cases.",
        "indexed_at": 1745048767.547057
    },
    "excerpt_id_9224c08a6f58fb5797f206ea7efc517e": {
        "doc_id": "doc_c554f080ffc12bde105430067c572f1e",
        "doc_order_index": 6,
        "excerpt": "re(\"custom/path/to/excerpt.json\")\n\nrag = SmolRag(\n    source_to_doc_kv=source_to_doc_kv,\n    doc_to_source_kv=doc_to_source_kv,\n    doc_to_excerpt_kv=doc_to_excerpt_kv,\n    excerpt_kv=excerpt_kv\n)\n```This allows you to customize the storage location of the key-value stores.\n\n---\n\n### **10. Query Configuration**\n\nSmolRAG's query processing can be configured in several ways:\n\n**Query Types**:\n\n- `query()`: Vector search query\n- `local_kg_query()`: Local knowledge graph query\n- `global_kg_query()`: Global knowledge graph query\n- `hybrid_kg_query()`: Hybrid knowledge graph query\n- `mix_query()`: Mix query (combines vector search and knowledge graph)\n\n**Query Parameters**:\n\nThe query methods don't have explicit parameters for customization, but you can modify their behavior by customizing the underlying components (LLM, vector store, etc.) or by extending the `SmolRag` class to override the query methods.\n\n**System Prompts**:\n\nThe query processing is guided by prompts defined in `prompts.py`. If you need to customize this process, you can modify these prompts or extend the `SmolRag` class to override the query methods.\n\n---\n\n### **11. Logging Configuration**\n\nSmolRAG includes a logging system that can be configured:\n\n**Log Level**:\n\nThe log level can be set in `app/logger.py`:\n\n```python\ndef set_logger(log_file_name):\n    # ...\n    logger.setLevel(logging.INFO)  # Change to logging.DEBUG for more verbose logging\n    # ...\n```\n\n**Log File**:\n\nThe log file is specified when calling `set_logger()`:\n\n```python\nfrom app.logger import set_logger\n\nset_logger(\"custom_log.log\")\n```\n\n**Custom Logging**:\n\nIf you need more advanced logging configuration, you can modify `app/logger.py` or implement your own logging system.\n\n---\n\n### **12. API Configuration**\n\nIf you're using the SmolRAG API, you can configure it in several ways:\n\n**Server Configuration**:\n\nWhen starting the API server, you can specify the host and port:\n\n```bash\nuvicorn api.main:app --host 0.0.0.0 --port 8000\n```\n\n**FastAPI Configuration**:\n\nThe FastAPI application in `api/main.py` can be customized with additional middleware, error handlers, etc.:",
        "summary": "The excerpt illustrates specific customization options for key-value stores in SmolRAG, emphasizing its flexibility in configuring storage paths for various components, which aligns with the overall theme of the document that provides comprehensive configuration settings for optimizing SmolRAG's performance and functionality.",
        "indexed_at": 1745048767.547134
    },
    "excerpt_id_c4c3ec315a84b895249de1a09e9984ee": {
        "doc_id": "doc_c554f080ffc12bde105430067c572f1e",
        "doc_order_index": 7,
        "excerpt": ":\n\n```bash\nuvicorn api.main:app --host 0.0.0.0 --port 8000\n```\n\n**FastAPI Configuration**:\n\nThe FastAPI application in `api/main.py` can be customized with additional middleware, error handlers, etc.:```python\nfrom fastapi import FastAPI\nfrom fastapi.middleware.cors import CORSMiddleware\n\napp = FastAPI(title=\"SmolRag API\")\n\n# Add CORS middleware\napp.add_middleware(\n    CORSMiddleware,\n    allow_origins=[\"*\"],\n    allow_credentials=True,\n    allow_methods=[\"*\"],\n    allow_headers=[\"*\"],\n)\n\n# Add custom middleware, error handlers, etc.\n```",
        "summary": "The excerpt details the configuration of the FastAPI server for SmolRAG, illustrating how to customize server parameters and middleware for enhanced functionality within the broader context of optimizing SmolRAG's performance and adaptability in server deployment.",
        "indexed_at": 1745048767.5472481
    },
    "excerpt_id_e0d2ab7be18b619d1b6cfd5900b9347e": {
        "doc_id": "doc_c554f080ffc12bde105430067c572f1e",
        "doc_order_index": 8,
        "excerpt": "ware\napp.add_middleware(\n    CORSMiddleware,\n    allow_origins=[\"*\"],\n    allow_credentials=True,\n    allow_methods=[\"*\"],\n    allow_headers=[\"*\"],\n)\n\n# Add custom middleware, error handlers, etc.\n```**Query Endpoint Configuration**:\n\nThe query endpoint in `api/main.py` can be customized to add additional parameters, validation, etc.:\n\n```python\nfrom fastapi import FastAPI, Query\nfrom pydantic import BaseModel, Field\n\nclass QueryRequest(BaseModel):\n    text: str = Field(..., description=\"The query text\")\n    query_type: str = Field(\"standard\", description=\"The query type\")\n    max_results: int = Field(5, description=\"Maximum number of results to return\")\n\n@app.post(\"/query\")\nasync def query_endpoint(request: QueryRequest):\n    # Process query with custom parameters\n    # ...\n```\n\n---\n\n### **13. Parallel Processing Configuration**\n\nSmolRAG uses Python's asyncio library for parallel processing during document ingestion, which significantly improves performance:\n\n**Asyncio Implementation**:\n\n- Multiple documents are processed simultaneously\n- Embedding and completion requests are executed concurrently\n- The `asyncio.gather()` function combines multiple asynchronous tasks\n- Rate limiting is applied to API calls to prevent throttling\n\n**Rate Limiting Configuration**:\n\n```python\n# In SmolRag.__init__\nself.llm_limiter = AsyncLimiter(max_rate=100, time_period=1)\n```\n\nYou can adjust the rate limiting parameters by extending the `SmolRag` class:\n\n```python\nfrom app.smol_rag import SmolRag\nfrom aiolimiter import AsyncLimiter\n\nclass CustomRateLimitedSmolRag(SmolRag):\n    def __init__(self, *args, **kwargs):\n        super().__init__(*args, **kwargs)\n        # Customize rate limiting\n        self.llm_limiter = AsyncLimiter(max_rate=50, time_period=1)\n```\n\nThis parallel processing approach dramatically reduces ingestion time, especially for large document collections.\n\n---\n\n### **14. Advanced Customization**\n\nFor more advanced customization, you can extend the core classes of SmolRAG:\n\n**Extending SmolRag**:",
        "summary": "The excerpt illustrates how to configure middleware and query endpoints in the SmolRAG API, highlighting the broader context of enhancing the application\u2019s flexibility and performance through customized request handling and improved processing efficiency, as discussed throughout the document.",
        "indexed_at": 1745048767.547328
    },
    "excerpt_id_7f32de37a5cddfe45cdff7356d2a5584": {
        "doc_id": "doc_c554f080ffc12bde105430067c572f1e",
        "doc_order_index": 9,
        "excerpt": "ngestion time, especially for large document collections.\n\n---\n\n### **14. Advanced Customization**\n\nFor more advanced customization, you can extend the core classes of SmolRAG:\n\n**Extending SmolRag**:```python\nfrom app.smol_rag import SmolRag\n\nclass CustomSmolRag(SmolRag):\n    def __init__(self, *args, **kwargs):\n        super().__init__(*args, **kwargs)\n        # Add custom initialization\n\n    def custom_query(self, text):\n        # Implement custom query method\n        # ...\n\n    # Override existing methods\n    def query(self, text):\n        # Custom implementation of query\n        # ...\n```",
        "summary": "The excerpt discusses advanced customization options for SmolRAG, illustrating how users can extend its core classes to implement tailored functionalities, which aligns with the broader document's theme of configuration flexibility and optimization for varied use cases.",
        "indexed_at": 1745048767.547404
    },
    "excerpt_id_c3ca869388739cbef75785b9d8a4b3e1": {
        "doc_id": "doc_c554f080ffc12bde105430067c572f1e",
        "doc_order_index": 10,
        "excerpt": "f custom_query(self, text):\n        # Implement custom query method\n        # ...\n\n    # Override existing methods\n    def query(self, text):\n        # Custom implementation of query\n        # ...\n```**Custom Components**:\n\nYou can also implement custom versions of the core components:\n\n- Custom LLM interface\n- Custom vector store\n- Custom knowledge graph store\n- Custom key-value store\n- Custom chunking strategies\n\nThese custom components can be passed to the `SmolRag` constructor to replace the default implementations.\n\n---\n\n### **15. Configuration Best Practices**\n\nHere are some best practices for configuring SmolRAG:\n\n**Performance Optimization**:\n- Use a smaller embedding model if speed is more important than accuracy\n- Adjust chunk size and overlap based on your document characteristics\n- Implement caching for frequent queries\n- Use the appropriate query type for each use case\n\n**Resource Efficiency**:\n- Monitor memory usage, especially for large document collections\n- Consider using a more efficient chunking strategy for large documents\n- Implement rate limiting for the API to prevent excessive API calls\n- Use appropriate token limits for summarization and query processing\n\n**Customization Strategy**:\n- Start with the default configuration and adjust as needed\n- Test different configurations to find the optimal settings for your use case\n- Document your custom configuration for future reference\n- Consider creating a configuration file or module for your specific deployment\n\nBy following these best practices, you can optimize SmolRAG for your specific needs while maintaining its core functionality and performance.",
        "summary": "The excerpt emphasizes the importance of implementing custom query methods and components in SmolRAG, which aligns with the document's broader focus on optimizing configuration and customization for enhanced performance and resource efficiency.",
        "indexed_at": 1745048767.547481
    },
    "excerpt_id_f1fae642defef59936a03b705fb37221": {
        "doc_id": "doc_93121085de0e7adf39ab2e255aa404c4",
        "doc_order_index": 0,
        "excerpt": "**Title: SmolRAG Implementation Details**\n\n---\n\n### **1. Code Organization and Structure**\n\nSmolRAG's codebase is organized in a modular, maintainable structure that separates concerns and promotes reusability. The main components are organized as follows:\n\n- **app/**: The main package containing all SmolRAG functionality\n  - **smol_rag.py**: The core class that orchestrates the entire system\n  - **chunking.py**: Document chunking strategies\n  - **openai_llm.py**: Interface to OpenAI's API\n  - **vector_store.py**: Vector database implementation\n  - **graph_store.py**: Knowledge graph implementation\n  - **kv_store.py**: Key-value store implementation\n  - **prompts.py**: System prompts for various operations\n  - **utilities.py**: General utility functions\n  - **logger.py**: Logging configuration\n  - **definitions.py**: Constants and path definitions\n  - **evaluation/**: Evaluation framework\n- **api/**: FastAPI implementation for the REST API\n  - **main.py**: API endpoints and request handling\n\nThis organization follows the principle of separation of concerns, with each module responsible for a specific aspect of the system's functionality.\n\n---\n\n### **2. The SmolRag Class**\n\nThe `SmolRag` class in `smol_rag.py` is the main entry point and orchestrator for the system. It integrates all the components and provides the primary interface for users.\n\n**Key Methods**:\n- `__init__()`: Initializes the RAG system with configurable components\n- `import_documents()`: Imports documents from the input directory\n- `query()`: Performs vector search query\n- `local_kg_query()`: Performs local knowledge graph query\n- `global_kg_query()`: Performs global knowledge graph query\n- `hybrid_kg_query()`: Performs hybrid knowledge graph query\n- `mix_query()`: Performs mix query (combines vector search and knowledge graph)\n- `remove_document_by_id()`: Removes a document from the system",
        "summary": "The excerpt outlines the modular organization and key functionalities of the SmolRAG implementation, which supports its broader context of providing a flexible and maintainable system for document processing, querying, and integration with APIs.",
        "indexed_at": 1745048767.560544
    },
    "excerpt_id_23b091ffbf5cfdc68a155822645cbe8f": {
        "doc_id": "doc_93121085de0e7adf39ab2e255aa404c4",
        "doc_order_index": 1,
        "excerpt": "brid_kg_query()`: Performs hybrid knowledge graph query\n- `mix_query()`: Performs mix query (combines vector search and knowledge graph)\n- `remove_document_by_id()`: Removes a document from the systemThe class is designed to be flexible, allowing users to customize various components through dependency injection in the constructor.\n\n---\n\n### **3. Document Chunking Implementation**\n\nDocument chunking is implemented in `chunking.py`, which provides strategies for splitting documents into manageable pieces:\n\n**Key Functions**:\n- `naive_overlap_excerpts(text, excerpt_size, overlap)`: A simple chunking strategy that splits text at regular intervals with overlap\n- `preserve_markdown_code_excerpts(text, excerpt_size, overlap)`: An advanced strategy that respects Markdown structure and code blocks, which:\n  - Identifies and extracts fenced code blocks (\n\n``` ... ```\n\n) from the document\n  - Keeps entire code blocks intact, ensuring they remain functional and readable\n  - Merges code blocks with neighboring paragraphs when they fit within the chunk size limit\n  - Splits plain-text paragraphs at sentence boundaries when necessary\n  - Applies optional overlap between chunks to maintain context continuity\n\nThe chunking functions are designed to be interchangeable, allowing users to select the most appropriate strategy for their documents or implement custom strategies. The `preserve_markdown_code_excerpts` function is now the default chunking strategy in SmolRAG, providing better handling of technical documentation with code examples.\n\n---\n\n### **4. OpenAI LLM Interface**\n\nThe `OpenAiLlm` class in `openai_llm.py` provides a clean interface to OpenAI's API for embeddings and completions:\n\n**Key Methods**:\n- `__init__()`: Initializes the LLM interface with configurable models and caching\n- `get_embedding(text)`: Gets an embedding for the given text\n- `get_completion(prompt, context=None, use_cache=True)`: Gets a completion for the given prompt\n\nThe class includes caching mechanisms to improve performance and reduce API costs, with separate caches for embeddings and completions.\n\n---\n\n### **5. Vector Store Implementation**",
        "summary": "The excerpt highlights the flexibility and modular design of the SmolRAG system, particularly focusing on its document chunking strategies and the integration of various components such as the OpenAI API interface and vector store, which align with the broader context of creating an efficient, customizable, and maintainable retrieval-augmented generation framework.",
        "indexed_at": 1745048767.56064
    },
    "excerpt_id_0e491c74d7a88194d22edb5dcf034178": {
        "doc_id": "doc_93121085de0e7adf39ab2e255aa404c4",
        "doc_order_index": 2,
        "excerpt": "r the given prompt\n\nThe class includes caching mechanisms to improve performance and reduce API costs, with separate caches for embeddings and completions.\n\n---\n\n### **5. Vector Store Implementation**The `NanoVectorStore` class in `vector_store.py` provides a lightweight vector database for storing and retrieving embeddings:\n\n**Key Methods**:\n- `__init__(path, dimensions)`: Initializes the vector store with a path and dimensions\n- `upsert(items)`: Inserts or updates items in the store\n- `query(query, top_k=5, better_than_threshold=0.0)`: Queries the store for similar vectors\n- `delete(ids)`: Deletes items from the store\n- `save()`: Saves the store to disk\n\nThe implementation is optimized for simplicity and efficiency, providing the necessary functionality without the complexity of larger vector database systems.\n\n---\n\n### **6. Knowledge Graph Implementation**\n\nThe `NetworkXGraphStore` class in `graph_store.py` provides a graph database built on NetworkX for storing entities and relationships:\n\n**Key Methods**:\n- `__init__(path)`: Initializes the graph store with a path\n- `add_node(name, **attrs)`: Adds a node (entity) to the graph\n- `add_edge(source, target, **attrs)`: Adds an edge (relationship) to the graph\n- `get_node(name)`: Gets a node by name\n- `get_edge((source, target))`: Gets an edge by source and target\n- `get_node_edges(name)`: Gets all edges connected to a node\n- `degree(name)`: Gets the degree (number of connections) of a node\n- `save()`: Saves the graph to disk\n\nThe implementation leverages NetworkX's capabilities while providing a simplified interface tailored to SmolRAG's needs.\n\n---\n\n### **7. Key-Value Store Implementation**\n\nThe `JsonKvStore` class in `kv_store.py` provides a simple key-value store for caching and metadata:\n\n**Key Methods**:\n- `__init__(path)`: Initializes the store with a path\n- `add(key, value)`: Adds a key-value pair to the store\n- `get_by_key(key)`: Gets a value by key\n- `has(key)`: Checks if a key exists in the store\n- `remove(key)`: Removes a key-value pair from the store\n- `equal(key, value)`: Checks if a key's value equals the given value\n- `save()`: Saves the store to disk",
        "summary": "The excerpt illustrates specific implementations of caching and storage mechanisms within SmolRAG, highlighting the project's modular design that emphasizes efficient data management, which aligns with the overarching theme of maintainability and scalability detailed throughout the document.",
        "indexed_at": 1745048767.560747
    },
    "excerpt_id_048561f7b91b06effbd2fa38d6b6e86d": {
        "doc_id": "doc_93121085de0e7adf39ab2e255aa404c4",
        "doc_order_index": 3,
        "excerpt": ": Checks if a key exists in the store\n- `remove(key)`: Removes a key-value pair from the store\n- `equal(key, value)`: Checks if a key's value equals the given value\n- `save()`: Saves the store to diskThis lightweight implementation provides efficient storage for metadata and caching, with JSON serialization for persistence.\n\n---\n\n### **8. System Prompts**\n\nThe `prompts.py` file contains carefully crafted prompts for various operations:\n\n**Key Functions**:\n- `get_query_system_prompt(context)`: Gets the system prompt for vector search queries\n- `excerpt_summary_prompt(full_doc, excerpt)`: Gets the prompt for summarizing excerpts\n- `get_extract_entities_prompt(excerpt)`: Gets the prompt for extracting entities and relationships\n- `get_high_low_level_keywords_prompt(query)`: Gets the prompt for extracting high and low-level keywords\n- `get_kg_query_system_prompt(context)`: Gets the system prompt for knowledge graph queries\n- `get_mix_system_prompt(excerpt_context, kg_context)`: Gets the system prompt for mix queries\n\nThese prompts are critical for guiding the LLM's behavior in various tasks, ensuring consistent and high-quality results.\n\n---\n\n### **9. Utility Functions**\n\nThe `utilities.py` file contains various utility functions used throughout the system:\n\n**Key Functions**:\n- `read_file(path)`: Reads a file from disk\n- `get_docs(directory)`: Gets all documents in a directory\n- `make_hash(content, prefix=\"\")`: Creates a hash of content\n- `split_string_by_multi_markers(text, markers)`: Splits a string by multiple markers\n- `clean_str(s)`: Cleans a string\n- `extract_json_from_text(text)`: Extracts JSON from text\n- `truncate_list_by_token_size(items, get_text_for_row, max_token_size)`: Truncates a list to fit within a token limit\n- `list_of_list_to_csv(list_of_list)`: Converts a list of lists to CSV format\n\nThese utility functions provide common functionality used across different components of the system.\n\n---\n\n### **10. Constants and Path Definitions**\n\nThe `definitions.py` file contains constants and path definitions used throughout the system:",
        "summary": "The excerpt highlights the implementation of key-value store functionalities and system prompts, illustrating how these components contribute to SmolRAG's modular design and efficient handling of metadata, which supports the broader context of enhancing data processing and user interaction within the system.",
        "indexed_at": 1745048767.560832
    },
    "excerpt_id_0c67144102b1d81212b12e6ef61ad148": {
        "doc_id": "doc_93121085de0e7adf39ab2e255aa404c4",
        "doc_order_index": 4,
        "excerpt": "ionality used across different components of the system.\n\n---\n\n### **10. Constants and Path Definitions**\n\nThe `definitions.py` file contains constants and path definitions used throughout the system:**Key Constants**:\n- `INPUT_DOCS_DIR`: Path to the input documents directory\n- `DATA_DIR`: Path to the data directory\n- `CACHE_DIR`: Path to the cache directory\n- `LOG_DIR`: Path to the log directory\n- `EMBEDDINGS_DB`: Path to the embeddings database\n- `KG_DB`: Path to the knowledge graph database\n- `COMPLETION_MODEL`: Default OpenAI model for completions\n- `EMBEDDING_MODEL`: Default OpenAI model for embeddings\n\nThese constants provide a centralized place for configuration, making it easy to adjust paths and settings.\n\n---\n\n### **11. API Implementation**\n\nThe API is implemented using FastAPI in `api/main.py`:\n\n**Key Components**:\n- `app`: The FastAPI application\n- `QueryRequest`: Pydantic model for query requests\n- `QueryResponse`: Pydantic model for query responses\n- `query_map`: Mapping from query type strings to SmolRAG methods\n- `validate_request()`: Validates query requests\n- `query_endpoint()`: Handles query requests\n\nThe API provides a simple interface for interacting with SmolRAG through HTTP requests, with proper validation and error handling.\n\n---\n\n### **12. Logging and Error Handling**\n\nLogging and error handling are implemented throughout the system:\n\n**Logging**:\n- The `logger.py` file configures the logging system\n- The `set_logger()` function sets up logging with a specified file\n- Log messages are categorized by level (INFO, WARNING, ERROR, etc.)\n- Performance metrics and processing steps are logged for monitoring\n\n**Error Handling**:\n- Try-except blocks are used to catch and handle exceptions\n- Graceful degradation ensures the system continues even if individual steps fail\n- Detailed error messages help with debugging\n- The API includes proper error responses with status codes and messages\n\nThis robust logging and error handling ensures that the system is reliable and maintainable.\n\n---\n\n### **13. Data Flow and Processing Pipeline**\n\nThe data flow in SmolRAG follows well-defined processing pipelines:",
        "summary": "The excerpt discusses the organization of constants and path definitions in the SmolRAG system, emphasizing their role in configuration centralization, which supports the broader structure and modularity of the entire system's implementation.",
        "indexed_at": 1745048767.5609212
    },
    "excerpt_id_d4a7e13bce25a456a78a4eef57373bf4": {
        "doc_id": "doc_93121085de0e7adf39ab2e255aa404c4",
        "doc_order_index": 5,
        "excerpt": "ogging and error handling ensures that the system is reliable and maintainable.\n\n---\n\n### **13. Data Flow and Processing Pipeline**\n\nThe data flow in SmolRAG follows well-defined processing pipelines:**Document Ingestion Pipeline**:\n1. Documents are read from the input directory\n2. Each document is chunked into excerpts using the `preserve_markdown_code_excerpts` function\n3. Multiple processing tasks are created and executed in parallel using asyncio:\n   - Excerpt summarization tasks are gathered and processed concurrently\n   - Embedding generation tasks are gathered and processed concurrently\n   - Entity and relationship extraction tasks are gathered and processed concurrently\n4. The asyncio.gather() function combines these asynchronous tasks for efficient parallel processing\n5. Rate limiting is applied to API calls to prevent throttling\n6. All data is stored in the appropriate stores\n\n**Query Processing Pipeline**:\n1. The query is received and validated\n2. The appropriate query method is called based on the query type\n3. The query is processed according to the specific pipeline for that query type\n4. The results are formatted and returned\n\nThese pipelines ensure consistent processing and make it easy to understand and modify the system's behavior. The use of asyncio for parallel processing significantly improves data ingestion speed, especially for large document collections.\n\n---\n\n### **14. Conclusion**\n\nSmolRAG's implementation is characterized by modularity, flexibility, and attention to detail. The system is designed to be easy to understand, maintain, and extend, with clear separation of concerns and well-defined interfaces between components.\n\nThe core functionality is implemented in the `SmolRag` class, which orchestrates the various components to provide a seamless experience for users. The modular design allows for customization and extension, making it possible to adapt SmolRAG to different use cases and requirements.\n\nBy understanding these implementation details, developers can more effectively use, customize, and extend SmolRAG to meet their specific needs.",
        "summary": "The excerpt underscores the critical role of well-defined data flow and processing pipelines in SmolRAG's modular and flexible design, enhancing system reliability, maintainability, and adaptability for varied use cases as detailed throughout the document.",
        "indexed_at": 1745048767.560995
    },
    "excerpt_id_87030b6b3fa79706b6853abbb475c551": {
        "doc_id": "doc_29c075b5e1084616707b26ab9f8796ab",
        "doc_order_index": 0,
        "excerpt": "**Title: SmolRAG Project Overview and Architecture**\n\n---\n\n### **1. Introduction to SmolRAG**\n\nSmolRAG is a lightweight retrieval-augmented generation system inspired by LightRAG, designed for fast, up-to-date querying of your own documents. It combines the power of vector embeddings, knowledge graphs, and large language models to provide accurate and relevant answers to queries about your documents.\n\nThe system is built with a focus on simplicity, efficiency, and flexibility, making it accessible for developers who need to implement RAG capabilities without the complexity of larger systems. SmolRAG is particularly well-suited for applications where document content changes frequently and where maintaining up-to-date information is critical.\n\n---\n\n### **2. Core Principles**\n\nSmolRAG is built on several core principles that guide its design and implementation:\n\n- **Lightweight and Efficient**: Minimizes resource usage while maintaining high performance.\n- **Up-to-Date Information**: Automatically detects and processes document changes to ensure answers reflect the latest content.\n- **Contextual Understanding**: Preserves document context through intelligent chunking and summarization.\n- **Flexible Querying**: Offers multiple query methods to handle different types of questions and information needs.\n- **Knowledge Graph Integration**: Combines semantic search with structured knowledge representation for deeper understanding.\n- **Code-Friendly**: Preserves code blocks and technical content during processing.\n\nThese principles ensure that SmolRAG delivers accurate, relevant, and timely information while remaining accessible and easy to use.\n\n---\n\n### **3. High-Level Architecture**\n\nSmolRAG's architecture consists of several interconnected components that work together to process documents and answer queries:",
        "summary": "The excerpt provides an introduction to the SmolRAG system, highlighting its lightweight and efficient design for retrieval-augmented generation, which is integral to understanding the overall architecture and principles that make it suitable for dynamic document querying in the broader context of the full document.",
        "indexed_at": 1745049798.240934
    },
    "excerpt_id_39a1d6ebedcdf64866e51dc2d7baf5dc": {
        "doc_id": "doc_29c075b5e1084616707b26ab9f8796ab",
        "doc_order_index": 1,
        "excerpt": "g accessible and easy to use.\n\n---\n\n### **3. High-Level Architecture**\n\nSmolRAG's architecture consists of several interconnected components that work together to process documents and answer queries:1. **Document Processor**: Handles document ingestion, chunking, and summarization.\n2. **Vector Store**: Manages document embeddings for semantic search capabilities.\n3. **Knowledge Graph**: Stores entities and relationships extracted from documents.\n4. **Query Processor**: Processes different types of queries and retrieves relevant information.\n5. **LLM Interface**: Communicates with OpenAI's API for embeddings and completions.\n6. **API Layer**: Exposes functionality through a REST API.\n\nThis modular architecture allows for flexibility and extensibility, making it easy to adapt SmolRAG to different use cases and requirements.\n\n---\n\n### **4. Data Flow**\n\nThe data flow in SmolRAG follows two main paths: document ingestion and query processing.\n\n**Document Ingestion Flow**:\n1. Documents are read from the input directory\n2. Each document is split into overlapping chunks (~2,000 characters)\n3. Chunks are summarized with the whole document as context\n4. Summaries and chunks are embedded using OpenAI's embedding API\n5. Entities and relationships are extracted and stored in the knowledge graph\n6. Document hashes are stored to track changes\n\n**Query Processing Flow**:\n1. User submits a query through the API\n2. The query is processed based on the specified query type\n3. Relevant information is retrieved from the vector store and/or knowledge graph\n4. Retrieved information is used to generate a response using the LLM\n5. Response is returned to the user\n\nThis bidirectional flow ensures that SmolRAG can both ingest new information and retrieve it effectively when needed.\n\n---\n\n### **5. Key Components**\n\nEach component in SmolRAG's architecture serves a specific purpose:",
        "summary": "The excerpt details the modular architecture and data flow of SmolRAG, highlighting how its interconnected components collaboratively process documents and answer queries, which underscores the system's design focus on flexibility, efficiency, and adaptability for diverse use cases within the broader context of the project overview.",
        "indexed_at": 1745049798.241141
    },
    "excerpt_id_70868e98ba121059de996d38d21a0dd7": {
        "doc_id": "doc_29c075b5e1084616707b26ab9f8796ab",
        "doc_order_index": 2,
        "excerpt": " flow ensures that SmolRAG can both ingest new information and retrieve it effectively when needed.\n\n---\n\n### **5. Key Components**\n\nEach component in SmolRAG's architecture serves a specific purpose:- **SmolRag Class**: The main entry point and orchestrator for the system.\n- **Chunking Module**: Provides strategies for splitting documents into manageable pieces.\n- **OpenAiLlm**: Handles communication with OpenAI's API for embeddings and completions.\n- **NanoVectorStore**: A lightweight vector database for storing and retrieving embeddings.\n- **NetworkXGraphStore**: A graph database built on NetworkX for storing entities and relationships.\n- **JsonKvStore**: A simple key-value store for caching and metadata.\n- **API Module**: A FastAPI implementation that exposes SmolRAG's functionality.\n\nThese components are designed to be modular and interchangeable, allowing for customization and extension as needed.\n\n---\n\n### **6. System Requirements**\n\nSmolRAG is designed to be lightweight and can run on modest hardware. The minimum requirements are:\n\n- **Python**: Version 3.10 or higher\n- **Memory**: 4GB RAM (8GB recommended for larger document sets)\n- **Storage**: Depends on the size of your document collection\n- **API Keys**: OpenAI API key for embeddings and completions\n- **Dependencies**: NetworkX, NumPy, FastAPI, and other Python libraries\n\nFor production deployments, consider scaling resources based on the size of your document collection and expected query volume.\n\n---\n\n### **7. Integration Points**\n\nSmolRAG can be integrated with other systems in several ways:\n\n- **REST API**: The built-in FastAPI server provides a simple interface for integration.\n- **Python Library**: Direct integration in Python applications through the SmolRag class.\n- **Docker Container**: Containerized deployment for easy integration with microservices.\n- **Custom Adapters**: Extensible design allows for custom adapters to other systems.\n\nThese integration points make SmolRAG versatile and adaptable to different environments and use cases.\n\n---\n\n### **8. Conclusion**",
        "summary": "The excerpt highlights the modular components and system requirements of SmolRAG, emphasizing its design flexibility and lightweight architecture, which collectively support its core function of efficiently ingesting and retrieving information.",
        "indexed_at": 1745049798.241245
    },
    "excerpt_id_7f2443f5ebfc8f85347fa0ad3e1b4199": {
        "doc_id": "doc_29c075b5e1084616707b26ab9f8796ab",
        "doc_order_index": 3,
        "excerpt": "rs**: Extensible design allows for custom adapters to other systems.\n\nThese integration points make SmolRAG versatile and adaptable to different environments and use cases.\n\n---\n\n### **8. Conclusion**SmolRAG represents a balanced approach to retrieval-augmented generation, offering powerful capabilities in a lightweight package. Its architecture combines the best aspects of semantic search, knowledge graphs, and large language models to provide accurate and contextually relevant answers to queries about your documents.\n\nBy focusing on simplicity, efficiency, and flexibility, SmolRAG makes advanced RAG capabilities accessible to a wide range of developers and use cases. Whether you're building a documentation search system, a knowledge base, or a question-answering application, SmolRAG provides the tools you need to succeed.",
        "summary": "The excerpt emphasizes SmolRAG's adaptability and user-friendly design, reinforcing the broader context of the document that highlights its efficiency and versatility in providing advanced retrieval-augmented generation capabilities for various applications.",
        "indexed_at": 1745049798.241338
    },
    "excerpt_id_dc65135b9ad9bfac43cc3ae95a7b4158": {
        "doc_id": "doc_2c09b7fbf37e863290474da1ee784ad5",
        "doc_order_index": 0,
        "excerpt": "**Title: SmolRAG Document Ingestion Process**\n\n---\n\n### **1. Document Ingestion Overview**\n\nDocument ingestion is the first critical step in the SmolRAG pipeline. This process transforms raw documents into a format that can be efficiently queried and analyzed. SmolRAG's ingestion process is designed to be automatic, efficient, and change-aware, ensuring that the system always has access to the most up-to-date information.\n\nThe ingestion process handles various document formats, preserves important structural elements like code blocks, and extracts both semantic content and structured knowledge. This comprehensive approach enables SmolRAG to provide rich, contextually relevant responses to queries.\n\n---\n\n### **2. Document Sources and Formats**\n\nSmolRAG ingests documents from the `app/input_docs/` directory. The system supports various text-based formats, with a particular focus on Markdown files. Key aspects of document handling include:\n\n- **Supported Formats**: Plain text (.txt) and Markdown (.md) files are fully supported.\n- **Directory Structure**: All files in the input_docs directory are processed recursively.\n- **File Identification**: Each file is identified by its path and a content hash for change detection.\n- **Metadata Extraction**: File paths and other metadata are preserved for context and reference.\n\nWhen adding new documents to SmolRAG, place them in the input_docs directory and run the import_documents method. The system will automatically process new files and update any changed ones.\n\n---\n\n### **3. Document Chunking Strategies**\n\nSmolRAG employs sophisticated chunking strategies to break documents into manageable pieces while preserving context and coherence:",
        "summary": "The excerpt highlights the foundational role of the document ingestion process in the SmolRAG pipeline, emphasizing its automatic and efficient transformation of various document formats into a queryable structure, which is essential for providing accurate and contextually relevant responses within the broader context of the document's comprehensive capabilities.",
        "indexed_at": 1745049798.252296
    },
    "excerpt_id_d24dd08ee554d6069354fc456f67147f": {
        "doc_id": "doc_2c09b7fbf37e863290474da1ee784ad5",
        "doc_order_index": 1,
        "excerpt": "ate any changed ones.\n\n---\n\n### **3. Document Chunking Strategies**\n\nSmolRAG employs sophisticated chunking strategies to break documents into manageable pieces while preserving context and coherence:- **Default Chunking**: Documents are split into overlapping chunks of approximately 2,000 characters.\n- **Overlap Mechanism**: An overlap of 200 characters between chunks ensures context continuity.\n- **Code Block Preservation**: Markdown code blocks are kept intact to maintain their meaning and structure.\n- **Paragraph Awareness**: Text is segmented at paragraph boundaries when possible.\n- **Sentence Boundaries**: Long paragraphs are further divided at sentence boundaries to avoid splitting words.\n\nThe chunking process is configurable, allowing users to adjust chunk size and overlap based on their specific needs. The system provides two main chunking functions:\n\n1. `naive_overlap_excerpts`: A simple chunking strategy that splits text at regular intervals with overlap.\n2. `preserve_markdown_code_excerpts`: An advanced strategy that respects Markdown structure and code blocks.\n\nThe `preserve_markdown_code_excerpts` function, which is now the default, uses a sophisticated algorithm to:\n- Identify and extract fenced code blocks (\n\n``` ... ```\n\n) from the document\n- Keep entire code blocks intact, ensuring they remain functional and readable\n- Merge code blocks with neighboring paragraphs when they fit within the chunk size limit\n- Split plain-text paragraphs at sentence boundaries when necessary\n- Apply optional overlap between chunks to maintain context continuity\n\n---\n\n### **4. Excerpt Summarization**\n\nAfter chunking, each excerpt is summarized to enhance context quality:\n\n- **Contextual Summarization**: Each chunk is summarized with the whole document provided as context.\n- **Summary Purpose**: Summaries help preserve the relationship between the excerpt and the broader document.\n- **LLM-Based Approach**: Summaries are generated using OpenAI's language models with carefully crafted prompts.\n- **Fallback Mechanism**: If summarization fails, a default summary is used to ensure processing continues.",
        "summary": "The excerpt on document chunking strategies illustrates a crucial aspect of SmolRAG's ingestion process, emphasizing how maintaining context and coherence in the transformation of raw documents is essential for creating a robust and effective knowledge base for querying.",
        "indexed_at": 1745049798.252411
    },
    "excerpt_id_40ff8100b340e2bffbf37fe882a8ee48": {
        "doc_id": "doc_2c09b7fbf37e863290474da1ee784ad5",
        "doc_order_index": 2,
        "excerpt": "ch**: Summaries are generated using OpenAI's language models with carefully crafted prompts.\n- **Fallback Mechanism**: If summarization fails, a default summary is used to ensure processing continues.The summarization process is critical for maintaining context when retrieving excerpts during queries. It helps the system understand not just the content of each chunk, but also its significance within the larger document.\n\n---\n\n### **5. Vector Embedding Generation**\n\nSmolRAG creates vector embeddings for each excerpt to enable semantic search:\n\n- **Combined Content**: Both the excerpt and its summary are embedded together.\n- **Embedding Model**: OpenAI's embedding models (default: text-embedding-3-small) generate the vectors.\n- **Dimensionality**: The default embedding dimension is 1536, but this is configurable.\n- **Storage**: Embeddings are stored in the NanoVectorStore for efficient retrieval.\n- **Metadata**: Each embedding is associated with metadata including document ID, excerpt ID, and timestamp.\n\nThese embeddings form the foundation of SmolRAG's semantic search capabilities, allowing the system to find relevant content based on meaning rather than just keywords.\n\n---\n\n### **6. Entity and Relationship Extraction**\n\nSmolRAG builds a knowledge graph by extracting entities and relationships from documents:\n\n- **Entity Extraction**: Key concepts, terms, and names are identified in each excerpt.\n- **Entity Properties**: Each entity has a name, category, and description.\n- **Relationship Identification**: Connections between entities are extracted with descriptions and weights.\n- **LLM-Based Extraction**: OpenAI's language models analyze text to identify entities and relationships.\n- **Structured Format**: Extracted information follows a specific format for consistent processing.\n\nThe extracted entities and relationships form a knowledge graph that enables structured querying and reasoning about document content. This graph complements the vector embeddings, providing a more comprehensive understanding of the documents.\n\n---\n\n### **7. Parallel Processing with Asyncio**\n\nSmolRAG leverages Python's asyncio library to significantly improve data ingestion speed:",
        "summary": "The excerpt highlights the critical role of summarization and vector embedding generation in SmolRAG's document ingestion process, emphasizing how these components enhance the system's ability to retrieve and understand the contextual significance of documents within the broader framework of effective knowledge management.",
        "indexed_at": 1745049798.252495
    },
    "excerpt_id_7fedf9d4b30621d6c79f65db2d09ce1a": {
        "doc_id": "doc_2c09b7fbf37e863290474da1ee784ad5",
        "doc_order_index": 3,
        "excerpt": "viding a more comprehensive understanding of the documents.\n\n---\n\n### **7. Parallel Processing with Asyncio**\n\nSmolRAG leverages Python's asyncio library to significantly improve data ingestion speed:- **Concurrent Processing**: Multiple documents are processed simultaneously.\n- **Parallel API Calls**: Embedding and completion requests are executed concurrently.\n- **Task Gathering**: The `asyncio.gather()` function combines multiple asynchronous tasks.\n- **Rate Limiting**: An `AsyncLimiter` controls API call rates to prevent throttling.\n- **Resource Efficiency**: Parallel processing makes better use of available system resources.\n\nThis asynchronous approach dramatically reduces ingestion time, especially for large document collections, by:\n- Processing multiple document chunks in parallel\n- Generating embeddings for multiple excerpts concurrently\n- Extracting entities and relationships from different excerpts simultaneously\n\n---\n\n### **8. Change Detection and Updates**\n\nSmolRAG includes a robust change detection mechanism to ensure information stays current:\n\n- **Content Hashing**: Each document's content is hashed to detect changes.\n- **Path-Based Tracking**: Documents are tracked by their file path and content hash.\n- **Automatic Updates**: When a document changes, old embeddings and graph entries are removed and new ones are created.\n- **Selective Processing**: Only changed documents are reprocessed, saving time and resources.\n- **Consistency Maintenance**: The system ensures that all components (vector store, knowledge graph, etc.) remain in sync.\n\nThis change detection mechanism is crucial for maintaining up-to-date information, especially in environments where documents are frequently updated.\n\n---\n\n### **9. Storage and Persistence**\n\nSmolRAG uses several storage mechanisms to persist processed documents:",
        "summary": "The excerpt highlights the parallel processing and change detection mechanisms in SmolRAG's document ingestion process, emphasizing their roles in improving ingestion speed and ensuring information remains current within the broader context of transforming raw documents into a rich, queryable knowledge base.",
        "indexed_at": 1745049798.252579
    },
    "excerpt_id_e1f4404cf1e9a718f626b127f773cf70": {
        "doc_id": "doc_2c09b7fbf37e863290474da1ee784ad5",
        "doc_order_index": 4,
        "excerpt": "o-date information, especially in environments where documents are frequently updated.\n\n---\n\n### **9. Storage and Persistence**\n\nSmolRAG uses several storage mechanisms to persist processed documents:- **Vector Store**: NanoVectorStore stores embeddings for semantic search.\n- **Knowledge Graph**: NetworkXGraphStore stores entities and relationships.\n- **Key-Value Stores**: JsonKvStore manages metadata, mappings, and caches.\n- **File Structure**: Data is organized in the app/data directory with separate files for different components.\n- **Serialization**: Data is serialized to disk to persist between runs.\n\nThese storage mechanisms ensure that processed documents are available for querying without needing to reprocess them each time the system starts.\n\n---\n\n### **10. Error Handling and Logging**\n\nThe document ingestion process includes comprehensive error handling and logging:\n\n- **Exception Handling**: Errors during processing are caught and logged.\n- **Graceful Degradation**: The system continues processing even if individual steps fail.\n- **Detailed Logging**: Each step of the ingestion process is logged for debugging and monitoring.\n- **Performance Metrics**: Processing time and resource usage are tracked and logged.\n- **Warning System**: Potential issues are flagged with warnings for user attention.\n\nThis robust error handling ensures that the ingestion process is reliable and resilient, even when processing complex or problematic documents.\n\n---\n\n### **11. Conclusion**\n\nSmolRAG's document ingestion process is a sophisticated pipeline that transforms raw documents into a rich, queryable knowledge base. By combining chunking, summarization, embedding, and knowledge graph extraction, the system creates a comprehensive representation of document content that enables accurate and contextually relevant responses to queries.\n\nThe change detection mechanism ensures that information stays current, while the modular design allows for customization and extension. Whether you're working with technical documentation, knowledge bases, or any other text-based content, SmolRAG's ingestion process provides the foundation for effective retrieval-augmented generation.",
        "summary": "The excerpt highlights the storage and error handling components of the SmolRAG document ingestion process, emphasizing how these factors contribute to the system's reliability and efficiency in maintaining an up-to-date and queryable knowledge base.",
        "indexed_at": 1745049798.2526531
    }
}